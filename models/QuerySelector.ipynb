{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25399,"status":"ok","timestamp":1670755784719,"user":{"displayName":"Simon Eliasen","userId":"10493305960020237489"},"user_tz":-60},"id":"9PUVlK5eXbVH","outputId":"b2b43900-e272-45a1-b9af-a08c87d765ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'query-selector'...\n","remote: Enumerating objects: 402, done.\u001b[K\n","remote: Counting objects: 100% (384/384), done.\u001b[K\n","remote: Compressing objects: 100% (248/248), done.\u001b[K\n","remote: Total 402 (delta 232), reused 272 (delta 132), pack-reused 18\u001b[K\n","Receiving objects: 100% (402/402), 11.79 MiB | 10.83 MiB/s, done.\n","Resolving deltas: 100% (236/236), done.\n","Checking out files: 100% (19/19), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deepspeed\n","  Downloading deepspeed-0.7.6.tar.gz (709 kB)\n","\u001b[K     |████████████████████████████████| 709 kB 25.0 MB/s \n","\u001b[?25hCollecting hjson\n","  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 75.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from deepspeed) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from deepspeed) (21.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from deepspeed) (5.4.8)\n","Collecting py-cpuinfo\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from deepspeed) (1.10.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from deepspeed) (1.13.0+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from deepspeed) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->deepspeed) (3.0.9)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic->deepspeed) (4.4.0)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.7.6-py3-none-any.whl size=714426 sha256=4890da0448bd09346994b4dfd1f6f2f4010b19f6a15e1b96082db67cea5cd2de\n","  Stored in directory: /root/.cache/pip/wheels/a8/8e/b2/e0eea301fe581983fcb99c6d25ee85b522f82390b0dc071157\n","Successfully built deepspeed\n","Installing collected packages: py-cpuinfo, ninja, hjson, deepspeed\n","Successfully installed deepspeed-0.7.6 hjson-3.1.0 ninja-1.11.1 py-cpuinfo-9.0.0\n","/content/query-selector\n"]}],"source":["!git clone https://github.com/simoneliasen/query-selector.git\n","!pip3 install deepspeed\n","%cd query-selector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12906,"status":"ok","timestamp":1670755803259,"user":{"displayName":"Simon Eliasen","userId":"10493305960020237489"},"user_tz":-60},"id":"aFTDbnd5XcLZ","outputId":"c598988e-1ed3-418e-91d4-d1820f592463"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 14.7 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 49.9 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 64.5 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 73.6 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 64.9 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 79.0 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 78.9 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 65.1 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 68.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 72.4 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 81.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 84.3 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 81.3 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 69.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 82.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 67.1 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 78.4 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#Get data\n","import pandas as pd\n","import numpy as np\n","import json\n","from datetime import datetime, timedelta\n","!pip install wandb -qU\n","import wandb\n","\n","#Paper Dataset\n","ETTh1 = pd.read_csv(\"data/ETTh1.csv\")\n","\n","#Our Full Dataset\n","#dataset_dropNA = pd.read_csv(\"data/dataset_dropNA.csv\") #old dataset without timefeatures\n","dataset_dropNA = pd.read_csv(\"data/datasetV3.csv\")\n","dataset_dropNA.rename(columns = {'hour':'date'}, inplace = True) #model only works with date somehow\n","\n","#Subset of Our Dataset (7 features, default for troubleshooting)\n","#Change sys.argv.extend([\"--input_len\", '372', \"--output_len\", \"3\"], with 372-372 or 372-1)\n","dataset_dropNA_subset = dataset_dropNA[['date', 'TH_NP15_GEN-APND', 'TH_SP15_GEN-APND','TH_ZP26_GEN-APND', 'CAISO-SP15 Wind Power Generation Forecast','CAISO-NEVP Power Demand Forecast','CAISO-AZPS Power Demand Forecast','CAISO-SDGE Power Demand Forecast']].copy()\n","dataset_dropNA_subset.to_csv('data/dataset_dropNA_subset.csv', index=False) \n","\n","\n","\n","def timestep_check(df_features, endate):\n","    xx = True\n","    try:\n","        df_features.index[df_features['date'] == str(endate)][0]\n","    except:\n","        xx = False\n","\n","    return xx\n","\n","\n","def get_data(dates, traininglength, df_features):\n","    #to get date as datetime object, so timedelta method can be used.\n","    start_date = datetime.fromisoformat(dates)\n","    #timedelta finds automatic the date x days before \n","    endindex = df_features.index[df_features['date'] == dates][0]\n","    \n","    i = 7\n","    timestep_exist = False\n","    #til at håndtere manglende timesteps i csv\n","    while timestep_exist is False:\n","        endate = start_date - timedelta(days= (traininglength+i))\n","        timestep_exist = timestep_check(df_features, endate)\n","        i += 1\n","        \n","    startindex = df_features.index[df_features['date'] == str(endate)][0]\n"," \n","    df_season = df_features.iloc[startindex:endindex]\n","   \n","    return df_season\n"," \n","\n","def offset_dataframe(df,i) -> pd.DataFrame:\n","    later_validation_hours = (6-i)*24\n","    unused_train_hours = i*24\n","    df_copy = df.drop(df.tail(later_validation_hours).index) # drop last n rows\n","    df_copy = df_copy.drop(df_copy.head(unused_train_hours).index) # drop first n rows\n","    return df_copy\n","\n","\n","def split_dataframes(df, season_start):\n","    df.to_csv('data/season ' + str(season_start) + '.csv', index=False) #save to training.csv file\n","    for i in range(7):\n","      df_subset = offset_dataframe(df,i)\n","      df_subset.to_csv('data/training ' + str(i+1) + ' ' + str(season_start) + '.csv', index=False) #save as training,1,2,3,4... files .csv\n","      \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsntLENKGruc"},"outputs":[],"source":["#Parse json\n","def get_results():\n","\n","    with open('data/datasave.json', 'r') as f:\n","      data = json.load(f)\n","\n","    season1 = \"s1\"\n","    season2 = \"s2\"\n","    season3 = \"s3\"\n","    season4 = \"s4\"\n","\n","    season1_RMSE = []\n","    season1_MAE = []\n","    season1_pred_NP15 = []  \n","    season1_pred_SP15 = []\n","    season1_pred_ZP26 = []\n","    season1_truth_NP15 = []\n","    season1_truth_SP15 = []\n","    season1_truth_ZP26 = []\n","\n","    season2_RMSE = []\n","    season2_MAE = []\n","    season2_pred_NP15 = []  \n","    season2_pred_SP15 = []\n","    season2_pred_ZP26 = []\n","    season2_truth_NP15 = []\n","    season2_truth_SP15 = []\n","    season2_truth_ZP26 = []\n","\n","\n","    season3_RMSE = []\n","    season3_MAE = []\n","    season3_pred_NP15 = []  \n","    season3_pred_SP15 = []\n","    season3_pred_ZP26 = []\n","    season3_truth_NP15 = []\n","    season3_truth_SP15 = []\n","    season3_truth_ZP26 = []\n","\n","    season4_RMSE = []\n","    season4_MAE = []\n","    season4_pred_NP15 = []  \n","    season4_pred_SP15 = []\n","    season4_pred_ZP26 = []\n","    season4_truth_NP15 = []\n","    season4_truth_SP15 = []\n","    season4_truth_ZP26 = []\n","\n","\n","    for key, value in data.items():\n","      if season1 in key: \n","        season1_RMSE.append(value['RMSE'])\n","        season1_MAE.append(value['MAE'])\n","\n","        for x in value['Predictions']: \n","          season1_pred_NP15.append(x[0])\n","          season1_pred_SP15.append(x[1])\n","          season1_pred_ZP26.append(x[2])\n","\n","        for x in value['Ground Truth']:\n","          season1_truth_NP15.append(x[0])\n","          season1_truth_SP15.append(x[1])\n","          season1_truth_ZP26.append(x[2])\n","    \n","      if season2 in key:\n","        season2_RMSE.append(value['RMSE'])\n","        season2_MAE.append(value['MAE'])\n","\n","        for x in value['Predictions']: \n","          season2_pred_NP15.append(x[0])\n","          season2_pred_SP15.append(x[1])\n","          season2_pred_ZP26.append(x[2])\n","\n","        for x in value['Ground Truth']:\n","          season2_truth_NP15.append(x[0])\n","          season2_truth_SP15.append(x[1])\n","          season2_truth_ZP26.append(x[2])\n","\n","      if season3 in key:\n","        season3_RMSE.append(value['RMSE'])\n","        season3_MAE.append(value['MAE'])\n","\n","        for x in value['Predictions']: \n","          season3_pred_NP15.append(x[0])\n","          season3_pred_SP15.append(x[1])\n","          season3_pred_ZP26.append(x[2])\n","\n","        for x in value['Ground Truth']:\n","          season3_truth_NP15.append(x[0])\n","          season3_truth_SP15.append(x[1])\n","          season3_truth_ZP26.append(x[2])\n","\n","      if season4 in key:\n","        season4_RMSE.append(value['RMSE'])\n","        season4_MAE.append(value['MAE'])\n","\n","        for x in value['Predictions']: \n","          season4_pred_NP15.append(x[0])\n","          season4_pred_SP15.append(x[1])\n","          season4_pred_ZP26.append(x[2])\n","\n","        for x in value['Ground Truth']:\n","          season4_truth_NP15.append(x[0])\n","          season4_truth_SP15.append(x[1])\n","          season4_truth_ZP26.append(x[2])\n","\n","\n","    print(\"\\n\")\n","    print(\"Season 1\")\n","    print(\"RMSE\")\n","    print(season1_RMSE)\n","    print(\"MAE\")\n","    print(season1_MAE)\n","    print(\"RMSE_average_season1\")\n","    RMSE_average1 = sum(season1_RMSE) / len(season1_RMSE)\n","    print(RMSE_average1)\n","    print(\"MAE_average_season1\")\n","    MAE_average1 = sum(season1_MAE) / len(season1_MAE)\n","    print(MAE_average1)\n","    print(\"NP15 pred\")\n","    print(season1_pred_NP15)\n","    print(\"SP15 pred\")\n","    print(season1_pred_SP15)\n","    print(\"ZP26 pred\")\n","    print(season1_pred_ZP26)\n","    print(\"NP15 truth\")\n","    print(season1_truth_NP15)\n","    print(\"SP15 truth\")\n","    print(season1_truth_SP15)\n","    print(\"ZP26 truth\")\n","    print(season1_truth_ZP26)\n","\n","\n","    print(\"\\n\")\n","    print(\"Season 2\")\n","    print(\"RMSE\")\n","    print(season2_RMSE)\n","    print(\"MAE\")\n","    print(season2_MAE)\n","    print(\"RMSE_average_season2\")\n","    RMSE_average2 = sum(season2_RMSE) / len(season2_RMSE)\n","    print(RMSE_average2)\n","    print(\"MAE_average_season2\")\n","    MAE_average2 = sum(season2_MAE) / len(season2_MAE)\n","    print(MAE_average2)\n","    print(\"NP15 pred\")\n","    print(season2_pred_NP15)\n","    print(\"SP15 pred\")\n","    print(season2_pred_SP15)\n","    print(\"ZP26 pred\")\n","    print(season2_pred_ZP26)\n","    print(\"NP15 truth\")\n","    print(season2_truth_NP15)\n","    print(\"SP15 truth\")\n","    print(season2_truth_SP15)\n","    print(\"ZP26 truth\")\n","    print(season2_truth_ZP26)\n","\n","\n","    print(\"\\n\")\n","    print(\"Season 3\")\n","    print(\"RMSE\")\n","    print(season3_RMSE)\n","    print(\"MAE\")\n","    print(season3_MAE)\n","    print(\"RMSE_average_season3\")\n","    RMSE_average3 = sum(season3_RMSE) / len(season3_RMSE)\n","    print(RMSE_average3)\n","    print(\"MAE_average_season3\")\n","    MAE_average3 = sum(season3_MAE) / len(season3_MAE)\n","    print(MAE_average3)\n","    print(\"NP15 pred\")\n","    print(season3_pred_NP15)\n","    print(\"SP15 pred\")\n","    print(season3_pred_SP15)\n","    print(\"ZP26 pred\")\n","    print(season3_pred_ZP26)\n","    print(\"NP15 truth\")\n","    print(season3_truth_NP15)\n","    print(\"SP15 truth\")\n","    print(season3_truth_SP15)\n","    print(\"ZP26 truth\")\n","    print(season3_truth_ZP26)\n","\n","\n","    print(\"\\n\")\n","    print(\"Season 4\")\n","    print(\"RMSE\")\n","    print(season4_RMSE)\n","    print(\"MAE\")\n","    print(season4_MAE)\n","    print(\"RMSE_average_season4\")\n","    RMSE_average4 = sum(season4_RMSE) / len(season4_RMSE)\n","    print(RMSE_average4)\n","    print(\"MAE_average_season3\")\n","    MAE_average4 = sum(season4_MAE) / len(season4_MAE)\n","    print(MAE_average4)\n","    print(\"NP15 pred\")\n","    print(season4_pred_NP15)\n","    print(\"SP15 pred\")\n","    print(season4_pred_SP15)\n","    print(\"ZP26 pred\")\n","    print(season4_pred_ZP26)\n","    print(\"NP15 truth\")\n","    print(season4_truth_NP15)\n","    print(\"SP15 truth\")\n","    print(season4_truth_SP15)\n","    print(\"ZP26 truth\")\n","    print(season4_truth_ZP26)\n","\n","\n","    RMSE_seasons_average = []\n","    RMSE_seasons_average.append(RMSE_average1) \n","    RMSE_seasons_average.append(RMSE_average2)\n","    RMSE_seasons_average.append(RMSE_average3)\n","    RMSE_seasons_average.append(RMSE_average4)\n","\n","    MAE_seasons_average = []\n","    MAE_seasons_average.append(MAE_average1)\n","    MAE_seasons_average.append(MAE_average2)\n","    MAE_seasons_average.append(MAE_average3)\n","    MAE_seasons_average.append(MAE_average4)\n","\n","\n","    print(\"\\n\")\n","    print(\"RMSE Averages of seasons\")\n","    print(RMSE_seasons_average)\n","\n","    print(\"RMSE Total seasons average\")\n","    Total_average_rmse_loss = sum(RMSE_seasons_average) / len(RMSE_seasons_average)\n","    print(Total_average_rmse_loss)\n","\n","    print(\"\\n\")\n","    print(\"MAE Averages of seasons\")\n","    print(MAE_seasons_average)\n","\n","    print(\"MAE Total seasons average\")\n","    Total_average_mae_loss = sum(MAE_seasons_average) / len(MAE_seasons_average)\n","    print(Total_average_mae_loss)\n","\n","    #Predictions/targets for individual seasons\n","    for i in range(len(season1_pred_NP15)): #Any predicition or target series can be used all are 273\n","      wandb.log({\"Winter predictions (39h) Hub: NP15\": season1_pred_NP15[i],\n","                 \"Winter predictions (39h) Hub: SP15\": season1_pred_SP15[i],\n","                 \"Winter predictions (39h) Hub: ZP26\": season1_pred_ZP26[i],\n","                 \"Spring predictions (39h) Hub: NP15\": season2_pred_NP15[i],\n","                 \"Spring predictions (39h) Hub: SP15\": season2_pred_SP15[i],\n","                 \"Spring predictions (39h) Hub: ZP26\": season2_pred_ZP26[i],\n","                 \"Summer predictions (39h) Hub: NP15\": season3_pred_NP15[i],\n","                 \"Summer predictions (39h) Hub: SP15\": season3_pred_SP15[i],\n","                 \"Summer predictions (39h) Hub: ZP26\": season3_pred_ZP26[i],\n","                 \"Fall predictions (39h) Hub: NP15\": season4_pred_NP15[i],\n","                 \"Fall predictions (39h) Hub: SP15\": season4_pred_SP15[i],\n","                 \"Fall predictions (39h) Hub: ZP26\": season4_pred_ZP26[i],\n","                 \"Winter targets (39h) Hub: NP15\": season1_truth_NP15[i],\n","                 \"Winter targets (39h) Hub: SP15\": season1_truth_SP15[i],\n","                 \"Winter targets (39h) Hub: ZP26\": season1_truth_ZP26[i],\n","                 \"Spring targets (39h) Hub: NP15\": season2_truth_NP15[i],\n","                 \"Spring targets (39h) Hub: SP15\": season2_truth_SP15[i],\n","                 \"Spring targets (39h) Hub: ZP26\": season2_truth_ZP26[i],\n","                 \"Summer targets (39h) Hub: NP15\": season3_truth_NP15[i],\n","                 \"Summer targets (39h) Hub: SP15\": season3_truth_SP15[i],\n","                 \"Summer targets (39h) Hub: ZP26\": season3_truth_ZP26[i],\n","                 \"Fall targets (39h) Hub: NP15\": season4_truth_NP15[i],\n","                 \"Fall targets (39h) Hub: SP15\": season4_truth_SP15[i],\n","                 \"Fall targets (39h) Hub: ZP26\": season4_truth_ZP26[i]\n","                 })\n","      \n","    #7 values of RMSE/MAE over season\n","    for i in range(len(season1_RMSE)): #Any season series can be used all are 7\n","      wandb.log({\"Winter_RMSE_loss\": season1_RMSE[i],\n","                 \"Spring_RMSE_loss\": season2_RMSE[i],\n","                 \"Summer_RMSE_loss\": season3_RMSE[i],\n","                 \"Fall_RMSE_loss\": season4_RMSE[i],\n","                 \"Winter_MAE_loss\": season1_MAE[i],\n","                 \"Spring_MAE_loss\": season2_MAE[i],\n","                 \"Summer_MAE_loss\": season3_MAE[i],\n","                 \"Fall_MAE_loss\": season4_MAE[i]\n","                 })\n","\n","    #Individual seasons averages\n","    wandb.log({\"Winter_Average_MAE_Loss\": MAE_average1})\n","    wandb.log({\"Spring_Average_MAE_Loss\": MAE_average2})\n","    wandb.log({\"Summer_Average_MAE_Loss\": MAE_average3})\n","    wandb.log({\"Fall_Average_MAE_Loss\": MAE_average4})\n","\n","    wandb.log({\"Winter_Average_RMSE_Loss\": RMSE_average1})\n","    wandb.log({\"Spring_Average_RMSE_Loss\": RMSE_average2})\n","    wandb.log({\"Summer_Average_RMSE_Loss\": RMSE_average3})\n","    wandb.log({\"Fall_Average_RMSE_Loss\": RMSE_average4})\n","\n","    #Logging Total Average of MAE and RMSE\n","    wandb.log({\"Total_Average_MAE_Loss\": Total_average_mae_loss})\n","    wandb.log({\"Total_Average_RMSE_Loss\": Total_average_rmse_loss})\n","\n","\n","#from matplotlib import pyplot as plt\n","#plt.plot(season1_pred_NP15)\n","#plt.plot(season1_truth_NP15)\n"]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_AGENT_MAX_INITIAL_FAILURES\"]= \"100\"\n","\n","sweep_config = {\n","    'name': 'navn',\n","    'method': 'random', #grid, random, bayesian\n","    'metric': {\n","    'name': 'Total_Average_MAE_Loss',\n","    'goal': 'minimize'  \n","        },\n","    'parameters': {\n","        'batch_size': {\n","            'values': [16, 18, 24, 32, 64, 96, 128]  \n","        },\n","        'hidden_size': {\n","            'values': [32, 64, 96, 128, 144]  \n","        },        \n","        'attention_heads': {\n","            'values': [1, 2, 3, 4, 5, 6] \n","        },\n","        'embedding_size': {\n","            'values': [16, 18, 24, 32, 48] \n","        },\n","        'factor': {\n","          'values': [0.75, 0.8, 0.85, 0.9]\n","        },\n","        'sequence_length': {\n","            'values': [39, 48, 78, 96, 168]   \n","        },\n","        'lr': {\n","            'values': [0.00005, 0.0001, 0.001, 0.01, 0.1] \n","        },\n","        'weight_decay': {\n","            'values': [0, 0.000001, 0.0001, 0.01, 0.1]  \n","        },\n","        'dropout_rate': {\n","            'values': [0, 0.05, 0.1 , 0.15]  \n","        },\n","        'n_encoder_layers': {\n","            'values': [1, 2, 3, 4, 5]\n","        },\n","        'n_decoder_layers': {\n","            'values': [1, 2, 3, 4, 5] \n","        },\n","        'days_training_length': {\n","            'values': [31, 62, 124, 248, 365, 520]\n","        },\n","    }\n","}\n","\n","\n","def set_hyp_config(modelname):\n","    sweep_config['name'] = modelname\n","    if modelname == \"LSTM\":\n","        print('speciel setting for: ', modelname)\n","        sweep_config['parameters']['batch_size']['values'] = [1] #LSTM tager kun batch_size på 1\n","        del sweep_config['parameters']['encoder_length'] #Fjerner alle transformers parametre som ikke er med i LSTM\n","        del sweep_config['parameters']['attention_heads']\n","        del sweep_config['parameters']['encoding_size']\n","        del sweep_config['parameters']['n_encoder_layers']\n","        del sweep_config['parameters']['n_decoder_layers']\n","        sweep_config['parameters']['optimizer']['values'] = ['rAdam', 'adam', 'sgd']\n","        #Tænker der skal være noget til optim her, vil gætte på: sweep_config['parameters']['optimizer']['values'] = ['rAdam', 'adam']\n"," \n","    if modelname == \"Queryselector\" or modelname == \"TFT\":\n","        print('speciel setting for: ', modelname)\n","        #del sweep_config['parameters']['sequence_length']\n","        #Tænker der skal være noget til optim her, vil gætte på: sweep_config['parameters']['optimizer']['values'] = ['sgd', 'ranger']\n"," \n","  \n","def sweep():\n","    wandb.init(config=sweep_config)\n","    run(wandb.config)\n"," \n","\n","def wandb_initialize(modelname):\n","    sweep_config = {\n","    'name': 'navn',\n","    'method': 'random', #grid, random, bayesian\n","    'metric': {\n","    'name': 'Total_Average_MAE_Loss',\n","    'goal': 'minimize'  \n","        },\n","    'parameters': {\n","        'batch_size': {\n","            'values': [16, 18, 24, 32, 64, 96, 128]  \n","        },\n","        'hidden_size': {\n","            'values': [32, 64, 96, 128, 144]  \n","        },        \n","        'attention_heads': {\n","            'values': [1, 2, 3, 4, 5, 6] \n","        },\n","        'embedding_size': {\n","            'values': [16, 18, 24, 32, 48] \n","        },\n","        'factor': {\n","          'values': [0.75, 0.8, 0.85, 0.9]\n","        },\n","        'sequence_length': {\n","            'values': [39, 48, 78, 96, 168]   \n","        },\n","        'lr': {\n","            'values': [0.00005, 0.0001, 0.001, 0.01, 0.1] \n","        },\n","        'weight_decay': {\n","            'values': [0, 0.000001, 0.0001, 0.01, 0.1]  \n","        },\n","        'dropout_rate': {\n","            'values': [0, 0.05, 0.1 , 0.15]  \n","        },\n","        'n_encoder_layers': {\n","            'values': [1, 2, 3, 4, 5]\n","        },\n","        'n_decoder_layers': {\n","            'values': [1, 2, 3, 4, 5] \n","        },\n","        'days_training_length': {\n","            'values': [31, 62, 124, 248, 365, 520]\n","        },\n","    }\n","}\n","    #sweep_id = wandb.sweep(sweep_config, project=\"Yggdrasil\", entity=\"ygg_monkeys\") #todo: dette laver en ny sweep.\n","    sweep_ids = {\n","        \"LSTM\":\"ywympjpq\", \n","        \"Queryselector\":\"69vvdc1l\", \n","        \"TFT\":\"29snzczn\"\n","    }\n","    wandb.agent(sweep_id=sweep_ids[modelname], function=sweep, project=\"Yggdrasil\", entity=\"ygg_monkeys\")\n"," \n","\n","def run(hyper_dick): #Emulate run here\n","\n","    print(\"Initializing hyperparameters\")\n","    hyperparameters = {\n","      \"data\": \"training\",\n","      \"seq_len\": hyper_dick['sequence_length'], \n","      \"pred_len\": 39,\n","      \"dec_seq_len\": hyper_dick['sequence_length'],\n","      \"hidden_size\": hyper_dick['hidden_size'],\n","      \"heads\": hyper_dick['attention_heads'],\n","      \"n_encoder_layers\": hyper_dick['n_encoder_layers'], \n","      \"encoder_attention\": \"query_selector_\"+ str(hyper_dick['factor']),\n","      \"n_decoder_layers\": hyper_dick['n_decoder_layers'],\n","      \"decoder_attention\": \"full\",\n","      \"batch_size\": hyper_dick['batch_size'],\n","      \"embedding_size\": hyper_dick['embedding_size'],\n","      \"prediction_type\": \"multiuni\", \n","      \"dropout\": hyper_dick['dropout_rate'],\n","      \"fp16\": True,\n","      \"deepspeed\": True,\n","      \"iterations\": 10000,\n","      \"exps\": 1,\n","      \"debug\": False\n","    }\n","    more_hyperparameters = {\n","      \"train_micro_batch_size_per_gpu\": 5,\n","      \"gradient_accumulation_steps\": 1,\n","      \"steps_per_print\": 10,\n","      \"optimizer\": {\n","        \"type\": \"Adam\",\n","        \"params\": { \n","          \"lr\": hyper_dick['lr'], \n","          \"weight_decay\": hyper_dick['weight_decay']\n","        }\n","      },\n","      \"zero_optimization\": {\n","        \"stage\": 2,\n","        \"allgather_partitions\": False,\n","        \"cpu_offload\": False\n","      },\n","      \"fp16\": {\n","        \"enabled\": True,\n","        \"loss_scale_window\": 1000\n","      }\n","    }\n","    with open(\"settings/hyperparameters.json\", \"w\") as outfile:\n","        json.dump(hyperparameters, outfile, indent=2)\n","    with open(\"settings/ds_config.json\", \"w\") as outfile:\n","        json.dump(more_hyperparameters, outfile, indent=2)\n","    print(\"Done Configuring hyperparameters\")\n","\n","\n","\n","    print(\"Configure data\")\n","    dates = [\"2021-01-10 23:00:00\", \"2021-04-11 23:00:00\", \"2021-07-11 23:00:00\", \"2021-10-10 23:00:00\" ]\n","    for i in range(len(dates)):\n","      df_season = get_data(dates[i], hyper_dick['days_training_length'], dataset_dropNA)\n","      split_dataframes(df_season, dates[i]) #Split each season into 7\n","    read_subset = pd.read_csv(\"data/training 1 2021-01-10 23:00:00.csv\") #First episode and season as starter\n","    read_subset.to_csv('data/training.csv',index=False)\n","    print(\"Done Configuring data\")\n","\n","\n","\n","    print(\"Starting run\")\n","    !python3 run-ds.py #can be commented out to just serve test-data to setup wand\n","    get_results()\n","    print(\"ending run\")\n","    #mae, rmse, predictions, truth = train(df_season, hyper_dick)\n","\n","\n","modelnames = [\"LSTM\", \"Queryselector\", \"TFT\"]\n","modelname = modelnames[1]\n","set_hyp_config(modelname)\n","wandb_initialize(modelname)\n"],"metadata":{"id":"qw6oG-uBzuUc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}