{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SafbhDsQWVWM",
        "outputId": "8a33d35e-46e0-4ab3-b706-9abda19b85cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'query-selector'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 112 (delta 71), reused 21 (delta 9), pack-reused 18\u001b[K\n",
            "Receiving objects: 100% (112/112), 2.08 MiB | 7.10 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.7.4.tar.gz (665 kB)\n",
            "\u001b[K     |████████████████████████████████| 665 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.9.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic->deepspeed) (4.1.1)\n",
            "Building wheels for collected packages: deepspeed, py-cpuinfo\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.7.4-py3-none-any.whl size=676700 sha256=57731c3ccfe9bb4b12e5dc08b1e33aeaf1da4e2911b7f66b280ba4bc65cdb561\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/6b/f8/bf450c749abd7dccc77d0df7f2d5c4466d3288c84bdf7b8ce1\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=669d0d89ed9af6972feb3f9284db8c61eee2780758356a9ba42d20378926a377\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "Successfully built deepspeed py-cpuinfo\n",
            "Installing collected packages: py-cpuinfo, ninja, hjson, deepspeed\n",
            "Successfully installed deepspeed-0.7.4 hjson-3.1.0 ninja-1.10.2.4 py-cpuinfo-8.0.0\n",
            "/content/query-selector\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/moraieu/query-selector.git\n",
        "!pip3 install deepspeed\n",
        "%cd query-selector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run-ds.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITvIWJvvWg8j",
        "outputId": "d0c08587-9d44-4770-a999-dc9fd76be3f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " Run   2, iteration:   3:   Loss at step 150: 0.0693359375, mean for epoch: 0.0858966064453125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 151: 0.0799560546875, mean for epoch: 0.08585726504294289, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 152: 0.09698486328125, mean for epoch: 0.08593047292608964, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:45,889] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:45,890] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=38.4631528705833, CurrSamplesPerSec=39.771515266451736, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   3:   Loss at step 153: 0.07916259765625, mean for epoch: 0.0858862384472018, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 154: 0.0849609375, mean for epoch: 0.0858802299994927, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 155: 0.0909423828125, mean for epoch: 0.08591288904989919, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 156: 0.08709716796875, mean for epoch: 0.08592048058143029, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 157: 0.0753173828125, mean for epoch: 0.08585294492685111, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 158: 0.1422119140625, mean for epoch: 0.0862096472631527, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 159: 0.08551025390625, mean for epoch: 0.08620524856279481, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 160: 0.0665283203125, mean for epoch: 0.08608226776123047, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 161: 0.09259033203125, mean for epoch: 0.08612269052067158, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 162: 0.081787109375, mean for epoch: 0.08609592767409337, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:47,227] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:47,228] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=38.460321684133156, CurrSamplesPerSec=34.632528767521435, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   3:   Loss at step 163: 0.10662841796875, mean for epoch: 0.0862218938722201, mem_alloc: 2342824960\n",
            " Run   2, iteration:   3:   Loss at step 164: 0.085205078125, mean for epoch: 0.08621569377620046, mem_alloc: 2342824960\n",
            "Loss after iteration 3 ; MSE: 0.08624267578125, MAE: 0.221923828125\n",
            "Connected by ('127.0.0.1', 55436)\n",
            "\u001b[94mReceived training result: b'3;0.08624;0.22192' \u001b[0m\n",
            "Time per iteration 22.20395803451538, memory OrderedDict([('active.all.allocated', 1110150), ('active.all.current', 7), ('active.all.freed', 1110143), ('active.all.peak', 295), ('active.large_pool.allocated', 373872), ('active.large_pool.current', 5), ('active.large_pool.freed', 373867), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 736278), ('active.small_pool.current', 2), ('active.small_pool.freed', 736276), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 3628864593408), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 3628813700608), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 3537862809088), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 3537812876800), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 91001784320), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 91000823808), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 3628864593408), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 3628819792384), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 3537862809088), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 3537818968576), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 91001784320), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 91000823808), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1110150), ('allocation.all.current', 6), ('allocation.all.freed', 1110144), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 373872), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 373868), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 736278), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 736276), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 474981), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 474977), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 247442), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 247441), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 227539), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 227536), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2197740484608), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2197728462848), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2091025660928), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2091016872960), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 106714823680), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 106711589888), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   2, iteration:   4:   Loss at step 1: 0.0841064453125, mean for epoch: 0.0841064453125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 2: 0.1275634765625, mean for epoch: 0.1058349609375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 3: 0.0697021484375, mean for epoch: 0.09379069010416667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 4: 0.09033203125, mean for epoch: 0.092926025390625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 5: 0.09942626953125, mean for epoch: 0.09422607421875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 6: 0.12127685546875, mean for epoch: 0.09873453776041667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 7: 0.064697265625, mean for epoch: 0.0938720703125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 8: 0.06439208984375, mean for epoch: 0.09018707275390625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:48,720] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:48,721] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=38.440356138106225, CurrSamplesPerSec=36.85272105197491, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 9: 0.06671142578125, mean for epoch: 0.08757866753472222, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 10: 0.139404296875, mean for epoch: 0.09276123046875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 11: 0.08544921875, mean for epoch: 0.09209650213068182, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 12: 0.101318359375, mean for epoch: 0.092864990234375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 13: 0.0777587890625, mean for epoch: 0.09170297475961539, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 14: 0.08447265625, mean for epoch: 0.0911865234375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 15: 0.0650634765625, mean for epoch: 0.08944498697916667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 16: 0.09478759765625, mean for epoch: 0.08977890014648438, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 17: 0.1138916015625, mean for epoch: 0.09119729434742647, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 18: 0.07867431640625, mean for epoch: 0.09050157335069445, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:50,055] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:50,055] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=38.43868053315947, CurrSamplesPerSec=37.88276522336025, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 19: 0.08734130859375, mean for epoch: 0.09033524362664473, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 20: 0.08245849609375, mean for epoch: 0.08994140625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 21: 0.0743408203125, mean for epoch: 0.08919852120535714, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 22: 0.08392333984375, mean for epoch: 0.088958740234375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 23: 0.084716796875, mean for epoch: 0.08877430791440218, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 24: 0.06866455078125, mean for epoch: 0.0879364013671875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 25: 0.09039306640625, mean for epoch: 0.08803466796875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 26: 0.071533203125, mean for epoch: 0.08739999624399039, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 27: 0.07818603515625, mean for epoch: 0.08705873842592593, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 28: 0.08062744140625, mean for epoch: 0.08682904924665179, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:51,383] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:51,384] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=38.440534145015114, CurrSamplesPerSec=39.52319298622537, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 29: 0.051605224609375, mean for epoch: 0.08561443460398707, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 30: 0.08868408203125, mean for epoch: 0.08571675618489584, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 31: 0.08526611328125, mean for epoch: 0.0857022193170363, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 32: 0.07049560546875, mean for epoch: 0.08522701263427734, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 33: 0.09716796875, mean for epoch: 0.08558885978929924, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 34: 0.068115234375, mean for epoch: 0.08507492963005514, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 35: 0.06805419921875, mean for epoch: 0.084588623046875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 36: 0.076171875, mean for epoch: 0.08435482449001735, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 37: 0.1448974609375, mean for epoch: 0.08599111196157094, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 38: 0.09381103515625, mean for epoch: 0.0861968994140625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:52,709] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:52,709] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=38.445097645670224, CurrSamplesPerSec=38.79275773024247, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 39: 0.11260986328125, mean for epoch: 0.08687415489783654, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 40: 0.11041259765625, mean for epoch: 0.08746261596679687, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 41: 0.07415771484375, mean for epoch: 0.08713810618330793, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 42: 0.09539794921875, mean for epoch: 0.08733476911272321, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 43: 0.0927734375, mean for epoch: 0.08746124977289244, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 44: 0.06451416015625, mean for epoch: 0.08693972500887784, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 45: 0.072265625, mean for epoch: 0.08661363389756944, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 46: 0.06890869140625, mean for epoch: 0.08622874384341032, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 47: 0.10614013671875, mean for epoch: 0.08665239050033245, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 48: 0.0938720703125, mean for epoch: 0.08680280049641927, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:54,055] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:54,056] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=38.437404399854316, CurrSamplesPerSec=38.17800181682805, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 49: 0.08612060546875, mean for epoch: 0.08678887814891581, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 50: 0.08465576171875, mean for epoch: 0.0867462158203125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 51: 0.08172607421875, mean for epoch: 0.08664778167126226, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 52: 0.1053466796875, mean for epoch: 0.08700737586388221, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 53: 0.07073974609375, mean for epoch: 0.086700439453125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 54: 0.07489013671875, mean for epoch: 0.08648173014322917, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 55: 0.07537841796875, mean for epoch: 0.08627985174005681, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 56: 0.062103271484375, mean for epoch: 0.08584812709263392, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 57: 0.0697021484375, mean for epoch: 0.08556486430921052, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 58: 0.087158203125, mean for epoch: 0.08559233566810345, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:55,395] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:55,396] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=38.43271259234166, CurrSamplesPerSec=39.27464225585285, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 59: 0.062255859375, mean for epoch: 0.08519680217161017, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 60: 0.06378173828125, mean for epoch: 0.08483988444010417, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 61: 0.055511474609375, mean for epoch: 0.08435909083632172, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 62: 0.06317138671875, mean for epoch: 0.08401735367313508, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 63: 0.0750732421875, mean for epoch: 0.08387538364955358, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 64: 0.07049560546875, mean for epoch: 0.08366632461547852, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 65: 0.07012939453125, mean for epoch: 0.08345806415264423, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 66: 0.0860595703125, mean for epoch: 0.08349748091264204, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 67: 0.0916748046875, mean for epoch: 0.08361953052122202, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 68: 0.08538818359375, mean for epoch: 0.08364554012522978, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:56,758] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:56,759] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=38.41776211841107, CurrSamplesPerSec=38.23793686912889, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 69: 0.0546875, mean for epoch: 0.08322585838428442, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 70: 0.0579833984375, mean for epoch: 0.08286525181361608, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 71: 0.07012939453125, mean for epoch: 0.08268587354203345, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 72: 0.0906982421875, mean for epoch: 0.08279715643988715, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 73: 0.0797119140625, mean for epoch: 0.08275489284567637, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 74: 0.0826416015625, mean for epoch: 0.0827533618823902, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 75: 0.08831787109375, mean for epoch: 0.08282755533854166, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 76: 0.06927490234375, mean for epoch: 0.08264923095703125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 77: 0.09893798828125, mean for epoch: 0.08286077325994318, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 78: 0.0826416015625, mean for epoch: 0.08285796336638622, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:58,106] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:58,106] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=38.411044507655284, CurrSamplesPerSec=38.688272971457245, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 79: 0.07666015625, mean for epoch: 0.08277951011174842, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 80: 0.06170654296875, mean for epoch: 0.08251609802246093, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 81: 0.061248779296875, mean for epoch: 0.08225353853202161, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 82: 0.0716552734375, mean for epoch: 0.08212429139672256, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 83: 0.07080078125, mean for epoch: 0.08198786356362951, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 84: 0.071533203125, mean for epoch: 0.0818634033203125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 85: 0.10015869140625, mean for epoch: 0.08207864200367647, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 86: 0.09759521484375, mean for epoch: 0.08225906726925872, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 87: 0.0943603515625, mean for epoch: 0.08239816249102011, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 88: 0.08209228515625, mean for epoch: 0.08239468661221591, mem_alloc: 2342824960\n",
            "[2022-10-25 13:44:59,457] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:44:59,457] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=38.40418352233693, CurrSamplesPerSec=38.85658383297883, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 89: 0.06842041015625, mean for epoch: 0.08223767227001405, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 90: 0.0897216796875, mean for epoch: 0.08232082790798612, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 91: 0.07843017578125, mean for epoch: 0.08227807348901099, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 92: 0.0770263671875, mean for epoch: 0.08222098972486414, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 93: 0.084228515625, mean for epoch: 0.0822425760248656, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 94: 0.07080078125, mean for epoch: 0.08212085480385638, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 95: 0.061431884765625, mean for epoch: 0.081903076171875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 96: 0.06842041015625, mean for epoch: 0.08176263173421223, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 97: 0.12152099609375, mean for epoch: 0.08217251177915592, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 98: 0.110595703125, mean for epoch: 0.08246254434390944, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:00,806] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:00,806] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=38.39804127498043, CurrSamplesPerSec=36.82237345750546, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 99: 0.07635498046875, mean for epoch: 0.0824008517795139, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 100: 0.07684326171875, mean for epoch: 0.08234527587890625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 101: 0.07342529296875, mean for epoch: 0.08225695921642946, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 102: 0.051605224609375, mean for epoch: 0.08195645201439951, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 103: 0.07647705078125, mean for epoch: 0.08190325394417476, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 104: 0.061279296875, mean for epoch: 0.08170494666466346, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 105: 0.08355712890625, mean for epoch: 0.08172258649553571, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 106: 0.09014892578125, mean for epoch: 0.08180208026238207, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 107: 0.07470703125, mean for epoch: 0.08173577139310748, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 108: 0.0714111328125, mean for epoch: 0.08164017288773148, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:02,134] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:02,134] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=38.402908704319614, CurrSamplesPerSec=38.4823951673872, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 109: 0.06585693359375, mean for epoch: 0.08149537252723624, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 110: 0.07879638671875, mean for epoch: 0.08147083629261363, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 111: 0.060699462890625, mean for epoch: 0.08128370680250563, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 112: 0.0899658203125, mean for epoch: 0.08136122567313057, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 113: 0.0657958984375, mean for epoch: 0.08122347941440819, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 114: 0.079833984375, mean for epoch: 0.08121129086143092, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 115: 0.07244873046875, mean for epoch: 0.08113509468410326, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 116: 0.07440185546875, mean for epoch: 0.08107704951845367, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 117: 0.0797119140625, mean for epoch: 0.0810653816940438, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 118: 0.10113525390625, mean for epoch: 0.0812354653568591, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:03,489] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:03,490] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=38.39669428645145, CurrSamplesPerSec=37.218058589791596, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 119: 0.07366943359375, mean for epoch: 0.08117188525800946, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 120: 0.06561279296875, mean for epoch: 0.08104222615559896, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 121: 0.064453125, mean for epoch: 0.08090512614604856, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 122: 0.1002197265625, mean for epoch: 0.0810634425429047, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 123: 0.0684814453125, mean for epoch: 0.08096114988249492, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 124: 0.065185546875, mean for epoch: 0.08083392727759577, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 125: 0.059783935546875, mean for epoch: 0.08066552734375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 126: 0.05718994140625, mean for epoch: 0.08047921316964286, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 127: 0.0714111328125, mean for epoch: 0.0804078109621063, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 128: 0.08319091796875, mean for epoch: 0.0804295539855957, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:04,837] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:04,837] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=38.393247888020966, CurrSamplesPerSec=36.173884245060734, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 129: 0.08941650390625, mean for epoch: 0.08049922026405039, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 130: 0.044036865234375, mean for epoch: 0.08021874060997596, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 131: 0.0762939453125, mean for epoch: 0.08018878034052958, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 132: 0.07562255859375, mean for epoch: 0.08015418775153882, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 133: 0.07122802734375, mean for epoch: 0.08008707376351033, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 134: 0.063232421875, mean for epoch: 0.07996129277926772, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 135: 0.06866455078125, mean for epoch: 0.07987761320891204, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 136: 0.06695556640625, mean for epoch: 0.07978259815889246, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 137: 0.06597900390625, mean for epoch: 0.07968184199646441, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 138: 0.0888671875, mean for epoch: 0.07974840247112772, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:06,173] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:06,174] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=38.39349700860559, CurrSamplesPerSec=40.02847790194974, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 139: 0.0948486328125, mean for epoch: 0.07985703722178507, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 140: 0.072998046875, mean for epoch: 0.07980804443359375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 141: 0.10052490234375, mean for epoch: 0.07995497250387855, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 142: 0.111328125, mean for epoch: 0.0801759101975132, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 143: 0.0633544921875, mean for epoch: 0.08005827790373689, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 144: 0.08251953125, mean for epoch: 0.08007536994086371, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 145: 0.07666015625, mean for epoch: 0.08005181674299569, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 146: 0.0682373046875, mean for epoch: 0.0799708954275471, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 147: 0.0789794921875, mean for epoch: 0.07996415118781888, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 148: 0.072021484375, mean for epoch: 0.07991048452016469, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:07,506] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:07,507] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=38.39595301276502, CurrSamplesPerSec=39.39978394626838, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 149: 0.09674072265625, mean for epoch: 0.08002343913852769, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 150: 0.07904052734375, mean for epoch: 0.08001688639322917, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 151: 0.06298828125, mean for epoch: 0.07990411417373758, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 152: 0.079345703125, mean for epoch: 0.079900440416838, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 153: 0.09991455078125, mean for epoch: 0.08003125159569036, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 154: 0.05487060546875, mean for epoch: 0.07986787077668425, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 155: 0.063720703125, mean for epoch: 0.07976369550151209, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 156: 0.07794189453125, mean for epoch: 0.07975201729016426, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 157: 0.063232421875, mean for epoch: 0.07964679693720143, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 158: 0.0694580078125, mean for epoch: 0.07958231093008307, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:08,855] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:08,855] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=38.389445610046174, CurrSamplesPerSec=39.79581690317243, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   4:   Loss at step 159: 0.0970458984375, mean for epoch: 0.07969214481377751, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 160: 0.06829833984375, mean for epoch: 0.07962093353271485, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 161: 0.0609130859375, mean for epoch: 0.07950473572156444, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 162: 0.08306884765625, mean for epoch: 0.07952673641251928, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 163: 0.083251953125, mean for epoch: 0.0795495905027799, mem_alloc: 2342824960\n",
            " Run   2, iteration:   4:   Loss at step 164: 0.0938720703125, mean for epoch: 0.07963692269674162, mem_alloc: 2342824960\n",
            "Loss after iteration 4 ; MSE: 0.07965087890625, MAE: 0.2132568359375\n",
            "Connected by ('127.0.0.1', 46102)\n",
            "\u001b[94mReceived training result: b'4;0.07965;0.21326' \u001b[0m\n",
            "Time per iteration 22.19165390729904, memory OrderedDict([('active.all.allocated', 1484398), ('active.all.current', 7), ('active.all.freed', 1484391), ('active.all.peak', 295), ('active.large_pool.allocated', 498512), ('active.large_pool.current', 5), ('active.large_pool.freed', 498507), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 985886), ('active.small_pool.current', 2), ('active.small_pool.freed', 985884), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 4838829366784), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 4838778473984), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 4717275741696), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 4717225809408), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 121553625088), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 121552664576), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 4838829366784), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 4838784565760), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 4717275741696), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 4717231901184), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 121553625088), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 121552664576), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1484398), ('allocation.all.current', 6), ('allocation.all.freed', 1484392), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 498512), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 498508), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 985886), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 985884), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 634546), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 634542), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 329934), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 329933), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 304612), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 304609), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2930653007360), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2930640985600), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2788155622400), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2788146834432), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 142497384960), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 142494151168), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   2, iteration:   5:   Loss at step 1: 0.06982421875, mean for epoch: 0.06982421875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 2: 0.06744384765625, mean for epoch: 0.068634033203125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 3: 0.0626220703125, mean for epoch: 0.06663004557291667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 4: 0.064697265625, mean for epoch: 0.0661468505859375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:10,347] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:10,348] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=38.3775677519837, CurrSamplesPerSec=37.69422261525382, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 5: 0.13916015625, mean for epoch: 0.08074951171875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 6: 0.08648681640625, mean for epoch: 0.08170572916666667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 7: 0.06463623046875, mean for epoch: 0.07926722935267858, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 8: 0.078369140625, mean for epoch: 0.07915496826171875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 9: 0.074462890625, mean for epoch: 0.07863362630208333, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 10: 0.0989990234375, mean for epoch: 0.080670166015625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 11: 0.093017578125, mean for epoch: 0.08179265802556818, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 12: 0.08880615234375, mean for epoch: 0.08237711588541667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 13: 0.07989501953125, mean for epoch: 0.08218618539663461, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 14: 0.0791015625, mean for epoch: 0.08196585518973214, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:11,695] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:11,696] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=38.37064821296999, CurrSamplesPerSec=38.143837497567304, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 15: 0.06719970703125, mean for epoch: 0.0809814453125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 16: 0.07275390625, mean for epoch: 0.08046722412109375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 17: 0.10845947265625, mean for epoch: 0.08211382697610294, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 18: 0.05975341796875, mean for epoch: 0.08087158203125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 19: 0.06011962890625, mean for epoch: 0.07977937397203948, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 20: 0.07061767578125, mean for epoch: 0.0793212890625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 21: 0.0828857421875, mean for epoch: 0.07949102492559523, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 22: 0.0811767578125, mean for epoch: 0.07956764914772728, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 23: 0.07623291015625, mean for epoch: 0.07942266049592392, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 24: 0.06524658203125, mean for epoch: 0.07883199055989583, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:13,051] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:13,052] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=38.36142426552293, CurrSamplesPerSec=36.409584210809584, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 25: 0.0850830078125, mean for epoch: 0.07908203125, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 26: 0.160400390625, mean for epoch: 0.08220966045673077, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 27: 0.07159423828125, mean for epoch: 0.0818164966724537, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 28: 0.090576171875, mean for epoch: 0.08212934221540179, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 29: 0.08367919921875, mean for epoch: 0.08218278556034483, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 30: 0.06982421875, mean for epoch: 0.08177083333333333, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 31: 0.06512451171875, mean for epoch: 0.08123385521673387, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 32: 0.064453125, mean for epoch: 0.08070945739746094, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 33: 0.0994873046875, mean for epoch: 0.08127848307291667, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 34: 0.0654296875, mean for epoch: 0.08081234202665441, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:14,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:14,385] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=38.36253359339287, CurrSamplesPerSec=39.745586039071796, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 35: 0.0706787109375, mean for epoch: 0.08052280970982142, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 36: 0.09002685546875, mean for epoch: 0.08078681098090278, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 37: 0.0802001953125, mean for epoch: 0.08077095650337837, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 38: 0.08544921875, mean for epoch: 0.08089406866776316, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 39: 0.107177734375, mean for epoch: 0.08156800881410256, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 40: 0.0830078125, mean for epoch: 0.08160400390625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 41: 0.063720703125, mean for epoch: 0.08116782583841463, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 42: 0.058746337890625, mean for epoch: 0.08063398088727679, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 43: 0.07415771484375, mean for epoch: 0.08048337004905523, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 44: 0.06341552734375, mean for epoch: 0.08009546453302557, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:15,728] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:15,728] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=38.35971895288917, CurrSamplesPerSec=39.28464787808967, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 45: 0.05615234375, mean for epoch: 0.07956339518229166, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 46: 0.08837890625, mean for epoch: 0.07975503672724185, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 47: 0.07568359375, mean for epoch: 0.07966841028091755, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 48: 0.0657958984375, mean for epoch: 0.07937939961751302, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 49: 0.067626953125, mean for epoch: 0.07913955377072704, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 50: 0.06353759765625, mean for epoch: 0.0788275146484375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 51: 0.07916259765625, mean for epoch: 0.07883408490349264, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 52: 0.09197998046875, mean for epoch: 0.07908689058743991, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 53: 0.08392333984375, mean for epoch: 0.07917814434699293, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 54: 0.0726318359375, mean for epoch: 0.0790569164134838, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:17,055] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:17,055] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=38.362618258571324, CurrSamplesPerSec=36.68543079953399, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 55: 0.10064697265625, mean for epoch: 0.079449462890625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 56: 0.064453125, mean for epoch: 0.07918167114257812, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 57: 0.06292724609375, mean for epoch: 0.0788965057908443, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 58: 0.08306884765625, mean for epoch: 0.07896844271955819, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 59: 0.073974609375, mean for epoch: 0.07888380147643008, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 60: 0.07867431640625, mean for epoch: 0.07888031005859375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 61: 0.062225341796875, mean for epoch: 0.0786072777920082, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 62: 0.08392333984375, mean for epoch: 0.07869302072832661, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 63: 0.073974609375, mean for epoch: 0.07861812531001984, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 64: 0.060302734375, mean for epoch: 0.07833194732666016, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:18,393] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:18,394] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=38.362293774903605, CurrSamplesPerSec=39.14473917531354, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 65: 0.0699462890625, mean for epoch: 0.07820293719951923, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 66: 0.083740234375, mean for epoch: 0.07828683564157198, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 67: 0.09259033203125, mean for epoch: 0.07850032066231344, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 68: 0.083984375, mean for epoch: 0.07858096852022059, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 69: 0.0672607421875, mean for epoch: 0.07841690726902174, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 70: 0.0628662109375, mean for epoch: 0.07819475446428571, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 71: 0.06390380859375, mean for epoch: 0.07799347353653169, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 72: 0.07745361328125, mean for epoch: 0.07798597547743055, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 73: 0.0650634765625, mean for epoch: 0.07780895494434932, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 74: 0.0985107421875, mean for epoch: 0.07808870882601351, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:19,786] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:19,787] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=38.34025702706857, CurrSamplesPerSec=36.01782040140557, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 75: 0.066162109375, mean for epoch: 0.0779296875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 76: 0.06378173828125, mean for epoch: 0.0777435302734375, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 77: 0.09375, mean for epoch: 0.07795140650365259, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 78: 0.046478271484375, mean for epoch: 0.07754790477263622, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 79: 0.083251953125, mean for epoch: 0.07762010791633703, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 80: 0.0841064453125, mean for epoch: 0.07770118713378907, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 81: 0.08612060546875, mean for epoch: 0.07780513057002315, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 82: 0.062286376953125, mean for epoch: 0.07761587747713415, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 83: 0.08697509765625, mean for epoch: 0.07772863916603916, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 84: 0.0625, mean for epoch: 0.07754734584263392, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:21,133] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:21,133] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=38.33710736843094, CurrSamplesPerSec=37.35482193176515, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 85: 0.07012939453125, mean for epoch: 0.07746007582720588, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 86: 0.064453125, mean for epoch: 0.07730883221293605, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 87: 0.06982421875, mean for epoch: 0.07722280217313218, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 88: 0.059783935546875, mean for epoch: 0.07702463323419745, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 89: 0.057586669921875, mean for epoch: 0.07680622915203651, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 90: 0.05511474609375, mean for epoch: 0.0765652126736111, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 91: 0.07049560546875, mean for epoch: 0.07649851369333792, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 92: 0.07623291015625, mean for epoch: 0.07649562669836957, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 93: 0.0638427734375, mean for epoch: 0.07635957451276881, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 94: 0.0625, mean for epoch: 0.07621213223071809, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:22,486] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:22,487] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=38.3329646867547, CurrSamplesPerSec=38.86335249489458, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 95: 0.07830810546875, mean for epoch: 0.07623419510690789, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 96: 0.09814453125, mean for epoch: 0.07646242777506511, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 97: 0.071044921875, mean for epoch: 0.07640657719877578, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 98: 0.10272216796875, mean for epoch: 0.07667510363520408, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 99: 0.0728759765625, mean for epoch: 0.07663672861426768, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 100: 0.05706787109375, mean for epoch: 0.0764410400390625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 101: 0.0743408203125, mean for epoch: 0.07642024578434406, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 102: 0.06988525390625, mean for epoch: 0.0763561772365196, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 103: 0.100830078125, mean for epoch: 0.07659378792475728, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 104: 0.07012939453125, mean for epoch: 0.07653163029597355, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:23,831] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:23,832] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=38.329747218230324, CurrSamplesPerSec=38.475546773663865, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 105: 0.05975341796875, mean for epoch: 0.07637183779761905, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 106: 0.06573486328125, mean for epoch: 0.07627148898142688, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 107: 0.05767822265625, mean for epoch: 0.07609772013726636, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 108: 0.05841064453125, mean for epoch: 0.07593395091869214, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 109: 0.08721923828125, mean for epoch: 0.07603748566513761, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 110: 0.06707763671875, mean for epoch: 0.07595603249289773, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 111: 0.06048583984375, mean for epoch: 0.07581666138795046, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 112: 0.07513427734375, mean for epoch: 0.07581056867327009, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 113: 0.07177734375, mean for epoch: 0.07577487641731195, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 114: 0.07281494140625, mean for epoch: 0.07574891207510964, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:25,168] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:25,169] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=38.329856055631836, CurrSamplesPerSec=38.25307215389133, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 115: 0.076416015625, mean for epoch: 0.07575471297554348, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 116: 0.07061767578125, mean for epoch: 0.07571042817214439, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 117: 0.075439453125, mean for epoch: 0.07570811214610043, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 118: 0.0848388671875, mean for epoch: 0.0757854914261123, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 119: 0.063720703125, mean for epoch: 0.07568410665047269, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 120: 0.0963134765625, mean for epoch: 0.07585601806640625, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 121: 0.11810302734375, mean for epoch: 0.07620516690340909, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 122: 0.08868408203125, mean for epoch: 0.07630745309298156, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 123: 0.0770263671875, mean for epoch: 0.07631329792301829, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 124: 0.0665283203125, mean for epoch: 0.07623438681325605, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:26,489] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:26,489] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=38.336739299769405, CurrSamplesPerSec=39.24208572380215, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 125: 0.07269287109375, mean for epoch: 0.0762060546875, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 126: 0.07659912109375, mean for epoch: 0.07620917426215278, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 127: 0.07135009765625, mean for epoch: 0.07617091381643701, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 128: 0.0631103515625, mean for epoch: 0.07606887817382812, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 129: 0.0992431640625, mean for epoch: 0.07624852380087209, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 130: 0.0721435546875, mean for epoch: 0.07621694711538461, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 131: 0.058746337890625, mean for epoch: 0.07608358368618798, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 132: 0.06280517578125, mean for epoch: 0.07598298968690814, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 133: 0.09027099609375, mean for epoch: 0.07609041830650846, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 134: 0.08477783203125, mean for epoch: 0.07615524975221548, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:27,861] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:27,862] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=38.32389461002228, CurrSamplesPerSec=38.603597218975324, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 135: 0.076171875, mean for epoch: 0.07615537290219908, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 136: 0.09295654296875, mean for epoch: 0.0762789109173943, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 137: 0.07391357421875, mean for epoch: 0.07626164568601733, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 138: 0.0865478515625, mean for epoch: 0.07633618340975996, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 139: 0.066162109375, mean for epoch: 0.07626298863253148, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 140: 0.060821533203125, mean for epoch: 0.07615269252232143, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 141: 0.08233642578125, mean for epoch: 0.07619654878656915, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 142: 0.08282470703125, mean for epoch: 0.07624322595730634, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 143: 0.0933837890625, mean for epoch: 0.07636309003496504, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 144: 0.0672607421875, mean for epoch: 0.0762998792860243, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:29,203] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:29,204] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=38.3249622385623, CurrSamplesPerSec=38.394891304745826, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 145: 0.076904296875, mean for epoch: 0.07630404768318966, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 146: 0.062744140625, mean for epoch: 0.07621117160744863, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 147: 0.0665283203125, mean for epoch: 0.0761453018707483, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 148: 0.07080078125, mean for epoch: 0.07610919024493243, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 149: 0.07421875, mean for epoch: 0.07609650272651007, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 150: 0.08782958984375, mean for epoch: 0.07617472330729166, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 151: 0.07470703125, mean for epoch: 0.07616500349234272, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 152: 0.07086181640625, mean for epoch: 0.07613011410361842, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 153: 0.05523681640625, mean for epoch: 0.07599355660232843, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 154: 0.08544921875, mean for epoch: 0.07605495700588474, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:30,574] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:30,575] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=38.31319819422682, CurrSamplesPerSec=38.85550394548395, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   2, iteration:   5:   Loss at step 155: 0.08441162109375, mean for epoch: 0.07610887096774194, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 156: 0.0875244140625, mean for epoch: 0.07618204752604167, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 157: 0.072998046875, mean for epoch: 0.07616176726711783, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 158: 0.0672607421875, mean for epoch: 0.0761054316653481, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 159: 0.093017578125, mean for epoch: 0.0762117973663522, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 160: 0.0758056640625, mean for epoch: 0.07620925903320312, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 161: 0.0765380859375, mean for epoch: 0.07621130143633541, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 162: 0.07464599609375, mean for epoch: 0.07620163905767748, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 163: 0.07159423828125, mean for epoch: 0.0761733727952454, mem_alloc: 2342824960\n",
            " Run   2, iteration:   5:   Loss at step 164: 0.0609130859375, mean for epoch: 0.076080322265625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:31,932] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:31,933] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=38.30674164199378, CurrSamplesPerSec=39.20899666270928, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            "Loss after iteration 5 ; MSE: 0.07611083984375, MAE: 0.2086181640625\n",
            "Connected by ('127.0.0.1', 50576)\n",
            "\u001b[94mReceived training result: b'5;0.07611;0.20862' \u001b[0m\n",
            "Time per iteration 22.20761079788208, memory OrderedDict([('active.all.allocated', 1858646), ('active.all.current', 7), ('active.all.freed', 1858639), ('active.all.peak', 295), ('active.large_pool.allocated', 623152), ('active.large_pool.current', 5), ('active.large_pool.freed', 623147), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 1235494), ('active.small_pool.current', 2), ('active.small_pool.freed', 1235492), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 6048794140160), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 6048743247360), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 5896688674304), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 5896638742016), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 152105465856), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 152104505344), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 6048794140160), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 6048749339136), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 5896688674304), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 5896644833792), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 152105465856), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 152104505344), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1858646), ('allocation.all.current', 6), ('allocation.all.freed', 1858640), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 623152), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 623148), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 1235494), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 1235492), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 794111), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 794107), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 412426), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 412425), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 381685), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 381682), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 3663565530112), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 3663553508352), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 3485285583872), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 3485276795904), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 178279946240), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 178276712448), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            "2342824960\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.023162841796875, mean for epoch: 0.023162841796875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 2: 0.08587646484375, mean for epoch: 0.0545196533203125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 3: 0.049163818359375, mean for epoch: 0.052734375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 4: 0.030517578125, mean for epoch: 0.04718017578125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 5: 0.0401611328125, mean for epoch: 0.0457763671875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 6: 0.07403564453125, mean for epoch: 0.050486246744791664, mem_alloc: 2342824960\n",
            "Validation set Loss at step 7: 0.063720703125, mean for epoch: 0.05237688337053571, mem_alloc: 2342824960\n",
            "Validation set Loss at step 8: 0.04510498046875, mean for epoch: 0.0514678955078125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 9: 0.0252227783203125, mean for epoch: 0.04855177137586805, mem_alloc: 2342824960\n",
            "Validation set Loss at step 10: 0.05145263671875, mean for epoch: 0.04884185791015625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 11: 0.0263824462890625, mean for epoch: 0.046800093217329544, mem_alloc: 2342824960\n",
            "Validation set Loss at step 12: 0.0211334228515625, mean for epoch: 0.04466120402018229, mem_alloc: 2342824960\n",
            "Validation set Loss at step 13: 0.030670166015625, mean for epoch: 0.043584970327524036, mem_alloc: 2342824960\n",
            "Validation set Loss at step 14: 0.01531219482421875, mean for epoch: 0.04156548636300223, mem_alloc: 2342824960\n",
            "Validation set Loss at step 15: 0.028289794921875, mean for epoch: 0.04068044026692708, mem_alloc: 2342824960\n",
            "Validation set Loss at step 16: 0.0135955810546875, mean for epoch: 0.03898763656616211, mem_alloc: 2342824960\n",
            "Validation set Loss at step 17: 0.0187530517578125, mean for epoch: 0.03779736687155331, mem_alloc: 2342824960\n",
            "Validation set Loss at step 18: 0.015899658203125, mean for epoch: 0.03658082750108507, mem_alloc: 2342824960\n",
            "Validation set Loss at step 19: 0.109619140625, mean for epoch: 0.04042494924444901, mem_alloc: 2342824960\n",
            "Validation set Loss at step 20: 0.019500732421875, mean for epoch: 0.03937873840332031, mem_alloc: 2342824960\n",
            "Validation set Loss at step 21: 0.01137542724609375, mean for epoch: 0.038045247395833336, mem_alloc: 2342824960\n",
            "Validation set Loss at step 22: 0.00577545166015625, mean for epoch: 0.0365784384987571, mem_alloc: 2342824960\n",
            "Validation set Loss at step 23: 0.0105133056640625, mean for epoch: 0.03544517185377038, mem_alloc: 2342824960\n",
            "Validation set Loss at step 24: 0.007965087890625, mean for epoch: 0.03430016835530599, mem_alloc: 2342824960\n",
            "Validation set Loss at step 25: 0.017578125, mean for epoch: 0.03363128662109375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 26: 0.055938720703125, mean for epoch: 0.03448926485501803, mem_alloc: 2342824960\n",
            "Validation set Loss at step 27: 0.03472900390625, mean for epoch: 0.03449814407913773, mem_alloc: 2342824960\n",
            "Validation set Loss at step 28: 0.053802490234375, mean for epoch: 0.03518758501325335, mem_alloc: 2342824960\n",
            "Validation set Loss at step 29: 0.010009765625, mean for epoch: 0.03431938434469289, mem_alloc: 2342824960\n",
            "Validation set Loss at step 30: 0.01116180419921875, mean for epoch: 0.033547465006510416, mem_alloc: 2342824960\n",
            "Validation set Loss at step 31: 0.0178070068359375, mean for epoch: 0.03303970829133065, mem_alloc: 2342824960\n",
            "Validation set Loss at step 32: 0.030731201171875, mean for epoch: 0.032967567443847656, mem_alloc: 2342824960\n",
            "Validation set Loss at step 33: 0.00653839111328125, mean for epoch: 0.03216668331261837, mem_alloc: 2342824960\n",
            "Validation set Loss at step 34: 0.04290771484375, mean for epoch: 0.03248259600471048, mem_alloc: 2342824960\n",
            "Validation set Loss at step 35: 0.0132598876953125, mean for epoch: 0.031933375767299106, mem_alloc: 2342824960\n",
            "Validation set Loss at step 36: 0.01085662841796875, mean for epoch: 0.03134791056315104, mem_alloc: 2342824960\n",
            "Validation set Loss at step 37: 0.08685302734375, mean for epoch: 0.03284804885451858, mem_alloc: 2342824960\n",
            "Validation set Loss at step 38: 0.06634521484375, mean for epoch: 0.03372955322265625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 39: 0.04931640625, mean for epoch: 0.03412921612079327, mem_alloc: 2342824960\n",
            "Validation set Loss at step 40: 0.03338623046875, mean for epoch: 0.034110641479492186, mem_alloc: 2342824960\n",
            "Validation set Loss at step 41: 0.037078857421875, mean for epoch: 0.03418303699028201, mem_alloc: 2342824960\n",
            "Validation set Loss at step 42: 0.0206451416015625, mean for epoch: 0.03386070614769345, mem_alloc: 2342824960\n",
            "Validation set Loss at step 43: 0.0135040283203125, mean for epoch: 0.03338729503542878, mem_alloc: 2342824960\n",
            "Validation set Loss at step 44: 0.015838623046875, mean for epoch: 0.03298846158114346, mem_alloc: 2342824960\n",
            "Validation set Loss at step 45: 0.01763916015625, mean for epoch: 0.03264736599392361, mem_alloc: 2342824960\n",
            "Validation set Loss at step 46: 0.043609619140625, mean for epoch: 0.03288567584493886, mem_alloc: 2342824960\n",
            "Validation set Loss at step 47: 0.01119232177734375, mean for epoch: 0.03242411512009641, mem_alloc: 2342824960\n",
            "Validation set Loss at step 48: 0.048858642578125, mean for epoch: 0.032766501108805336, mem_alloc: 2342824960\n",
            "Validation set Loss at step 49: 0.0181732177734375, mean for epoch: 0.03246867899992028, mem_alloc: 2342824960\n",
            "Validation set Loss at step 50: 0.020263671875, mean for epoch: 0.03222457885742187, mem_alloc: 2342824960\n",
            "Validation set Loss at step 51: 0.056549072265625, mean for epoch: 0.03270152970856311, mem_alloc: 2342824960\n",
            "Validation set Loss at step 52: 0.028778076171875, mean for epoch: 0.03262607867901142, mem_alloc: 2342824960\n",
            "Validation set Loss at step 53: 0.0535888671875, mean for epoch: 0.03302160299049234, mem_alloc: 2342824960\n",
            "Validation set Loss at step 54: 0.375244140625, mean for epoch: 0.039359057391131366, mem_alloc: 2342824960\n",
            "Validation set Loss at step 55: 0.1156005859375, mean for epoch: 0.040745267001065344, mem_alloc: 2342824960\n",
            "Validation set Loss at step 56: 0.1343994140625, mean for epoch: 0.042417662484305244, mem_alloc: 2342824960\n",
            "Validation set Loss at step 57: 0.148681640625, mean for epoch: 0.04428194280256305, mem_alloc: 2342824960\n",
            "Validation set Loss at step 58: 0.08172607421875, mean for epoch: 0.04492753127525593, mem_alloc: 2342824960\n",
            "Validation set Loss at step 59: 0.053680419921875, mean for epoch: 0.045075885320113876, mem_alloc: 2342824960\n",
            "Validation set Loss at step 60: 0.05224609375, mean for epoch: 0.045195388793945315, mem_alloc: 2342824960\n",
            "Validation set Loss at step 61: 0.07720947265625, mean for epoch: 0.04572020984086834, mem_alloc: 2342824960\n",
            "Validation set Loss at step 62: 0.0247039794921875, mean for epoch: 0.045381238383631554, mem_alloc: 2342824960\n",
            "Validation set Loss at step 63: 0.019439697265625, mean for epoch: 0.04496946788969494, mem_alloc: 2342824960\n",
            "Validation set Loss at step 64: 0.036468505859375, mean for epoch: 0.04483664035797119, mem_alloc: 2342824960\n",
            "Validation set Loss at step 65: 0.0211334228515625, mean for epoch: 0.04447197547325721, mem_alloc: 2342824960\n",
            "Validation set Loss at step 66: 0.0081634521484375, mean for epoch: 0.04392184633197206, mem_alloc: 2342824960\n",
            "Validation set Loss at step 67: 0.02093505859375, mean for epoch: 0.0435787599478195, mem_alloc: 2342824960\n",
            "Validation set Loss at step 68: 0.0257720947265625, mean for epoch: 0.04331689722397748, mem_alloc: 2342824960\n",
            "Validation set Loss at step 69: 0.138427734375, mean for epoch: 0.044695315153702446, mem_alloc: 2342824960\n",
            "Validation set Loss at step 70: 0.314208984375, mean for epoch: 0.04854551042829241, mem_alloc: 2342824960\n",
            "Validation set Loss at step 71: 0.206298828125, mean for epoch: 0.05076738814233055, mem_alloc: 2342824960\n",
            "Validation set Loss at step 72: 0.262451171875, mean for epoch: 0.05370744069417318, mem_alloc: 2342824960\n",
            "Validation set Loss at step 73: 0.12152099609375, mean for epoch: 0.05463639350786601, mem_alloc: 2342824960\n",
            "Validation set Loss at step 74: 0.08026123046875, mean for epoch: 0.054982675088418496, mem_alloc: 2342824960\n",
            "Validation set Loss at step 75: 0.07318115234375, mean for epoch: 0.05522532145182291, mem_alloc: 2342824960\n",
            "Validation set Loss at step 76: 0.048858642578125, mean for epoch: 0.05514154936137952, mem_alloc: 2342824960\n",
            "Validation set Loss at step 77: 0.11370849609375, mean for epoch: 0.05590215905920252, mem_alloc: 2342824960\n",
            "Validation set Loss at step 78: 0.034423828125, mean for epoch: 0.05562679584209736, mem_alloc: 2342824960\n",
            "Validation set Loss at step 79: 0.06683349609375, mean for epoch: 0.055768652807308146, mem_alloc: 2342824960\n",
            "Validation set Loss at step 80: 0.03350830078125, mean for epoch: 0.05549039840698242, mem_alloc: 2342824960\n",
            "Validation set Loss at step 81: 0.04254150390625, mean for epoch: 0.05533053551191165, mem_alloc: 2342824960\n",
            "Validation set Loss at step 82: 0.04620361328125, mean for epoch: 0.055219231582269435, mem_alloc: 2342824960\n",
            "Validation set Loss at step 83: 0.04583740234375, mean for epoch: 0.05510619749505836, mem_alloc: 2342824960\n",
            "Validation set Loss at step 84: 0.035797119140625, mean for epoch: 0.05487632751464844, mem_alloc: 2342824960\n",
            "Validation set Loss at step 85: 0.01183319091796875, mean for epoch: 0.054369937672334556, mem_alloc: 2342824960\n",
            "Validation set Loss at step 86: 0.071044921875, mean for epoch: 0.054563832837481833, mem_alloc: 2342824960\n",
            "Validation set Loss at step 87: 0.0280609130859375, mean for epoch: 0.05425920157596983, mem_alloc: 2342824960\n",
            "Validation set Loss at step 88: 0.06011962890625, mean for epoch: 0.05432579734108665, mem_alloc: 2342824960\n",
            "Validation set Loss at step 89: 0.07080078125, mean for epoch: 0.05451090951983848, mem_alloc: 2342824960\n",
            "Loss for validation set  ; MSE: 0.05450439453125, MAE: 0.1806640625\n",
            "Connected by ('127.0.0.1', 50582)\n",
            "\u001b[94mReceived result: b'0.05450;0.18066' \u001b[0m\n",
            "Iteration  1| MSE 0.0688 | MAE 0.2087\n",
            "Iteration  2| MSE 0.0545 | MAE 0.1807\n",
            "Mean        | MSE 0.0616 | MAE 0.1947\n",
            "[2022-10-25 13:45:37,422] [INFO] [launch.py:318:main] Process 448 exits successfully.\n",
            "[2022-10-25 13:45:38,682] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-25 13:45:38,682] [INFO] [runner.py:507:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --deepspeed_config settings/ds_config_zero.json --data ETTh1 --seq_len 720 --pred_len 24 --dec_seq_len 48 --hidden_size 312 --n_encoder_layers 3 --n_decoder_layers 3 --encoder_attention query_selector_0.8 --decoder_attention full --n_heads 4 --batch_size 48 --embedding_size 96 --iterations 5 --exps 5 --dropout 0.1 --fp16 --deepspeed --features S --input_len 1 --output_len 1 --run_num 3\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-25 13:45:40,538] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Number of parameters: 177\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([24, 4608])\n",
            "torch.Size([24])\n",
            "[2022-10-25 13:45:42,704] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.4, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-25 13:45:42,706] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-25 13:45:42,718] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2022-10-25 13:45:44,538] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.23226571083068848 seconds\n",
            "[2022-10-25 13:45:45,540] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2022-10-25 13:45:45,546] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2022-10-25 13:45:45,546] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2022-10-25 13:45:45,546] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "[2022-10-25 13:45:45,547] [INFO] [stage_1_and_2.py:140:__init__] Reduce bucket size 500000000\n",
            "[2022-10-25 13:45:45,547] [INFO] [stage_1_and_2.py:141:__init__] Allgather bucket size 500000000\n",
            "[2022-10-25 13:45:45,547] [INFO] [stage_1_and_2.py:142:__init__] CPU Offload: False\n",
            "[2022-10-25 13:45:45,547] [INFO] [stage_1_and_2.py:143:__init__] Round robin gradient partitioning: False\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.24680423736572266 seconds\n",
            "Rank: 0 partition count [1] and sizes[(3045720, False)] \n",
            "[2022-10-25 13:45:45,984] [INFO] [utils.py:827:see_memory_usage] Before initializing optimizer states\n",
            "[2022-10-25 13:45:45,985] [INFO] [utils.py:832:see_memory_usage] MA 0.02 GB         Max_MA 0.02 GB         CA 0.04 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:45:45,985] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:45:46,046] [INFO] [utils.py:827:see_memory_usage] After initializing optimizer states\n",
            "[2022-10-25 13:45:46,047] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.05 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:45:46,047] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:45:46,047] [INFO] [stage_1_and_2.py:523:__init__] optimizer state initialized\n",
            "[2022-10-25 13:45:46,095] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-25 13:45:46,095] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.04 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:45:46,096] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:45:46,102] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2022-10-25 13:45:46,102] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2022-10-25 13:45:46,102] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2022-10-25 13:45:46,102] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:46,103] [INFO] [config.py:1002:print] DeepSpeedEngine configuration:\n",
            "[2022-10-25 13:45:46,103] [INFO] [config.py:1006:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-25 13:45:46,103] [INFO] [config.py:1006:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-25 13:45:46,103] [INFO] [config.py:1006:print]   amp_enabled .................. False\n",
            "[2022-10-25 13:45:46,103] [INFO] [config.py:1006:print]   amp_params ................... False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   bfloat16_enabled ............. False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f68522c8750>\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   communication_data_type ...... None\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   curriculum_enabled ........... False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   curriculum_params ............ False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   dataloader_drop_last ......... False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   disable_allgather ............ False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   dump_state ................... False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-25 13:45:46,104] [INFO] [config.py:1006:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   elasticity_enabled ........... False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   fp16_auto_cast ............... False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   fp16_enabled ................. True\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   global_rank .................. 0\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   gradient_accumulation_steps .. 1\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   gradient_clipping ............ 0.0\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   load_universal_checkpoint .... False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   loss_scale ................... 0\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   memory_breakdown ............. False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f684e341790>\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   optimizer_name ............... adam\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}\n",
            "[2022-10-25 13:45:46,105] [INFO] [config.py:1006:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   pld_enabled .................. False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   pld_params ................... False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   prescale_gradients ........... False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   scheduler_name ............... None\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   scheduler_params ............. None\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   sparse_attention ............. None\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   steps_per_print .............. 10\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   train_batch_size ............. 5\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   train_micro_batch_size_per_gpu  5\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   world_size ................... 1\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=False allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=False prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   zero_enabled ................. True\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:1006:print]   zero_optimization_stage ...... 2\n",
            "[2022-10-25 13:45:46,106] [INFO] [config.py:997:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 5, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 5e-05, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": false, \n",
            "        \"cpu_offload\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 1000\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0005102157592773438 seconds\n",
            "train 7897\n",
            " Run   3, iteration:   1:   Loss at step 1: 0.962890625, mean for epoch: 0.962890625, mem_alloc: 1323024896\n",
            "[2022-10-25 13:45:46,993] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 4294967296\n",
            " Run   3, iteration:   1:   Loss at step 2: 0.8701171875, mean for epoch: 0.91650390625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,122] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
            " Run   3, iteration:   1:   Loss at step 3: 0.896484375, mean for epoch: 0.9098307291666666, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,241] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
            " Run   3, iteration:   1:   Loss at step 4: 0.87646484375, mean for epoch: 0.9014892578125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,358] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
            " Run   3, iteration:   1:   Loss at step 5: 0.96142578125, mean for epoch: 0.9134765625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,480] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
            " Run   3, iteration:   1:   Loss at step 6: 0.85693359375, mean for epoch: 0.904052734375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,596] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
            " Run   3, iteration:   1:   Loss at step 7: 1.0400390625, mean for epoch: 0.9234793526785714, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,715] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
            " Run   3, iteration:   1:   Loss at step 8: 0.994140625, mean for epoch: 0.93231201171875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,832] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
            " Run   3, iteration:   1:   Loss at step 9: 1.0234375, mean for epoch: 0.9424370659722222, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:47,949] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
            " Run   3, iteration:   1:   Loss at step 10: 0.76025390625, mean for epoch: 0.92421875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,064] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
            "[2022-10-25 13:45:48,065] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=10, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:48,065] [INFO] [timer.py:207:stop] 0/10, RunningAvgSamplesPerSec=43.37816314964278, CurrSamplesPerSec=44.5345027128614, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 11: 0.75927734375, mean for epoch: 0.9092240767045454, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,184] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
            " Run   3, iteration:   1:   Loss at step 12: 0.9560546875, mean for epoch: 0.9131266276041666, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,296] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
            " Run   3, iteration:   1:   Loss at step 13: 0.9697265625, mean for epoch: 0.91748046875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,416] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
            " Run   3, iteration:   1:   Loss at step 14: 1.00390625, mean for epoch: 0.9236537388392857, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,528] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
            " Run   3, iteration:   1:   Loss at step 15: 1.03515625, mean for epoch: 0.9310872395833333, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,647] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            " Run   3, iteration:   1:   Loss at step 16: 0.8115234375, mean for epoch: 0.923614501953125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,767] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            " Run   3, iteration:   1:   Loss at step 17: 0.9033203125, mean for epoch: 0.9224207261029411, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,888] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            " Run   3, iteration:   1:   Loss at step 18: 0.7490234375, mean for epoch: 0.9127875434027778, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:48,999] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            " Run   3, iteration:   1:   Loss at step 19: 0.8896484375, mean for epoch: 0.9115696957236842, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 20: 0.74755859375, mean for epoch: 0.903369140625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:49,261] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:49,262] [INFO] [timer.py:207:stop] 0/20, RunningAvgSamplesPerSec=43.11021063269293, CurrSamplesPerSec=39.77822920993682, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 21: 0.440185546875, mean for epoch: 0.8813127790178571, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 22: 0.52685546875, mean for epoch: 0.8652010830965909, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 23: 0.42529296875, mean for epoch: 0.8460746433423914, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 24: 0.265869140625, mean for epoch: 0.8218994140625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 25: 0.2081298828125, mean for epoch: 0.7973486328125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 26: 0.185546875, mean for epoch: 0.7738177959735577, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 27: 0.1976318359375, mean for epoch: 0.7524775752314815, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 28: 0.2335205078125, mean for epoch: 0.7339433942522321, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 29: 0.212158203125, mean for epoch: 0.7159508014547413, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 30: 0.19921875, mean for epoch: 0.6987263997395833, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:50,588] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:50,588] [INFO] [timer.py:207:stop] 0/30, RunningAvgSamplesPerSec=41.434338784361884, CurrSamplesPerSec=39.40970532246153, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 31: 0.2099609375, mean for epoch: 0.6829597719254032, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 32: 0.1602783203125, mean for epoch: 0.6666259765625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 33: 0.2220458984375, mean for epoch: 0.6531538529829546, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 34: 0.1912841796875, mean for epoch: 0.6395694508272058, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 35: 0.177490234375, mean for epoch: 0.6263671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 36: 0.1688232421875, mean for epoch: 0.6136576334635416, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 37: 0.161865234375, mean for epoch: 0.6014470280827703, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 38: 0.161376953125, mean for epoch: 0.5898662366365132, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 39: 0.1468505859375, mean for epoch: 0.5785068609775641, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 40: 0.169921875, mean for epoch: 0.568292236328125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:51,929] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:51,930] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=40.52742761840176, CurrSamplesPerSec=39.86207997688661, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 41: 0.358154296875, mean for epoch: 0.5631669207317073, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 42: 0.200927734375, mean for epoch: 0.5545421781994048, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 43: 0.149169921875, mean for epoch: 0.5451149164244186, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 44: 0.2020263671875, mean for epoch: 0.5373174493963068, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 45: 0.2021484375, mean for epoch: 0.5298692491319444, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 46: 0.1365966796875, mean for epoch: 0.5213198454483695, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 47: 0.174072265625, mean for epoch: 0.513931599069149, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 48: 0.12359619140625, mean for epoch: 0.5057996114095052, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 49: 0.126953125, mean for epoch: 0.49806805046237246, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 50: 0.10357666015625, mean for epoch: 0.49017822265625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:53,266] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:53,266] [INFO] [timer.py:207:stop] 0/50, RunningAvgSamplesPerSec=40.07185469129878, CurrSamplesPerSec=39.31919169950841, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 51: 0.1448974609375, mean for epoch: 0.48340801164215685, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 52: 0.1431884765625, mean for epoch: 0.47686532827524036, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 53: 0.1409912109375, mean for epoch: 0.4705280807783019, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 54: 0.146728515625, mean for epoch: 0.4645317925347222, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 55: 0.11444091796875, mean for epoch: 0.45816650390625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 56: 0.121337890625, mean for epoch: 0.4521517072405134, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 57: 0.1385498046875, mean for epoch: 0.44664991947642546, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 58: 0.12353515625, mean for epoch: 0.4410789752828664, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 59: 0.135009765625, mean for epoch: 0.4358913615598517, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 60: 0.1253662109375, mean for epoch: 0.4307159423828125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:54,607] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:54,608] [INFO] [timer.py:207:stop] 0/60, RunningAvgSamplesPerSec=39.7382833061779, CurrSamplesPerSec=38.54541578060297, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 61: 0.1248779296875, mean for epoch: 0.4257022044697746, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 62: 0.1749267578125, mean for epoch: 0.4216574392011089, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 63: 0.10467529296875, mean for epoch: 0.4166259765625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 64: 0.191162109375, mean for epoch: 0.4131031036376953, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 65: 0.15185546875, mean for epoch: 0.4090839092548077, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 66: 0.10565185546875, mean for epoch: 0.4044864538944129, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 67: 0.10833740234375, mean for epoch: 0.4000663187966418, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 68: 0.11224365234375, mean for epoch: 0.39583363252527576, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 69: 0.1453857421875, mean for epoch: 0.392203952955163, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 70: 0.1231689453125, mean for epoch: 0.388360595703125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:55,957] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:55,957] [INFO] [timer.py:207:stop] 0/70, RunningAvgSamplesPerSec=39.49365731242149, CurrSamplesPerSec=36.37787927305023, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 71: 0.1732177734375, mean for epoch: 0.3853304151078345, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 72: 0.152099609375, mean for epoch: 0.38209109836154515, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 73: 0.10467529296875, mean for epoch: 0.3782908818493151, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 74: 0.127197265625, mean for epoch: 0.3748977248733108, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 75: 0.1168212890625, mean for epoch: 0.37145670572916667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 76: 0.12371826171875, mean for epoch: 0.3681969893606086, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 77: 0.1256103515625, mean for epoch: 0.3650465135450487, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 78: 0.1663818359375, mean for epoch: 0.3624995304987981, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 79: 0.0994873046875, mean for epoch: 0.3591702618176424, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 80: 0.10858154296875, mean for epoch: 0.35603790283203124, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:57,287] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:57,288] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=39.36818410727597, CurrSamplesPerSec=39.046856555560936, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 81: 0.10882568359375, mean for epoch: 0.3529859001253858, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 82: 0.10125732421875, mean for epoch: 0.34991603944359756, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 83: 0.09832763671875, mean for epoch: 0.3468848538685994, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 84: 0.09423828125, mean for epoch: 0.3438771565755208, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 85: 0.12091064453125, mean for epoch: 0.3412540211397059, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 86: 0.1676025390625, mean for epoch: 0.33923481785973836, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 87: 0.10565185546875, mean for epoch: 0.33654995622306033, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 88: 0.125732421875, mean for epoch: 0.3341543024236506, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 89: 0.1009521484375, mean for epoch: 0.33153405350245785, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 90: 0.09454345703125, mean for epoch: 0.32890082465277776, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:58,637] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:58,637] [INFO] [timer.py:207:stop] 0/90, RunningAvgSamplesPerSec=39.22241047956641, CurrSamplesPerSec=39.08418798560494, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 91: 0.10699462890625, mean for epoch: 0.32646229502918955, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 92: 0.1334228515625, mean for epoch: 0.3243640402088995, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 93: 0.1151123046875, mean for epoch: 0.32211402154737906, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 94: 0.1678466796875, mean for epoch: 0.3204728796126995, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 95: 0.1396484375, mean for epoch: 0.3185694644325658, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 96: 0.130126953125, mean for epoch: 0.3166065216064453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 97: 0.1258544921875, mean for epoch: 0.3146400058392397, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 98: 0.141845703125, mean for epoch: 0.31287679866868623, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 99: 0.1453857421875, mean for epoch: 0.3111849698153409, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 100: 0.1376953125, mean for epoch: 0.3094500732421875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:45:59,978] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:45:59,979] [INFO] [timer.py:207:stop] 0/100, RunningAvgSamplesPerSec=39.1165246345099, CurrSamplesPerSec=36.938533591901944, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 101: 0.1324462890625, mean for epoch: 0.3076975605275371, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 102: 0.1436767578125, mean for epoch: 0.30608951344209556, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 103: 0.10821533203125, mean for epoch: 0.30416840488470875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 104: 0.1572265625, mean for epoch: 0.30275550255408656, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 105: 0.1060791015625, mean for epoch: 0.3008823939732143, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 106: 0.09503173828125, mean for epoch: 0.2989404066553656, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 107: 0.0972900390625, mean for epoch: 0.29705582378066586, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 108: 0.099853515625, mean for epoch: 0.29522987648292826, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 109: 0.110107421875, mean for epoch: 0.29353150533973627, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 110: 0.177734375, mean for epoch: 0.2924788041548295, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:01,333] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:01,333] [INFO] [timer.py:207:stop] 0/110, RunningAvgSamplesPerSec=39.0110678363696, CurrSamplesPerSec=37.08117837812988, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 111: 0.12445068359375, mean for epoch: 0.29096503730292794, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 112: 0.1263427734375, mean for epoch: 0.2894951956612723, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 113: 0.10369873046875, mean for epoch: 0.2878509791551438, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 114: 0.11236572265625, mean for epoch: 0.28631163479989036, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 115: 0.12164306640625, mean for epoch: 0.28487973420516305, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 116: 0.1070556640625, mean for epoch: 0.28334676808324355, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 117: 0.1307373046875, mean for epoch: 0.28204241369524574, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 118: 0.11578369140625, mean for epoch: 0.2806334414724576, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 119: 0.091552734375, mean for epoch: 0.27904452796743695, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 120: 0.16455078125, mean for epoch: 0.27809041341145835, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:02,676] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:02,676] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=38.94882038623061, CurrSamplesPerSec=39.31078953287846, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 121: 0.10540771484375, mean for epoch: 0.27666328367122933, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 122: 0.0888671875, mean for epoch: 0.27512397140753075, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 123: 0.12432861328125, mean for epoch: 0.2738979928861789, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 124: 0.10784912109375, mean for epoch: 0.2725588890814012, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 125: 0.107177734375, mean for epoch: 0.27123583984375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 126: 0.10986328125, mean for epoch: 0.2699551052517361, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 127: 0.1180419921875, mean for epoch: 0.2687589390071358, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 128: 0.1463623046875, mean for epoch: 0.26780271530151367, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 129: 0.11163330078125, mean for epoch: 0.2665920996850775, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 130: 0.09210205078125, mean for epoch: 0.2652498685396635, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:04,030] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:04,031] [INFO] [timer.py:207:stop] 0/130, RunningAvgSamplesPerSec=38.87964306133851, CurrSamplesPerSec=35.30951250475642, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 131: 0.09454345703125, mean for epoch: 0.2639467661617366, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 132: 0.09344482421875, mean for epoch: 0.2626550847833807, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 133: 0.11749267578125, mean for epoch: 0.2615636380991541, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 134: 0.12939453125, mean for epoch: 0.2605773014808769, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 135: 0.11529541015625, mean for epoch: 0.2595011393229167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 136: 0.105224609375, mean for epoch: 0.25836675307329965, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 137: 0.09246826171875, mean for epoch: 0.25715581518020075, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 138: 0.12005615234375, mean for epoch: 0.2561623393625453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 139: 0.08575439453125, mean for epoch: 0.25493638292491005, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 140: 0.09149169921875, mean for epoch: 0.2537689208984375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:05,366] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:05,367] [INFO] [timer.py:207:stop] 0/140, RunningAvgSamplesPerSec=38.84838340792517, CurrSamplesPerSec=35.1805029927262, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 141: 0.09259033203125, mean for epoch: 0.25262581033909576, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 142: 0.08673095703125, mean for epoch: 0.25145753672425175, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 143: 0.1517333984375, mean for epoch: 0.2507601651278409, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 144: 0.122802734375, mean for epoch: 0.24987157185872397, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 145: 0.07818603515625, mean for epoch: 0.24868753367456897, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 146: 0.09405517578125, mean for epoch: 0.24762840793557364, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 147: 0.08868408203125, mean for epoch: 0.24654715401785715, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 148: 0.09088134765625, mean for epoch: 0.24549535802892736, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 149: 0.0972900390625, mean for epoch: 0.2445006914586829, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 150: 0.07708740234375, mean for epoch: 0.24338460286458333, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:06,714] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:06,715] [INFO] [timer.py:207:stop] 0/150, RunningAvgSamplesPerSec=38.801802823654306, CurrSamplesPerSec=38.91260420938177, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 151: 0.11578369140625, mean for epoch: 0.24253956371585264, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 152: 0.11614990234375, mean for epoch: 0.24170805278577304, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 153: 0.0953369140625, mean for epoch: 0.2407513786764706, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 154: 0.153564453125, mean for epoch: 0.24018522980925325, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 155: 0.0933837890625, mean for epoch: 0.23923812373991934, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 156: 0.0770263671875, mean for epoch: 0.23819830478766027, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 157: 0.1162109375, mean for epoch: 0.2374213151871019, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 158: 0.1427001953125, mean for epoch: 0.2368218144284019, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 159: 0.08074951171875, mean for epoch: 0.23584022761890724, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 160: 0.1007080078125, mean for epoch: 0.23499565124511718, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:08,049] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:08,050] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=38.7769483101373, CurrSamplesPerSec=35.87156277154019, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   1:   Loss at step 161: 0.095703125, mean for epoch: 0.2341304802746506, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 162: 0.1009521484375, mean for epoch: 0.23330839180652005, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 163: 0.1112060546875, mean for epoch: 0.23255929771376535, mem_alloc: 2342824960\n",
            " Run   3, iteration:   1:   Loss at step 164: 0.10540771484375, mean for epoch: 0.23178398318407012, mem_alloc: 2342824960\n",
            "Loss after iteration 1 ; MSE: 0.2318115234375, MAE: 0.34130859375\n",
            "Connected by ('127.0.0.1', 33742)\n",
            "\u001b[94mReceived training result: b'1;0.23181;0.34131' \u001b[0m\n",
            "Time per iteration 22.376254320144653, memory OrderedDict([('active.all.allocated', 361654), ('active.all.current', 7), ('active.all.freed', 361647), ('active.all.peak', 295), ('active.large_pool.allocated', 124592), ('active.large_pool.current', 5), ('active.large_pool.freed', 124587), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 237062), ('active.small_pool.current', 2), ('active.small_pool.freed', 237060), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 1208935046656), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 1208884153856), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 1179036943872), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 1178987011584), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 29898102784), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 29897142272), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 1208935046656), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 1208890245632), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 1179036943872), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 1178993103360), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 29898102784), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 29897142272), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 361654), ('allocation.all.current', 6), ('allocation.all.freed', 361648), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 124592), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 124588), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 237062), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 237060), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 155851), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 155847), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 82458), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 82457), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 73393), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 73390), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 731915439104), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 731903417344), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 696765737984), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 696756950016), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 35149701120), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 35146467328), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   3, iteration:   2:   Loss at step 1: 0.09222412109375, mean for epoch: 0.09222412109375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 2: 0.1234130859375, mean for epoch: 0.107818603515625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 3: 0.1512451171875, mean for epoch: 0.12229410807291667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 4: 0.0780029296875, mean for epoch: 0.1112213134765625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 5: 0.091064453125, mean for epoch: 0.10718994140625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 6: 0.08544921875, mean for epoch: 0.10356648763020833, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:09,511] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:09,512] [INFO] [timer.py:207:stop] 0/170, RunningAvgSamplesPerSec=38.74933076803441, CurrSamplesPerSec=39.79317398242548, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 7: 0.06866455078125, mean for epoch: 0.09858049665178571, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 8: 0.11932373046875, mean for epoch: 0.10117340087890625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 9: 0.10699462890625, mean for epoch: 0.10182020399305555, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 10: 0.0975341796875, mean for epoch: 0.1013916015625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 11: 0.1015625, mean for epoch: 0.10140713778409091, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 12: 0.097900390625, mean for epoch: 0.10111490885416667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 13: 0.10467529296875, mean for epoch: 0.10138878455528846, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 14: 0.0831298828125, mean for epoch: 0.10008457728794642, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 15: 0.10272216796875, mean for epoch: 0.10026041666666667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 16: 0.088134765625, mean for epoch: 0.0995025634765625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:10,839] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:10,839] [INFO] [timer.py:207:stop] 0/180, RunningAvgSamplesPerSec=38.74581340480825, CurrSamplesPerSec=38.72384898608849, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 17: 0.1181640625, mean for epoch: 0.1006002987132353, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 18: 0.0975341796875, mean for epoch: 0.1004299587673611, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 19: 0.08917236328125, mean for epoch: 0.09983745374177631, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 20: 0.112060546875, mean for epoch: 0.1004486083984375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 21: 0.0880126953125, mean for epoch: 0.0998564220610119, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 22: 0.07269287109375, mean for epoch: 0.09862171519886363, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 23: 0.0899658203125, mean for epoch: 0.09824537194293478, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 24: 0.1148681640625, mean for epoch: 0.09893798828125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 25: 0.1324462890625, mean for epoch: 0.1002783203125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 26: 0.061981201171875, mean for epoch: 0.09880535419170673, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:12,184] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:12,184] [INFO] [timer.py:207:stop] 0/190, RunningAvgSamplesPerSec=38.70996099633292, CurrSamplesPerSec=36.462633291083556, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 27: 0.08270263671875, mean for epoch: 0.0982089572482639, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 28: 0.087890625, mean for epoch: 0.09784044538225446, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 29: 0.09625244140625, mean for epoch: 0.0977856866244612, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 30: 0.10675048828125, mean for epoch: 0.09808451334635417, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 31: 0.0645751953125, mean for epoch: 0.09700356760332661, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 32: 0.0931396484375, mean for epoch: 0.09688282012939453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 33: 0.100341796875, mean for epoch: 0.09698763760653409, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 34: 0.0765380859375, mean for epoch: 0.09638618020450368, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 35: 0.10125732421875, mean for epoch: 0.09652535574776785, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 36: 0.1072998046875, mean for epoch: 0.09682464599609375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:13,530] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:13,530] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=38.67749121260356, CurrSamplesPerSec=39.14459304333218, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 37: 0.1341552734375, mean for epoch: 0.09783358187288851, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 38: 0.0994873046875, mean for epoch: 0.09787710089432566, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 39: 0.10687255859375, mean for epoch: 0.09810775365584935, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 40: 0.1031494140625, mean for epoch: 0.09823379516601563, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 41: 0.087890625, mean for epoch: 0.09798152272294207, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 42: 0.091796875, mean for epoch: 0.09783426920572917, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 43: 0.080322265625, mean for epoch: 0.09742701330850291, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 44: 0.1007080078125, mean for epoch: 0.09750158136541193, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 45: 0.07861328125, mean for epoch: 0.09708184136284723, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 46: 0.10589599609375, mean for epoch: 0.09727345342221468, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:14,856] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:14,856] [INFO] [timer.py:207:stop] 0/210, RunningAvgSamplesPerSec=38.67308970374182, CurrSamplesPerSec=39.53474167606107, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 47: 0.08673095703125, mean for epoch: 0.09704914498836437, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 48: 0.0772705078125, mean for epoch: 0.09663709004720052, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 49: 0.0811767578125, mean for epoch: 0.09632157306281888, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 50: 0.12744140625, mean for epoch: 0.0969439697265625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 51: 0.11187744140625, mean for epoch: 0.09723678289675246, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 52: 0.096923828125, mean for epoch: 0.09723076453575721, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 53: 0.0762939453125, mean for epoch: 0.09683573021079009, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 54: 0.0970458984375, mean for epoch: 0.09683962221498843, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 55: 0.1182861328125, mean for epoch: 0.09722955877130682, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 56: 0.09832763671875, mean for epoch: 0.09724916730608259, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:16,199] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:16,199] [INFO] [timer.py:207:stop] 0/220, RunningAvgSamplesPerSec=38.648406585860535, CurrSamplesPerSec=36.19654837334456, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 57: 0.0714111328125, mean for epoch: 0.09679586845531798, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 58: 0.119140625, mean for epoch: 0.09718112287850215, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 59: 0.0885009765625, mean for epoch: 0.09703400175450212, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 60: 0.07293701171875, mean for epoch: 0.09663238525390624, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 61: 0.09228515625, mean for epoch: 0.09656111920466189, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 62: 0.107177734375, mean for epoch: 0.09673235493321572, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 63: 0.0977783203125, mean for epoch: 0.09674895755828374, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 64: 0.08843994140625, mean for epoch: 0.0966191291809082, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 65: 0.091796875, mean for epoch: 0.09654494065504808, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 66: 0.123046875, mean for epoch: 0.09694648511482007, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:17,524] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:17,524] [INFO] [timer.py:207:stop] 0/230, RunningAvgSamplesPerSec=38.651959880848494, CurrSamplesPerSec=38.90329234901719, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 67: 0.09722900390625, mean for epoch: 0.09695070181319963, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 68: 0.08990478515625, mean for epoch: 0.09684708539177389, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 69: 0.10162353515625, mean for epoch: 0.09691630930140399, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 70: 0.08892822265625, mean for epoch: 0.09680219377790178, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 71: 0.08026123046875, mean for epoch: 0.09656922246368838, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 72: 0.11053466796875, mean for epoch: 0.09676318698459202, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 73: 0.0906982421875, mean for epoch: 0.0966801055490154, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 74: 0.0992431640625, mean for epoch: 0.09671474147487331, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 75: 0.078857421875, mean for epoch: 0.09647664388020834, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 76: 0.1279296875, mean for epoch: 0.09689049971731085, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:18,845] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:18,845] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=38.662078846547715, CurrSamplesPerSec=37.65239857301109, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 77: 0.09027099609375, mean for epoch: 0.09680453213778409, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 78: 0.10638427734375, mean for epoch: 0.09692734938401443, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 79: 0.0772705078125, mean for epoch: 0.09667852860462817, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 80: 0.10003662109375, mean for epoch: 0.09672050476074219, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 81: 0.072265625, mean for epoch: 0.09641859266493055, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 82: 0.09710693359375, mean for epoch: 0.09642698706650152, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 83: 0.1248779296875, mean for epoch: 0.09676976950771837, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 84: 0.105712890625, mean for epoch: 0.09687623523530506, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 85: 0.0728759765625, mean for epoch: 0.09659387925091911, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 86: 0.0921630859375, mean for epoch: 0.0965423583984375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:20,186] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:20,186] [INFO] [timer.py:207:stop] 0/250, RunningAvgSamplesPerSec=38.6474716073254, CurrSamplesPerSec=38.03681159630578, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 87: 0.09088134765625, mean for epoch: 0.09647728930944684, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 88: 0.07952880859375, mean for epoch: 0.09628469293767755, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 89: 0.06219482421875, mean for epoch: 0.09590166070488061, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 90: 0.07159423828125, mean for epoch: 0.09563157823350694, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 91: 0.077880859375, mean for epoch: 0.09543651538890796, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 92: 0.11834716796875, mean for epoch: 0.09568554422129756, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 93: 0.0821533203125, mean for epoch: 0.09554003643733198, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 94: 0.1256103515625, mean for epoch: 0.09585993340674867, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 95: 0.07379150390625, mean for epoch: 0.09562763414884869, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 96: 0.10198974609375, mean for epoch: 0.09569390614827473, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:21,529] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:21,529] [INFO] [timer.py:207:stop] 0/260, RunningAvgSamplesPerSec=38.62689832159228, CurrSamplesPerSec=35.99086993083801, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 97: 0.0906982421875, mean for epoch: 0.09564240445795748, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 98: 0.10986328125, mean for epoch: 0.09578751544563138, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 99: 0.0999755859375, mean for epoch: 0.09582981918797348, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 100: 0.1014404296875, mean for epoch: 0.09588592529296874, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 101: 0.07574462890625, mean for epoch: 0.09568650651686263, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 102: 0.132080078125, mean for epoch: 0.09604330623851103, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 103: 0.11907958984375, mean for epoch: 0.09626695947739684, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 104: 0.07586669921875, mean for epoch: 0.09607080312875602, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 105: 0.091796875, mean for epoch: 0.09603009905133929, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 106: 0.0692138671875, mean for epoch: 0.0957771157318691, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:22,871] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:22,872] [INFO] [timer.py:207:stop] 0/270, RunningAvgSamplesPerSec=38.610842993966074, CurrSamplesPerSec=38.11645304582367, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 107: 0.10107421875, mean for epoch: 0.09582662136755257, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 108: 0.09698486328125, mean for epoch: 0.09583734582971644, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 109: 0.11004638671875, mean for epoch: 0.09596770400301032, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 110: 0.1103515625, mean for epoch: 0.09609846635298296, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 111: 0.11700439453125, mean for epoch: 0.09628680804828266, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 112: 0.07269287109375, mean for epoch: 0.0960761478969029, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 113: 0.1229248046875, mean for epoch: 0.09631374662956305, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 114: 0.09576416015625, mean for epoch: 0.09630892569558662, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 115: 0.0950927734375, mean for epoch: 0.09629835045855978, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 116: 0.08050537109375, mean for epoch: 0.09616220408472521, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:24,217] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:24,217] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=38.60097175345364, CurrSamplesPerSec=39.84367667594449, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 117: 0.0897216796875, mean for epoch: 0.09610715686765492, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 118: 0.088134765625, mean for epoch: 0.0960395942300053, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 119: 0.10052490234375, mean for epoch: 0.09607728589482668, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 120: 0.094970703125, mean for epoch: 0.0960680643717448, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 121: 0.0635986328125, mean for epoch: 0.09579972196216426, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 122: 0.07177734375, mean for epoch: 0.0956028172227203, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 123: 0.08172607421875, mean for epoch: 0.09548999817390752, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 124: 0.09967041015625, mean for epoch: 0.09552371117376512, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 125: 0.08099365234375, mean for epoch: 0.095407470703125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 126: 0.11834716796875, mean for epoch: 0.09558953179253472, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:25,555] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:25,556] [INFO] [timer.py:207:stop] 0/290, RunningAvgSamplesPerSec=38.59736295136822, CurrSamplesPerSec=39.404744009860806, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 127: 0.085693359375, mean for epoch: 0.09551160917507381, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 128: 0.1162109375, mean for epoch: 0.0956733226776123, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 129: 0.0924072265625, mean for epoch: 0.09564800410307656, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 130: 0.0799560546875, mean for epoch: 0.09552729679987981, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 131: 0.069580078125, mean for epoch: 0.09532922642831584, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 132: 0.056304931640625, mean for epoch: 0.09503358783143939, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 133: 0.08489990234375, mean for epoch: 0.0949573947074718, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 134: 0.07952880859375, mean for epoch: 0.09484225600513059, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 135: 0.08245849609375, mean for epoch: 0.09475052445023148, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 136: 0.06951904296875, mean for epoch: 0.09456499885110294, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:26,890] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:26,891] [INFO] [timer.py:207:stop] 0/300, RunningAvgSamplesPerSec=38.59145501309032, CurrSamplesPerSec=38.3312405298357, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 137: 0.08807373046875, mean for epoch: 0.09451761733006386, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 138: 0.07476806640625, mean for epoch: 0.09437450464221014, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 139: 0.1251220703125, mean for epoch: 0.0945957101506295, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 140: 0.1248779296875, mean for epoch: 0.09481201171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 141: 0.08538818359375, mean for epoch: 0.09474517605828901, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 142: 0.08428955078125, mean for epoch: 0.0946715448943662, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 143: 0.07366943359375, mean for epoch: 0.09452467698317307, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 144: 0.1158447265625, mean for epoch: 0.09467273288302952, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 145: 0.06854248046875, mean for epoch: 0.09449252424568966, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 146: 0.07684326171875, mean for epoch: 0.0943716388859161, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:28,248] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:28,249] [INFO] [timer.py:207:stop] 0/310, RunningAvgSamplesPerSec=38.56361639076704, CurrSamplesPerSec=36.53867731560369, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 147: 0.12548828125, mean for epoch: 0.09458331672512756, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 148: 0.066650390625, mean for epoch: 0.09439458073796453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 149: 0.11053466796875, mean for epoch: 0.09450290347105705, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 150: 0.09320068359375, mean for epoch: 0.09449422200520834, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 151: 0.08544921875, mean for epoch: 0.094434321321399, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 152: 0.1431884765625, mean for epoch: 0.09475507234272204, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 153: 0.109130859375, mean for epoch: 0.09484903173508986, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 154: 0.08575439453125, mean for epoch: 0.09478997564935066, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 155: 0.08203125, mean for epoch: 0.09470766129032258, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 156: 0.0804443359375, mean for epoch: 0.09461622971754807, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:29,581] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:29,582] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=38.56148224634864, CurrSamplesPerSec=38.92343756090047, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   2:   Loss at step 157: 0.128662109375, mean for epoch: 0.09483308245421974, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 158: 0.08270263671875, mean for epoch: 0.09475630748121044, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 159: 0.0869140625, mean for epoch: 0.09470698518573113, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 160: 0.06341552734375, mean for epoch: 0.09451141357421874, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 161: 0.07818603515625, mean for epoch: 0.09441001370826864, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 162: 0.0706787109375, mean for epoch: 0.09426352418499229, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 163: 0.08740234375, mean for epoch: 0.09422143105348926, mem_alloc: 2342824960\n",
            " Run   3, iteration:   2:   Loss at step 164: 0.0887451171875, mean for epoch: 0.09418803889576982, mem_alloc: 2342824960\n",
            "Loss after iteration 2 ; MSE: 0.09417724609375, MAE: 0.2330322265625\n",
            "Connected by ('127.0.0.1', 44700)\n",
            "\u001b[94mReceived training result: b'2;0.09418;0.23303' \u001b[0m\n",
            "Time per iteration 22.218876004219055, memory OrderedDict([('active.all.allocated', 735902), ('active.all.current', 7), ('active.all.freed', 735895), ('active.all.peak', 295), ('active.large_pool.allocated', 249232), ('active.large_pool.current', 5), ('active.large_pool.freed', 249227), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 486670), ('active.small_pool.current', 2), ('active.small_pool.freed', 486668), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 2418899820032), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 2418848927232), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 2358449876480), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 2358399944192), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 60449943552), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 60448983040), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 2418899820032), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 2418855019008), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 2358449876480), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 2358406035968), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 60449943552), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 60448983040), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 735902), ('allocation.all.current', 6), ('allocation.all.freed', 735896), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 249232), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 249228), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 486670), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 486668), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 315416), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 315412), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 164950), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 164949), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 150466), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 150463), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 1464827961856), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 1464815940096), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 1393895699456), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 1393886911488), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 70932262400), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 70929028608), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   3, iteration:   3:   Loss at step 1: 0.11529541015625, mean for epoch: 0.11529541015625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 2: 0.05963134765625, mean for epoch: 0.08746337890625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:31,057] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:31,057] [INFO] [timer.py:207:stop] 0/330, RunningAvgSamplesPerSec=38.55243297543459, CurrSamplesPerSec=37.79953100977093, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 3: 0.158203125, mean for epoch: 0.11104329427083333, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 4: 0.08148193359375, mean for epoch: 0.1036529541015625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 5: 0.10675048828125, mean for epoch: 0.1042724609375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 6: 0.09912109375, mean for epoch: 0.10341389973958333, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 7: 0.08984375, mean for epoch: 0.10147530691964286, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 8: 0.0679931640625, mean for epoch: 0.0972900390625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 9: 0.0653076171875, mean for epoch: 0.09373643663194445, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 10: 0.06689453125, mean for epoch: 0.09105224609375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 11: 0.1253662109375, mean for epoch: 0.09417169744318182, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 12: 0.07818603515625, mean for epoch: 0.09283955891927083, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:32,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:32,386] [INFO] [timer.py:207:stop] 0/340, RunningAvgSamplesPerSec=38.54821356370172, CurrSamplesPerSec=36.28692450375128, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 13: 0.08074951171875, mean for epoch: 0.09190955528846154, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 14: 0.0877685546875, mean for epoch: 0.09161376953125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 15: 0.056610107421875, mean for epoch: 0.08928019205729167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 16: 0.0863037109375, mean for epoch: 0.08909416198730469, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 17: 0.083984375, mean for epoch: 0.08879358628216912, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 18: 0.064697265625, mean for epoch: 0.08745490180121528, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 19: 0.07183837890625, mean for epoch: 0.08663297954358552, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 20: 0.0872802734375, mean for epoch: 0.08666534423828125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 21: 0.1378173828125, mean for epoch: 0.08910115559895833, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 22: 0.0947265625, mean for epoch: 0.08935685591264204, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:33,735] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:33,735] [INFO] [timer.py:207:stop] 0/350, RunningAvgSamplesPerSec=38.53222583203567, CurrSamplesPerSec=35.2815929906259, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 23: 0.08416748046875, mean for epoch: 0.08913123089334239, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 24: 0.09197998046875, mean for epoch: 0.0892499287923177, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 25: 0.08160400390625, mean for epoch: 0.088944091796875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 26: 0.06964111328125, mean for epoch: 0.08820166954627404, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 27: 0.0684814453125, mean for epoch: 0.08747129087094907, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 28: 0.0950927734375, mean for epoch: 0.08774348667689733, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 29: 0.0887451171875, mean for epoch: 0.08777802566002155, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 30: 0.06292724609375, mean for epoch: 0.08694966634114583, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 31: 0.0780029296875, mean for epoch: 0.0866610619329637, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 32: 0.076904296875, mean for epoch: 0.08635616302490234, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:35,077] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:35,077] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=38.528720962484876, CurrSamplesPerSec=38.440425325216886, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 33: 0.08685302734375, mean for epoch: 0.08637121951941287, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 34: 0.07763671875, mean for epoch: 0.08611432243795956, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 35: 0.0728759765625, mean for epoch: 0.085736083984375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 36: 0.0867919921875, mean for epoch: 0.08576541476779515, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 37: 0.089599609375, mean for epoch: 0.08586904164907094, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 38: 0.077392578125, mean for epoch: 0.08564597681949013, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 39: 0.09161376953125, mean for epoch: 0.0857989971454327, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 40: 0.0906982421875, mean for epoch: 0.08592147827148437, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 41: 0.07745361328125, mean for epoch: 0.08571494497903963, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 42: 0.076904296875, mean for epoch: 0.08550516764322917, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:36,415] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:36,415] [INFO] [timer.py:207:stop] 0/370, RunningAvgSamplesPerSec=38.521121863029016, CurrSamplesPerSec=38.24288764846082, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 43: 0.09039306640625, mean for epoch: 0.08561883970748546, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 44: 0.0836181640625, mean for epoch: 0.08557336980646307, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 45: 0.096435546875, mean for epoch: 0.08581475151909722, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 46: 0.0635986328125, mean for epoch: 0.08533179241677989, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 47: 0.11065673828125, mean for epoch: 0.08587062105219415, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 48: 0.08404541015625, mean for epoch: 0.08583259582519531, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 49: 0.08319091796875, mean for epoch: 0.08577868403220663, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 50: 0.07330322265625, mean for epoch: 0.0855291748046875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 51: 0.078857421875, mean for epoch: 0.08539835611979167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 52: 0.071044921875, mean for epoch: 0.08512232853816105, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:37,756] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:37,756] [INFO] [timer.py:207:stop] 0/380, RunningAvgSamplesPerSec=38.51389185630825, CurrSamplesPerSec=39.456714587013906, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 53: 0.0799560546875, mean for epoch: 0.08502485167305425, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 54: 0.059417724609375, mean for epoch: 0.08455064561631945, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 55: 0.08404541015625, mean for epoch: 0.08454145951704546, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 56: 0.08819580078125, mean for epoch: 0.08460671561104911, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 57: 0.0721435546875, mean for epoch: 0.08438806366502193, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 58: 0.08489990234375, mean for epoch: 0.08439688846982758, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 59: 0.07861328125, mean for epoch: 0.08429886122881355, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 60: 0.0660400390625, mean for epoch: 0.08399454752604167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 61: 0.0789794921875, mean for epoch: 0.08391233350409837, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 62: 0.0870361328125, mean for epoch: 0.0839627173639113, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:39,091] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:39,091] [INFO] [timer.py:207:stop] 0/390, RunningAvgSamplesPerSec=38.51048221143368, CurrSamplesPerSec=38.7161996259736, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 63: 0.09344482421875, mean for epoch: 0.08411322699652778, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 64: 0.11053466796875, mean for epoch: 0.08452606201171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 65: 0.08319091796875, mean for epoch: 0.08450552133413461, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 66: 0.0823974609375, mean for epoch: 0.0844735810250947, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 67: 0.1368408203125, mean for epoch: 0.08525518161147388, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 68: 0.0802001953125, mean for epoch: 0.08518084357766544, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 69: 0.086669921875, mean for epoch: 0.08520242442255435, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 70: 0.08660888671875, mean for epoch: 0.08522251674107142, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 71: 0.1455078125, mean for epoch: 0.08607160541373239, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 72: 0.1116943359375, mean for epoch: 0.08642747667100695, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:40,446] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:40,446] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=38.49223617279119, CurrSamplesPerSec=34.538872767158665, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 73: 0.07366943359375, mean for epoch: 0.08625270895761987, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 74: 0.07672119140625, mean for epoch: 0.08612390466638513, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 75: 0.0965576171875, mean for epoch: 0.08626302083333333, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 76: 0.07135009765625, mean for epoch: 0.08606679815995066, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 77: 0.09881591796875, mean for epoch: 0.08623237114448051, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 78: 0.0694580078125, mean for epoch: 0.08601731520432693, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 79: 0.09405517578125, mean for epoch: 0.08611906027492089, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 80: 0.080078125, mean for epoch: 0.08604354858398437, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 81: 0.08642578125, mean for epoch: 0.08604826750578703, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 82: 0.06494140625, mean for epoch: 0.08579086675876524, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:41,804] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:41,805] [INFO] [timer.py:207:stop] 0/410, RunningAvgSamplesPerSec=38.47821741954817, CurrSamplesPerSec=37.099742779607766, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 83: 0.0701904296875, mean for epoch: 0.08560290968561747, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 84: 0.0821533203125, mean for epoch: 0.08556184314546131, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 85: 0.09515380859375, mean for epoch: 0.08567468979779412, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 86: 0.07470703125, mean for epoch: 0.08554715888444768, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 87: 0.07452392578125, mean for epoch: 0.08542045505567529, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 88: 0.0806884765625, mean for epoch: 0.0853666825727983, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 89: 0.1085205078125, mean for epoch: 0.08562683791257023, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 90: 0.08172607421875, mean for epoch: 0.08558349609375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 91: 0.10418701171875, mean for epoch: 0.08578793033138736, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 92: 0.06890869140625, mean for epoch: 0.08560446034307065, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:43,126] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:43,127] [INFO] [timer.py:207:stop] 0/420, RunningAvgSamplesPerSec=38.48394638523732, CurrSamplesPerSec=37.568961007785546, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 93: 0.1298828125, mean for epoch: 0.08608057165658602, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 94: 0.0654296875, mean for epoch: 0.08586088139960106, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 95: 0.072509765625, mean for epoch: 0.08572034333881579, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 96: 0.076904296875, mean for epoch: 0.08562850952148438, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 97: 0.06341552734375, mean for epoch: 0.08539950970521908, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 98: 0.07867431640625, mean for epoch: 0.08533088528380102, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 99: 0.07818603515625, mean for epoch: 0.08525871508049243, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 100: 0.10302734375, mean for epoch: 0.0854364013671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 101: 0.052520751953125, mean for epoch: 0.08511050384823639, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 102: 0.07623291015625, mean for epoch: 0.08502346861596201, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:44,454] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:44,454] [INFO] [timer.py:207:stop] 0/430, RunningAvgSamplesPerSec=38.48568050994569, CurrSamplesPerSec=39.44765992825824, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 103: 0.07183837890625, mean for epoch: 0.08489545803625607, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 104: 0.0721435546875, mean for epoch: 0.08477284358097957, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 105: 0.100341796875, mean for epoch: 0.0849211193266369, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 106: 0.0919189453125, mean for epoch: 0.08498713655291863, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 107: 0.06488037109375, mean for epoch: 0.08479922285703854, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 108: 0.08721923828125, mean for epoch: 0.08482163040726273, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 109: 0.06640625, mean for epoch: 0.0846526819631594, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 110: 0.09063720703125, mean for epoch: 0.08470708673650568, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 111: 0.0675048828125, mean for epoch: 0.0845521119263795, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 112: 0.10589599609375, mean for epoch: 0.08474268232073102, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:45,793] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:45,794] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=38.482977988196325, CurrSamplesPerSec=37.517008445634694, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 113: 0.0885009765625, mean for epoch: 0.08477594156180863, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 114: 0.08416748046875, mean for epoch: 0.08477060418379934, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 115: 0.0738525390625, mean for epoch: 0.08467566448709239, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 116: 0.0723876953125, mean for epoch: 0.0845697337183459, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 117: 0.1015625, mean for epoch: 0.08471497103699252, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 118: 0.08770751953125, mean for epoch: 0.08474033161745233, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 119: 0.08355712890625, mean for epoch: 0.08473038873752627, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 120: 0.09930419921875, mean for epoch: 0.08485183715820313, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 121: 0.05633544921875, mean for epoch: 0.08461616453060433, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 122: 0.10479736328125, mean for epoch: 0.08478158419249487, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:47,121] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:47,122] [INFO] [timer.py:207:stop] 0/450, RunningAvgSamplesPerSec=38.48625665829983, CurrSamplesPerSec=37.7196466085355, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 123: 0.09014892578125, mean for epoch: 0.08482522111598069, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 124: 0.070556640625, mean for epoch: 0.08471015191847278, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 125: 0.0750732421875, mean for epoch: 0.084633056640625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 126: 0.12548828125, mean for epoch: 0.08495730445498512, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 127: 0.076171875, mean for epoch: 0.08488812784510334, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 128: 0.05706787109375, mean for epoch: 0.0846707820892334, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 129: 0.092529296875, mean for epoch: 0.08473170080850291, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 130: 0.07220458984375, mean for epoch: 0.08463533841646635, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 131: 0.0772705078125, mean for epoch: 0.08457911833552004, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 132: 0.08843994140625, mean for epoch: 0.08460836699514677, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:48,456] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:48,456] [INFO] [timer.py:207:stop] 0/460, RunningAvgSamplesPerSec=38.48345426081154, CurrSamplesPerSec=39.74453149577946, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 133: 0.1082763671875, mean for epoch: 0.08478632188381109, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 134: 0.06488037109375, mean for epoch: 0.08463777001224347, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 135: 0.07781982421875, mean for epoch: 0.08458726671006944, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 136: 0.09368896484375, mean for epoch: 0.0846541909610524, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 137: 0.08416748046875, mean for epoch: 0.08465063832972171, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 138: 0.09844970703125, mean for epoch: 0.08475063158118207, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 139: 0.06353759765625, mean for epoch: 0.08459801982632643, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 140: 0.056243896484375, mean for epoch: 0.08439549037388393, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 141: 0.0693359375, mean for epoch: 0.08428868503435284, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 142: 0.0771484375, mean for epoch: 0.08423840160101233, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:49,787] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:49,787] [INFO] [timer.py:207:stop] 0/470, RunningAvgSamplesPerSec=38.48485159444354, CurrSamplesPerSec=38.76572375000231, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 143: 0.0709228515625, mean for epoch: 0.08414528586647728, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 144: 0.06683349609375, mean for epoch: 0.08402506510416667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 145: 0.07012939453125, mean for epoch: 0.08392923289331897, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 146: 0.0699462890625, mean for epoch: 0.08383345930543665, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 147: 0.08404541015625, mean for epoch: 0.08383490114795919, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 148: 0.06768798828125, mean for epoch: 0.08372580038534629, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 149: 0.07037353515625, mean for epoch: 0.0836361878670302, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 150: 0.08038330078125, mean for epoch: 0.083614501953125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 151: 0.08428955078125, mean for epoch: 0.08361897247516556, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 152: 0.1207275390625, mean for epoch: 0.08386310778166119, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:51,141] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:51,142] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=38.47627660544978, CurrSamplesPerSec=39.50926902788244, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 153: 0.0845947265625, mean for epoch: 0.08386788960375817, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 154: 0.07818603515625, mean for epoch: 0.08383099444500812, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 155: 0.07830810546875, mean for epoch: 0.08379536290322581, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 156: 0.0791015625, mean for epoch: 0.08376527443910256, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 157: 0.08270263671875, mean for epoch: 0.0837585060459793, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 158: 0.10235595703125, mean for epoch: 0.08387621143196203, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 159: 0.07830810546875, mean for epoch: 0.0838411918976022, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 160: 0.07928466796875, mean for epoch: 0.08381271362304688, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 161: 0.072265625, mean for epoch: 0.08374099257569875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 162: 0.1087646484375, mean for epoch: 0.08389545958719136, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:52,482] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:52,483] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=38.474573589871646, CurrSamplesPerSec=37.54790726321198, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   3:   Loss at step 163: 0.101318359375, mean for epoch: 0.08400234854294479, mem_alloc: 2342824960\n",
            " Run   3, iteration:   3:   Loss at step 164: 0.1376953125, mean for epoch: 0.08432974466463415, mem_alloc: 2342824960\n",
            "Loss after iteration 3 ; MSE: 0.0843505859375, MAE: 0.2191162109375\n",
            "Connected by ('127.0.0.1', 51366)\n",
            "\u001b[94mReceived training result: b'3;0.08435;0.21912' \u001b[0m\n",
            "Time per iteration 22.18037025133769, memory OrderedDict([('active.all.allocated', 1110150), ('active.all.current', 7), ('active.all.freed', 1110143), ('active.all.peak', 295), ('active.large_pool.allocated', 373872), ('active.large_pool.current', 5), ('active.large_pool.freed', 373867), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 736278), ('active.small_pool.current', 2), ('active.small_pool.freed', 736276), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 3628864593408), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 3628813700608), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 3537862809088), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 3537812876800), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 91001784320), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 91000823808), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 3628864593408), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 3628819792384), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 3537862809088), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 3537818968576), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 91001784320), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 91000823808), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1110150), ('allocation.all.current', 6), ('allocation.all.freed', 1110144), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 373872), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 373868), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 736278), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 736276), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 474981), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 474977), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 247442), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 247441), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 227539), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 227536), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2197740484608), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2197728462848), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2091025660928), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2091016872960), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 106714823680), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 106711589888), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   3, iteration:   4:   Loss at step 1: 0.11309814453125, mean for epoch: 0.11309814453125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 2: 0.0648193359375, mean for epoch: 0.088958740234375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 3: 0.06500244140625, mean for epoch: 0.08097330729166667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 4: 0.10491943359375, mean for epoch: 0.0869598388671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 5: 0.09820556640625, mean for epoch: 0.089208984375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 6: 0.08966064453125, mean for epoch: 0.08928426106770833, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 7: 0.0587158203125, mean for epoch: 0.08491734095982142, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 8: 0.0860595703125, mean for epoch: 0.08506011962890625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:53,974] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:53,975] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=38.464468557353406, CurrSamplesPerSec=36.819076412041795, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 9: 0.06982421875, mean for epoch: 0.08336724175347222, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 10: 0.08355712890625, mean for epoch: 0.08338623046875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 11: 0.07611083984375, mean for epoch: 0.08272483132102272, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 12: 0.06439208984375, mean for epoch: 0.08119710286458333, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 13: 0.08380126953125, mean for epoch: 0.08139742337740384, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 14: 0.067138671875, mean for epoch: 0.08037894112723214, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 15: 0.07989501953125, mean for epoch: 0.0803466796875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 16: 0.072998046875, mean for epoch: 0.07988739013671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 17: 0.076416015625, mean for epoch: 0.07968319163602941, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 18: 0.078857421875, mean for epoch: 0.07963731553819445, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:55,323] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:55,324] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=38.453991700163996, CurrSamplesPerSec=37.78454819477901, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 19: 0.08795166015625, mean for epoch: 0.08007491262335527, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 20: 0.08837890625, mean for epoch: 0.0804901123046875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 21: 0.09454345703125, mean for epoch: 0.08115931919642858, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 22: 0.0816650390625, mean for epoch: 0.08118230646306818, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 23: 0.0782470703125, mean for epoch: 0.0810546875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 24: 0.11236572265625, mean for epoch: 0.08235931396484375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 25: 0.07501220703125, mean for epoch: 0.0820654296875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 26: 0.085693359375, mean for epoch: 0.08220496544471154, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 27: 0.08111572265625, mean for epoch: 0.08216462311921297, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 28: 0.07427978515625, mean for epoch: 0.08188302176339286, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:56,665] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:56,665] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=38.44925710332965, CurrSamplesPerSec=39.5582324014464, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 29: 0.074462890625, mean for epoch: 0.0816271551724138, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 30: 0.0654296875, mean for epoch: 0.08108723958333333, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 31: 0.12359619140625, mean for epoch: 0.08245849609375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 32: 0.09918212890625, mean for epoch: 0.08298110961914062, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 33: 0.0855712890625, mean for epoch: 0.08305959990530302, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 34: 0.07244873046875, mean for epoch: 0.0827475155101103, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 35: 0.062286376953125, mean for epoch: 0.08216291155133928, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 36: 0.070556640625, mean for epoch: 0.08184051513671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 37: 0.087646484375, mean for epoch: 0.08199743322423987, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 38: 0.06732177734375, mean for epoch: 0.08161123175370066, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:58,009] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:58,009] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=38.445024498448184, CurrSamplesPerSec=36.3690471029133, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 39: 0.0712890625, mean for epoch: 0.08134656074719551, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 40: 0.07440185546875, mean for epoch: 0.08117294311523438, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 41: 0.05584716796875, mean for epoch: 0.08055524128239329, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 42: 0.09027099609375, mean for epoch: 0.08078656877790179, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 43: 0.06964111328125, mean for epoch: 0.08052737213844477, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 44: 0.1248779296875, mean for epoch: 0.08153533935546875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 45: 0.05645751953125, mean for epoch: 0.08097805447048612, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 46: 0.10162353515625, mean for epoch: 0.08142686926800272, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 47: 0.07977294921875, mean for epoch: 0.08139167947972074, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 48: 0.06890869140625, mean for epoch: 0.08113161722819011, mem_alloc: 2342824960\n",
            "[2022-10-25 13:46:59,358] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:46:59,359] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=38.43689567706117, CurrSamplesPerSec=36.92487556144808, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 49: 0.1258544921875, mean for epoch: 0.08204432896205358, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 50: 0.0921630859375, mean for epoch: 0.0822467041015625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 51: 0.06524658203125, mean for epoch: 0.08191336837469362, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 52: 0.07733154296875, mean for epoch: 0.08182525634765625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 53: 0.10333251953125, mean for epoch: 0.08223105376621462, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 54: 0.1002197265625, mean for epoch: 0.0825641773365162, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 55: 0.06396484375, mean for epoch: 0.08222600763494319, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 56: 0.08306884765625, mean for epoch: 0.08224105834960938, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 57: 0.0655517578125, mean for epoch: 0.0819482636033443, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 58: 0.07061767578125, mean for epoch: 0.08175290864089439, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:00,700] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:00,701] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=38.4333661590947, CurrSamplesPerSec=39.27361255465978, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 59: 0.065673828125, mean for epoch: 0.0814803818524894, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 60: 0.064697265625, mean for epoch: 0.08120066324869792, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 61: 0.07427978515625, mean for epoch: 0.08108720623078894, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 62: 0.09368896484375, mean for epoch: 0.08129046040196572, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 63: 0.0672607421875, mean for epoch: 0.08106776646205358, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 64: 0.06610107421875, mean for epoch: 0.08083391189575195, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 65: 0.07220458984375, mean for epoch: 0.08070115309495192, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 66: 0.06884765625, mean for epoch: 0.0805215546579072, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 67: 0.08099365234375, mean for epoch: 0.08052860089202425, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 68: 0.08233642578125, mean for epoch: 0.08055518655215993, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:02,044] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:02,045] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=38.429278354870604, CurrSamplesPerSec=36.068926730520836, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 69: 0.0970458984375, mean for epoch: 0.08079418237658514, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 70: 0.054779052734375, mean for epoch: 0.08042253766741071, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 71: 0.06671142578125, mean for epoch: 0.08022942341549295, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 72: 0.10418701171875, mean for epoch: 0.08056216769748265, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 73: 0.0731201171875, mean for epoch: 0.08046022180008562, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 74: 0.07391357421875, mean for epoch: 0.08037175358952703, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 75: 0.08428955078125, mean for epoch: 0.08042399088541667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 76: 0.08465576171875, mean for epoch: 0.0804796720805921, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 77: 0.07904052734375, mean for epoch: 0.08046098188920454, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 78: 0.07025146484375, mean for epoch: 0.08033009064503205, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:03,400] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:03,401] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=38.420669666914335, CurrSamplesPerSec=39.199029534524236, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 79: 0.055908203125, mean for epoch: 0.08002095282832279, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 80: 0.0819091796875, mean for epoch: 0.0800445556640625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 81: 0.068359375, mean for epoch: 0.07990029417438271, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 82: 0.06451416015625, mean for epoch: 0.07971265839367378, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 83: 0.08636474609375, mean for epoch: 0.07979280402861445, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 84: 0.07354736328125, mean for epoch: 0.07971845354352679, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 85: 0.09832763671875, mean for epoch: 0.07993738511029412, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 86: 0.07464599609375, mean for epoch: 0.07987585733103197, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 87: 0.0775146484375, mean for epoch: 0.07984871699892242, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 88: 0.06671142578125, mean for epoch: 0.07969942959872159, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:04,749] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:04,750] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=38.414449138916154, CurrSamplesPerSec=39.07137228015329, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 89: 0.09130859375, mean for epoch: 0.07982986964536516, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 90: 0.08551025390625, mean for epoch: 0.07989298502604167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 91: 0.07958984375, mean for epoch: 0.07988965380322802, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 92: 0.08111572265625, mean for epoch: 0.07990298063858696, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 93: 0.098876953125, mean for epoch: 0.08010700184811828, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 94: 0.06915283203125, mean for epoch: 0.07999046812666223, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 95: 0.0889892578125, mean for epoch: 0.08008519222861842, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 96: 0.081787109375, mean for epoch: 0.08010292053222656, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 97: 0.07000732421875, mean for epoch: 0.0799988422197165, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 98: 0.09429931640625, mean for epoch: 0.08014476542570154, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:06,115] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:06,116] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=38.39814266796482, CurrSamplesPerSec=36.812290236059034, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 99: 0.07598876953125, mean for epoch: 0.08010278566919192, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 100: 0.0721435546875, mean for epoch: 0.080023193359375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 101: 0.08319091796875, mean for epoch: 0.0800545569693688, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 102: 0.0621337890625, mean for epoch: 0.0798788631663603, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 103: 0.08123779296875, mean for epoch: 0.07989205665958737, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 104: 0.051025390625, mean for epoch: 0.07961449256310096, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 105: 0.08111572265625, mean for epoch: 0.07962878999255953, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 106: 0.07476806640625, mean for epoch: 0.07958293410966981, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 107: 0.07025146484375, mean for epoch: 0.07949572411653037, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 108: 0.09246826171875, mean for epoch: 0.07961584020543981, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:07,462] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:07,462] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=38.39538113412852, CurrSamplesPerSec=39.22322325317812, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 109: 0.06622314453125, mean for epoch: 0.07949297143778669, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 110: 0.061279296875, mean for epoch: 0.079327392578125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 111: 0.0889892578125, mean for epoch: 0.07941443640906531, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 112: 0.08544921875, mean for epoch: 0.07946831839425224, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 113: 0.06011962890625, mean for epoch: 0.07929709105365045, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 114: 0.08831787109375, mean for epoch: 0.079376220703125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 115: 0.09344482421875, mean for epoch: 0.07949855638586957, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 116: 0.0689697265625, mean for epoch: 0.07940779061153017, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 117: 0.06097412109375, mean for epoch: 0.07925023788060898, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 118: 0.07220458984375, mean for epoch: 0.07919052899894068, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:08,790] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:08,790] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=38.39996549910583, CurrSamplesPerSec=39.22821233700522, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 119: 0.0794677734375, mean for epoch: 0.07919285878413866, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 120: 0.050994873046875, mean for epoch: 0.07895787556966145, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 121: 0.0831298828125, mean for epoch: 0.0789923549683626, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 122: 0.108642578125, mean for epoch: 0.07923538958440061, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 123: 0.0592041015625, mean for epoch: 0.07907253358422256, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 124: 0.0765380859375, mean for epoch: 0.07905209449029738, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 125: 0.0928955078125, mean for epoch: 0.079162841796875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 126: 0.06903076171875, mean for epoch: 0.07908242846292163, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 127: 0.057861328125, mean for epoch: 0.07891533318467027, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 128: 0.09027099609375, mean for epoch: 0.07900404930114746, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:10,134] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:10,134] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=38.39478882167444, CurrSamplesPerSec=38.018676204789244, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 129: 0.07830810546875, mean for epoch: 0.07899865438771803, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 130: 0.0948486328125, mean for epoch: 0.07912057729867789, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 131: 0.07598876953125, mean for epoch: 0.07909667036915553, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 132: 0.08160400390625, mean for epoch: 0.07911566532019412, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 133: 0.09002685546875, mean for epoch: 0.07919770434386748, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 134: 0.05291748046875, mean for epoch: 0.07900158327017258, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 135: 0.08843994140625, mean for epoch: 0.07907149703414351, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 136: 0.09039306640625, mean for epoch: 0.07915474386776195, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 137: 0.08697509765625, mean for epoch: 0.07921182674213048, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 138: 0.06170654296875, mean for epoch: 0.07908497685971468, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:11,464] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:11,465] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=38.40141955138056, CurrSamplesPerSec=39.37485449069867, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 139: 0.06646728515625, mean for epoch: 0.07899420209925809, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 140: 0.1201171875, mean for epoch: 0.07928793770926339, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 141: 0.06817626953125, mean for epoch: 0.07920913155197251, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 142: 0.09136962890625, mean for epoch: 0.07929476885728433, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 143: 0.10009765625, mean for epoch: 0.07944024359429633, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 144: 0.10736083984375, mean for epoch: 0.07963413662380642, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 145: 0.061614990234375, mean for epoch: 0.07950986664870689, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 146: 0.07415771484375, mean for epoch: 0.07947320807470035, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 147: 0.0732421875, mean for epoch: 0.07943082017963435, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 148: 0.067626953125, mean for epoch: 0.0793510643211571, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:12,828] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:12,829] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=38.38965964746516, CurrSamplesPerSec=39.83066073839971, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 149: 0.0655517578125, mean for epoch: 0.07925845152579698, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 150: 0.05731201171875, mean for epoch: 0.07911214192708334, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 151: 0.08843994140625, mean for epoch: 0.07917391543356789, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 152: 0.0802001953125, mean for epoch: 0.07918066727487665, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 153: 0.05767822265625, mean for epoch: 0.07904012842116014, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 154: 0.09356689453125, mean for epoch: 0.07913445807122566, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 155: 0.07171630859375, mean for epoch: 0.07908659904233871, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 156: 0.08489990234375, mean for epoch: 0.07912386380709134, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 157: 0.07122802734375, mean for epoch: 0.07907357185509555, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 158: 0.1036376953125, mean for epoch: 0.0792290409909019, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:14,164] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:14,164] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=38.38865168374182, CurrSamplesPerSec=38.17049709055235, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   4:   Loss at step 159: 0.1014404296875, mean for epoch: 0.07936873525943396, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 160: 0.0635986328125, mean for epoch: 0.07927017211914063, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 161: 0.09991455078125, mean for epoch: 0.07939839807356366, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 162: 0.07232666015625, mean for epoch: 0.07935474537037036, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 163: 0.08929443359375, mean for epoch: 0.07941572505272239, mem_alloc: 2342824960\n",
            " Run   3, iteration:   4:   Loss at step 164: 0.07330322265625, mean for epoch: 0.07937845369664634, mem_alloc: 2342824960\n",
            "Loss after iteration 4 ; MSE: 0.07940673828125, MAE: 0.212158203125\n",
            "Connected by ('127.0.0.1', 55208)\n",
            "\u001b[94mReceived training result: b'4;0.07941;0.21216' \u001b[0m\n",
            "Time per iteration 22.192165851593018, memory OrderedDict([('active.all.allocated', 1484398), ('active.all.current', 7), ('active.all.freed', 1484391), ('active.all.peak', 295), ('active.large_pool.allocated', 498512), ('active.large_pool.current', 5), ('active.large_pool.freed', 498507), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 985886), ('active.small_pool.current', 2), ('active.small_pool.freed', 985884), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 4838829366784), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 4838778473984), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 4717275741696), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 4717225809408), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 121553625088), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 121552664576), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 4838829366784), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 4838784565760), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 4717275741696), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 4717231901184), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 121553625088), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 121552664576), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1484398), ('allocation.all.current', 6), ('allocation.all.freed', 1484392), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 498512), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 498508), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 985886), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 985884), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 634546), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 634542), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 329934), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 329933), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 304612), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 304609), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2930653007360), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2930640985600), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2788155622400), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2788146834432), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 142497384960), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 142494151168), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   3, iteration:   5:   Loss at step 1: 0.068603515625, mean for epoch: 0.068603515625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 2: 0.07879638671875, mean for epoch: 0.073699951171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 3: 0.077392578125, mean for epoch: 0.07493082682291667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 4: 0.07537841796875, mean for epoch: 0.075042724609375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:15,659] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:15,660] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=38.38348146294434, CurrSamplesPerSec=38.507338265293946, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 5: 0.05450439453125, mean for epoch: 0.07093505859375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 6: 0.0638427734375, mean for epoch: 0.06975301106770833, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 7: 0.09442138671875, mean for epoch: 0.07327706473214286, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 8: 0.0888671875, mean for epoch: 0.075225830078125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 9: 0.08184814453125, mean for epoch: 0.0759616427951389, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 10: 0.07611083984375, mean for epoch: 0.0759765625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 11: 0.0634765625, mean for epoch: 0.07484019886363637, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 12: 0.10009765625, mean for epoch: 0.07694498697916667, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 13: 0.0716552734375, mean for epoch: 0.0765380859375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 14: 0.08184814453125, mean for epoch: 0.07691737583705358, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:17,015] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:17,015] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=38.37370910310102, CurrSamplesPerSec=36.938663716954444, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 15: 0.0914306640625, mean for epoch: 0.07788492838541666, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 16: 0.05706787109375, mean for epoch: 0.0765838623046875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 17: 0.09271240234375, mean for epoch: 0.07753259995404412, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 18: 0.06951904296875, mean for epoch: 0.07708740234375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 19: 0.06634521484375, mean for epoch: 0.07652202405427631, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 20: 0.07745361328125, mean for epoch: 0.076568603515625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 21: 0.07977294921875, mean for epoch: 0.07672119140625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 22: 0.07470703125, mean for epoch: 0.076629638671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 23: 0.0809326171875, mean for epoch: 0.07681672469429347, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 24: 0.065185546875, mean for epoch: 0.07633209228515625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:18,356] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:18,357] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=38.37093183135927, CurrSamplesPerSec=34.291395233236535, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 25: 0.07183837890625, mean for epoch: 0.07615234375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 26: 0.059295654296875, mean for epoch: 0.07550400954026443, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 27: 0.07568359375, mean for epoch: 0.07551066080729167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 28: 0.054412841796875, mean for epoch: 0.07475716727120536, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 29: 0.07525634765625, mean for epoch: 0.07477438038793104, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 30: 0.09259033203125, mean for epoch: 0.07536824544270833, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 31: 0.0694580078125, mean for epoch: 0.07517759261592742, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 32: 0.0841064453125, mean for epoch: 0.07545661926269531, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 33: 0.07080078125, mean for epoch: 0.07531553326231061, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 34: 0.0760498046875, mean for epoch: 0.07533712948069853, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:19,691] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:19,692] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=38.37187265732516, CurrSamplesPerSec=38.754405060437335, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 35: 0.07147216796875, mean for epoch: 0.07522670200892857, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 36: 0.08392333984375, mean for epoch: 0.07546827528211805, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 37: 0.061767578125, mean for epoch: 0.07509798616976351, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 38: 0.0782470703125, mean for epoch: 0.07518085680509869, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 39: 0.07623291015625, mean for epoch: 0.07520783253205128, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 40: 0.0885009765625, mean for epoch: 0.0755401611328125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 41: 0.07708740234375, mean for epoch: 0.07557789872332317, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 42: 0.059722900390625, mean for epoch: 0.07520039876302083, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 43: 0.077392578125, mean for epoch: 0.07525137967841569, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 44: 0.0777587890625, mean for epoch: 0.0753083662553267, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:21,019] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:21,020] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=38.37570334174819, CurrSamplesPerSec=38.25118830915372, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 45: 0.056182861328125, mean for epoch: 0.07488335503472222, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 46: 0.08111572265625, mean for epoch: 0.07501884128736414, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 47: 0.08599853515625, mean for epoch: 0.07525245179521277, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 48: 0.0736083984375, mean for epoch: 0.07521820068359375, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 49: 0.07586669921875, mean for epoch: 0.07523143534757654, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 50: 0.0679931640625, mean for epoch: 0.075086669921875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 51: 0.0689697265625, mean for epoch: 0.0749667298560049, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 52: 0.075927734375, mean for epoch: 0.07498521071213943, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 53: 0.0699462890625, mean for epoch: 0.07489013671875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 54: 0.06915283203125, mean for epoch: 0.07478389033564815, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:22,594] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:22,595] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=38.28528219976993, CurrSamplesPerSec=29.95251078683556, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 55: 0.094482421875, mean for epoch: 0.07514204545454546, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 56: 0.079833984375, mean for epoch: 0.075225830078125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 57: 0.09112548828125, mean for epoch: 0.07550477145010964, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 58: 0.097412109375, mean for epoch: 0.07588248417295258, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 59: 0.0811767578125, mean for epoch: 0.07597221762447035, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 60: 0.058197021484375, mean for epoch: 0.07567596435546875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 61: 0.08612060546875, mean for epoch: 0.07584718798027663, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 62: 0.052215576171875, mean for epoch: 0.07546603295110887, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 63: 0.0958251953125, mean for epoch: 0.07578919425843254, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 64: 0.052215576171875, mean for epoch: 0.07542085647583008, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:24,274] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:24,275] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=38.161284647980814, CurrSamplesPerSec=32.288664682579395, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 65: 0.052642822265625, mean for epoch: 0.07507042518028846, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 66: 0.07562255859375, mean for epoch: 0.07507879083806818, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 67: 0.057769775390625, mean for epoch: 0.07482044732392724, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 68: 0.07568359375, mean for epoch: 0.07483314065372243, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 69: 0.06591796875, mean for epoch: 0.0747039352638134, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 70: 0.1094970703125, mean for epoch: 0.07520098005022322, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 71: 0.07928466796875, mean for epoch: 0.07525849678147008, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 72: 0.0826416015625, mean for epoch: 0.07536103990342882, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 73: 0.0555419921875, mean for epoch: 0.07508954609910103, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 74: 0.0755615234375, mean for epoch: 0.07509592417124156, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:25,624] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:25,625] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=38.15779854455746, CurrSamplesPerSec=35.03995802861473, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 75: 0.06689453125, mean for epoch: 0.074986572265625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 76: 0.06658935546875, mean for epoch: 0.07487608257092927, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 77: 0.07470703125, mean for epoch: 0.0748738870992289, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 78: 0.1104736328125, mean for epoch: 0.07533029409555289, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 79: 0.0634765625, mean for epoch: 0.07518024686016614, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 80: 0.056854248046875, mean for epoch: 0.074951171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 81: 0.07537841796875, mean for epoch: 0.07495644651813271, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 82: 0.11370849609375, mean for epoch: 0.07542903248856707, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 83: 0.10888671875, mean for epoch: 0.07583213714231928, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 84: 0.1146240234375, mean for epoch: 0.0762939453125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:26,995] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:26,995] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=38.152283873047324, CurrSamplesPerSec=36.18880316409061, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 85: 0.0780029296875, mean for epoch: 0.07631405101102941, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 86: 0.1064453125, mean for epoch: 0.07666441451671512, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 87: 0.07122802734375, mean for epoch: 0.07660192730783046, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 88: 0.07452392578125, mean for epoch: 0.07657831365411932, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 89: 0.05999755859375, mean for epoch: 0.07639201303546349, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 90: 0.0673828125, mean for epoch: 0.07629191080729167, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 91: 0.10211181640625, mean for epoch: 0.07657564603365384, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 92: 0.1011962890625, mean for epoch: 0.07684326171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 93: 0.060943603515625, mean for epoch: 0.07667229765204973, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 94: 0.084716796875, mean for epoch: 0.0767578774310173, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:28,350] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:28,350] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=38.14828290804383, CurrSamplesPerSec=38.08136145980683, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 95: 0.0714111328125, mean for epoch: 0.0767015959087171, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 96: 0.06658935546875, mean for epoch: 0.07659626007080078, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 97: 0.064697265625, mean for epoch: 0.07647359002496779, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 98: 0.11224365234375, mean for epoch: 0.07683859066087373, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 99: 0.091796875, mean for epoch: 0.07698968444207702, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 100: 0.10693359375, mean for epoch: 0.07728912353515625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 101: 0.076171875, mean for epoch: 0.07727806166847154, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 102: 0.08380126953125, mean for epoch: 0.07734201468673407, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 103: 0.0810546875, mean for epoch: 0.07737806005385316, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 104: 0.05548095703125, mean for epoch: 0.07716751098632812, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:29,735] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:29,735] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=38.134416470454994, CurrSamplesPerSec=35.63330767649273, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 105: 0.05877685546875, mean for epoch: 0.07699236188616071, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 106: 0.074462890625, mean for epoch: 0.07696849894973468, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 107: 0.0897216796875, mean for epoch: 0.07708768755476052, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 108: 0.06243896484375, mean for epoch: 0.07695205123336227, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 109: 0.0721435546875, mean for epoch: 0.07690793658615253, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 110: 0.07635498046875, mean for epoch: 0.07690290971235796, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 111: 0.08428955078125, mean for epoch: 0.07696945602829391, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 112: 0.0762939453125, mean for epoch: 0.07696342468261719, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 113: 0.06591796875, mean for epoch: 0.0768656772849834, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 114: 0.085693359375, mean for epoch: 0.07694311309279057, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:31,076] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:31,077] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=38.136381683335905, CurrSamplesPerSec=39.57024955564528, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 115: 0.0831298828125, mean for epoch: 0.07699691109035327, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 116: 0.123779296875, mean for epoch: 0.07740020751953125, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 117: 0.09124755859375, mean for epoch: 0.07751856094751602, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 118: 0.08544921875, mean for epoch: 0.07758576991194385, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 119: 0.04852294921875, mean for epoch: 0.07734154452796743, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 120: 0.0706787109375, mean for epoch: 0.07728602091471354, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 121: 0.0548095703125, mean for epoch: 0.0771002651246126, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 122: 0.059906005859375, mean for epoch: 0.0769593285732582, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 123: 0.0692138671875, mean for epoch: 0.07689635734247967, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 124: 0.061981201171875, mean for epoch: 0.0767760738249748, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:32,438] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:32,439] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=38.131464132550434, CurrSamplesPerSec=38.702624095020326, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 125: 0.06939697265625, mean for epoch: 0.076717041015625, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 126: 0.061370849609375, mean for epoch: 0.07659524584573413, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 127: 0.058868408203125, mean for epoch: 0.07645566444697342, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 128: 0.0712890625, mean for epoch: 0.0764153003692627, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 129: 0.10443115234375, mean for epoch: 0.07663247751635174, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 130: 0.057159423828125, mean for epoch: 0.07648268479567308, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 131: 0.0654296875, mean for epoch: 0.07639831077051527, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 132: 0.09332275390625, mean for epoch: 0.07652652624881628, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 133: 0.0697021484375, mean for epoch: 0.076475215137453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 134: 0.08306884765625, mean for epoch: 0.07652442135027986, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:33,782] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:33,783] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=38.1329496541209, CurrSamplesPerSec=36.49264457661508, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 135: 0.10052490234375, mean for epoch: 0.07670220269097222, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 136: 0.080810546875, mean for epoch: 0.07673241110409007, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 137: 0.07525634765625, mean for epoch: 0.07672163691833941, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 138: 0.0860595703125, mean for epoch: 0.07678930310235507, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 139: 0.08428955078125, mean for epoch: 0.07684326171875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 140: 0.06243896484375, mean for epoch: 0.07674037388392857, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 141: 0.0828857421875, mean for epoch: 0.07678395805629433, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 142: 0.07598876953125, mean for epoch: 0.07677835813710387, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 143: 0.0601806640625, mean for epoch: 0.07666229034637238, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 144: 0.0992431640625, mean for epoch: 0.07681910196940105, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:35,112] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:35,113] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=38.1392272309103, CurrSamplesPerSec=37.452687486494256, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 145: 0.05902099609375, mean for epoch: 0.07669635641163793, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 146: 0.08251953125, mean for epoch: 0.0767362411708048, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 147: 0.054229736328125, mean for epoch: 0.07658313569568452, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 148: 0.086669921875, mean for epoch: 0.07665128965635558, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 149: 0.07696533203125, mean for epoch: 0.07665339732330118, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 150: 0.08306884765625, mean for epoch: 0.0766961669921875, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 151: 0.0567626953125, mean for epoch: 0.07656415724596441, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 152: 0.08184814453125, mean for epoch: 0.0765989203202097, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 153: 0.0673828125, mean for epoch: 0.0765386843213848, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 154: 0.11138916015625, mean for epoch: 0.07676498611252029, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:36,465] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:36,466] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=38.13813239228988, CurrSamplesPerSec=39.162209806089216, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   3, iteration:   5:   Loss at step 155: 0.0797119140625, mean for epoch: 0.07678399855090726, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 156: 0.07940673828125, mean for epoch: 0.07680081098507612, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 157: 0.05230712890625, mean for epoch: 0.07664480027119824, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 158: 0.06201171875, mean for epoch: 0.07655218583119067, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 159: 0.0679931640625, mean for epoch: 0.07649835550560141, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 160: 0.0810546875, mean for epoch: 0.0765268325805664, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 161: 0.10699462890625, mean for epoch: 0.07671607355153338, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 162: 0.0831298828125, mean for epoch: 0.07675566496672453, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 163: 0.0736083984375, mean for epoch: 0.07673635658310966, mem_alloc: 2342824960\n",
            " Run   3, iteration:   5:   Loss at step 164: 0.058349609375, mean for epoch: 0.07662424227086509, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:37,814] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:37,814] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=38.13687997970278, CurrSamplesPerSec=34.520395515472146, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            "Loss after iteration 5 ; MSE: 0.07659912109375, MAE: 0.2083740234375\n",
            "Connected by ('127.0.0.1', 35078)\n",
            "\u001b[94mReceived training result: b'5;0.07660;0.20837' \u001b[0m\n",
            "Time per iteration 22.321721172332765, memory OrderedDict([('active.all.allocated', 1858646), ('active.all.current', 7), ('active.all.freed', 1858639), ('active.all.peak', 295), ('active.large_pool.allocated', 623152), ('active.large_pool.current', 5), ('active.large_pool.freed', 623147), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 1235494), ('active.small_pool.current', 2), ('active.small_pool.freed', 1235492), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 6048794140160), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 6048743247360), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 5896688674304), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 5896638742016), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 152105465856), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 152104505344), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 6048794140160), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 6048749339136), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 5896688674304), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 5896644833792), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 152105465856), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 152104505344), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1858646), ('allocation.all.current', 6), ('allocation.all.freed', 1858640), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 623152), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 623148), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 1235494), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 1235492), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 794111), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 794107), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 412426), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 412425), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 381685), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 381682), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 3663565530112), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 3663553508352), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 3485285583872), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 3485276795904), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 178279946240), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 178276712448), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            "2342824960\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.040557861328125, mean for epoch: 0.040557861328125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 2: 0.0897216796875, mean for epoch: 0.0651397705078125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 3: 0.059814453125, mean for epoch: 0.06336466471354167, mem_alloc: 2342824960\n",
            "Validation set Loss at step 4: 0.037445068359375, mean for epoch: 0.056884765625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 5: 0.05194091796875, mean for epoch: 0.05589599609375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 6: 0.07452392578125, mean for epoch: 0.059000651041666664, mem_alloc: 2342824960\n",
            "Validation set Loss at step 7: 0.0775146484375, mean for epoch: 0.0616455078125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 8: 0.04718017578125, mean for epoch: 0.05983734130859375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 9: 0.023834228515625, mean for epoch: 0.055836995442708336, mem_alloc: 2342824960\n",
            "Validation set Loss at step 10: 0.06976318359375, mean for epoch: 0.0572296142578125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 11: 0.03973388671875, mean for epoch: 0.055639093572443184, mem_alloc: 2342824960\n",
            "Validation set Loss at step 12: 0.02294921875, mean for epoch: 0.052914937337239586, mem_alloc: 2342824960\n",
            "Validation set Loss at step 13: 0.03948974609375, mean for epoch: 0.051882230318509616, mem_alloc: 2342824960\n",
            "Validation set Loss at step 14: 0.016998291015625, mean for epoch: 0.04939052036830357, mem_alloc: 2342824960\n",
            "Validation set Loss at step 15: 0.049346923828125, mean for epoch: 0.049387613932291664, mem_alloc: 2342824960\n",
            "Validation set Loss at step 16: 0.0257110595703125, mean for epoch: 0.04790782928466797, mem_alloc: 2342824960\n",
            "Validation set Loss at step 17: 0.02728271484375, mean for epoch: 0.046694587258731615, mem_alloc: 2342824960\n",
            "Validation set Loss at step 18: 0.01175689697265625, mean for epoch: 0.04475360446506076, mem_alloc: 2342824960\n",
            "Validation set Loss at step 19: 0.096923828125, mean for epoch: 0.04749940571032072, mem_alloc: 2342824960\n",
            "Validation set Loss at step 20: 0.0183868408203125, mean for epoch: 0.046043777465820314, mem_alloc: 2342824960\n",
            "Validation set Loss at step 21: 0.0128326416015625, mean for epoch: 0.04446229480561756, mem_alloc: 2342824960\n",
            "Validation set Loss at step 22: 0.005687713623046875, mean for epoch: 0.04269981384277344, mem_alloc: 2342824960\n",
            "Validation set Loss at step 23: 0.0101318359375, mean for epoch: 0.04128381480341372, mem_alloc: 2342824960\n",
            "Validation set Loss at step 24: 0.01126861572265625, mean for epoch: 0.040033181508382164, mem_alloc: 2342824960\n",
            "Validation set Loss at step 25: 0.0231170654296875, mean for epoch: 0.039356536865234375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 26: 0.056488037109375, mean for epoch: 0.04001544072077824, mem_alloc: 2342824960\n",
            "Validation set Loss at step 27: 0.0416259765625, mean for epoch: 0.04007509019639757, mem_alloc: 2342824960\n",
            "Validation set Loss at step 28: 0.0302581787109375, mean for epoch: 0.039724486214773994, mem_alloc: 2342824960\n",
            "Validation set Loss at step 29: 0.0055389404296875, mean for epoch: 0.03854567429115032, mem_alloc: 2342824960\n",
            "Validation set Loss at step 30: 0.01090240478515625, mean for epoch: 0.037624231974283856, mem_alloc: 2342824960\n",
            "Validation set Loss at step 31: 0.01512908935546875, mean for epoch: 0.036898582212386594, mem_alloc: 2342824960\n",
            "Validation set Loss at step 32: 0.0162811279296875, mean for epoch: 0.036254286766052246, mem_alloc: 2342824960\n",
            "Validation set Loss at step 33: 0.00614166259765625, mean for epoch: 0.03534178300337358, mem_alloc: 2342824960\n",
            "Validation set Loss at step 34: 0.03179931640625, mean for epoch: 0.03523759280934053, mem_alloc: 2342824960\n",
            "Validation set Loss at step 35: 0.012786865234375, mean for epoch: 0.0345961434500558, mem_alloc: 2342824960\n",
            "Validation set Loss at step 36: 0.0125579833984375, mean for epoch: 0.033983972337510854, mem_alloc: 2342824960\n",
            "Validation set Loss at step 37: 0.0673828125, mean for epoch: 0.034886643693253803, mem_alloc: 2342824960\n",
            "Validation set Loss at step 38: 0.03912353515625, mean for epoch: 0.034998140837016856, mem_alloc: 2342824960\n",
            "Validation set Loss at step 39: 0.0296173095703125, mean for epoch: 0.03486017080453726, mem_alloc: 2342824960\n",
            "Validation set Loss at step 40: 0.01451873779296875, mean for epoch: 0.03435163497924805, mem_alloc: 2342824960\n",
            "Validation set Loss at step 41: 0.01641845703125, mean for epoch: 0.033914240395150536, mem_alloc: 2342824960\n",
            "Validation set Loss at step 42: 0.0084686279296875, mean for epoch: 0.03330839247930618, mem_alloc: 2342824960\n",
            "Validation set Loss at step 43: 0.004421234130859375, mean for epoch: 0.03263659809910974, mem_alloc: 2342824960\n",
            "Validation set Loss at step 44: 0.0194091796875, mean for epoch: 0.032335974953391335, mem_alloc: 2342824960\n",
            "Validation set Loss at step 45: 0.0270843505859375, mean for epoch: 0.03221927218967014, mem_alloc: 2342824960\n",
            "Validation set Loss at step 46: 0.0216217041015625, mean for epoch: 0.03198889027471128, mem_alloc: 2342824960\n",
            "Validation set Loss at step 47: 0.0179595947265625, mean for epoch: 0.031690394624750665, mem_alloc: 2342824960\n",
            "Validation set Loss at step 48: 0.0215911865234375, mean for epoch: 0.031479994455973305, mem_alloc: 2342824960\n",
            "Validation set Loss at step 49: 0.017486572265625, mean for epoch: 0.031194414411272322, mem_alloc: 2342824960\n",
            "Validation set Loss at step 50: 0.03192138671875, mean for epoch: 0.031208953857421874, mem_alloc: 2342824960\n",
            "Validation set Loss at step 51: 0.021697998046875, mean for epoch: 0.031022464527803308, mem_alloc: 2342824960\n",
            "Validation set Loss at step 52: 0.007373809814453125, mean for epoch: 0.030567682706392728, mem_alloc: 2342824960\n",
            "Validation set Loss at step 53: 0.034912109375, mean for epoch: 0.030649653020894754, mem_alloc: 2342824960\n",
            "Validation set Loss at step 54: 0.2401123046875, mean for epoch: 0.03452859101472078, mem_alloc: 2342824960\n",
            "Validation set Loss at step 55: 0.055389404296875, mean for epoch: 0.03490787852894176, mem_alloc: 2342824960\n",
            "Validation set Loss at step 56: 0.07843017578125, mean for epoch: 0.035685062408447266, mem_alloc: 2342824960\n",
            "Validation set Loss at step 57: 0.078369140625, mean for epoch: 0.036433905885930644, mem_alloc: 2342824960\n",
            "Validation set Loss at step 58: 0.041595458984375, mean for epoch: 0.036522898180731414, mem_alloc: 2342824960\n",
            "Validation set Loss at step 59: 0.0228271484375, mean for epoch: 0.036290766829151215, mem_alloc: 2342824960\n",
            "Validation set Loss at step 60: 0.0181884765625, mean for epoch: 0.0359890619913737, mem_alloc: 2342824960\n",
            "Validation set Loss at step 61: 0.02886962890625, mean for epoch: 0.03587234997358479, mem_alloc: 2342824960\n",
            "Validation set Loss at step 62: 0.0340576171875, mean for epoch: 0.03584308008993826, mem_alloc: 2342824960\n",
            "Validation set Loss at step 63: 0.0237274169921875, mean for epoch: 0.035650767977275545, mem_alloc: 2342824960\n",
            "Validation set Loss at step 64: 0.035614013671875, mean for epoch: 0.03565019369125366, mem_alloc: 2342824960\n",
            "Validation set Loss at step 65: 0.00830841064453125, mean for epoch: 0.03522955087515024, mem_alloc: 2342824960\n",
            "Validation set Loss at step 66: 0.0185394287109375, mean for epoch: 0.03497667023629853, mem_alloc: 2342824960\n",
            "Validation set Loss at step 67: 0.00879669189453125, mean for epoch: 0.03458592429089902, mem_alloc: 2342824960\n",
            "Validation set Loss at step 68: 0.02001953125, mean for epoch: 0.034371712628532856, mem_alloc: 2342824960\n",
            "Validation set Loss at step 69: 0.069091796875, mean for epoch: 0.03487490225529325, mem_alloc: 2342824960\n",
            "Validation set Loss at step 70: 0.197998046875, mean for epoch: 0.037205232892717634, mem_alloc: 2342824960\n",
            "Validation set Loss at step 71: 0.12347412109375, mean for epoch: 0.03842028765611245, mem_alloc: 2342824960\n",
            "Validation set Loss at step 72: 0.1759033203125, mean for epoch: 0.04032977422078451, mem_alloc: 2342824960\n",
            "Validation set Loss at step 73: 0.06182861328125, mean for epoch: 0.040624278865448414, mem_alloc: 2342824960\n",
            "Validation set Loss at step 74: 0.0306243896484375, mean for epoch: 0.0404891452273807, mem_alloc: 2342824960\n",
            "Validation set Loss at step 75: 0.0278778076171875, mean for epoch: 0.04032099405924479, mem_alloc: 2342824960\n",
            "Validation set Loss at step 76: 0.0170440673828125, mean for epoch: 0.040014718708239104, mem_alloc: 2342824960\n",
            "Validation set Loss at step 77: 0.045623779296875, mean for epoch: 0.04008756365094866, mem_alloc: 2342824960\n",
            "Validation set Loss at step 78: 0.00933837890625, mean for epoch: 0.039693343333708934, mem_alloc: 2342824960\n",
            "Validation set Loss at step 79: 0.0252685546875, mean for epoch: 0.03951075107236452, mem_alloc: 2342824960\n",
            "Validation set Loss at step 80: 0.01678466796875, mean for epoch: 0.03922667503356934, mem_alloc: 2342824960\n",
            "Validation set Loss at step 81: 0.0151824951171875, mean for epoch: 0.0389298333062066, mem_alloc: 2342824960\n",
            "Validation set Loss at step 82: 0.032867431640625, mean for epoch: 0.03885590157857755, mem_alloc: 2342824960\n",
            "Validation set Loss at step 83: 0.01369476318359375, mean for epoch: 0.038552755332854856, mem_alloc: 2342824960\n",
            "Validation set Loss at step 84: 0.01678466796875, mean for epoch: 0.038293611435663136, mem_alloc: 2342824960\n",
            "Validation set Loss at step 85: 0.0335693359375, mean for epoch: 0.038238031723920034, mem_alloc: 2342824960\n",
            "Validation set Loss at step 86: 0.03289794921875, mean for epoch: 0.038175937741301784, mem_alloc: 2342824960\n",
            "Validation set Loss at step 87: 0.0204010009765625, mean for epoch: 0.037971628123316274, mem_alloc: 2342824960\n",
            "Validation set Loss at step 88: 0.024871826171875, mean for epoch: 0.03782276673750444, mem_alloc: 2342824960\n",
            "Validation set Loss at step 89: 0.030303955078125, mean for epoch: 0.03773828570762377, mem_alloc: 2342824960\n",
            "Loss for validation set  ; MSE: 0.037750244140625, MAE: 0.14990234375\n",
            "Connected by ('127.0.0.1', 35082)\n",
            "\u001b[94mReceived result: b'0.03775;0.14990' \u001b[0m\n",
            "Iteration  1| MSE 0.0688 | MAE 0.2087\n",
            "Iteration  2| MSE 0.0545 | MAE 0.1807\n",
            "Iteration  3| MSE 0.0377 | MAE 0.1499\n",
            "Mean        | MSE 0.0537 | MAE 0.1798\n",
            "[2022-10-25 13:47:43,676] [INFO] [launch.py:318:main] Process 581 exits successfully.\n",
            "[2022-10-25 13:47:44,949] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-25 13:47:44,949] [INFO] [runner.py:507:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --deepspeed_config settings/ds_config_zero.json --data ETTh1 --seq_len 720 --pred_len 24 --dec_seq_len 48 --hidden_size 312 --n_encoder_layers 3 --n_decoder_layers 3 --encoder_attention query_selector_0.8 --decoder_attention full --n_heads 4 --batch_size 48 --embedding_size 96 --iterations 5 --exps 5 --dropout 0.1 --fp16 --deepspeed --features S --input_len 1 --output_len 1 --run_num 4\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-25 13:47:46,812] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-25 13:47:46,813] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Number of parameters: 177\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([24, 4608])\n",
            "torch.Size([24])\n",
            "[2022-10-25 13:47:48,970] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.4, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-25 13:47:48,971] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-25 13:47:48,982] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2022-10-25 13:47:50,812] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.2320725917816162 seconds\n",
            "[2022-10-25 13:47:51,812] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2022-10-25 13:47:51,825] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2022-10-25 13:47:51,825] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2022-10-25 13:47:51,825] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "[2022-10-25 13:47:51,825] [INFO] [stage_1_and_2.py:140:__init__] Reduce bucket size 500000000\n",
            "[2022-10-25 13:47:51,825] [INFO] [stage_1_and_2.py:141:__init__] Allgather bucket size 500000000\n",
            "[2022-10-25 13:47:51,825] [INFO] [stage_1_and_2.py:142:__init__] CPU Offload: False\n",
            "[2022-10-25 13:47:51,825] [INFO] [stage_1_and_2.py:143:__init__] Round robin gradient partitioning: False\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.2386634349822998 seconds\n",
            "Rank: 0 partition count [1] and sizes[(3045720, False)] \n",
            "[2022-10-25 13:47:52,264] [INFO] [utils.py:827:see_memory_usage] Before initializing optimizer states\n",
            "[2022-10-25 13:47:52,265] [INFO] [utils.py:832:see_memory_usage] MA 0.02 GB         Max_MA 0.02 GB         CA 0.04 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:47:52,265] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.41 GB, percent = 19.0%\n",
            "[2022-10-25 13:47:52,325] [INFO] [utils.py:827:see_memory_usage] After initializing optimizer states\n",
            "[2022-10-25 13:47:52,326] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.05 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:47:52,326] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.41 GB, percent = 19.0%\n",
            "[2022-10-25 13:47:52,326] [INFO] [stage_1_and_2.py:523:__init__] optimizer state initialized\n",
            "[2022-10-25 13:47:52,377] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-25 13:47:52,378] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.04 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:47:52,378] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.41 GB, percent = 19.0%\n",
            "[2022-10-25 13:47:52,383] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2022-10-25 13:47:52,383] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2022-10-25 13:47:52,383] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2022-10-25 13:47:52,383] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:52,384] [INFO] [config.py:1002:print] DeepSpeedEngine configuration:\n",
            "[2022-10-25 13:47:52,384] [INFO] [config.py:1006:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-25 13:47:52,384] [INFO] [config.py:1006:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-25 13:47:52,384] [INFO] [config.py:1006:print]   amp_enabled .................. False\n",
            "[2022-10-25 13:47:52,384] [INFO] [config.py:1006:print]   amp_params ................... False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   bfloat16_enabled ............. False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f60d283a510>\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   communication_data_type ...... None\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   curriculum_enabled ........... False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   curriculum_params ............ False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   dataloader_drop_last ......... False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   disable_allgather ............ False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   dump_state ................... False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-25 13:47:52,385] [INFO] [config.py:1006:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   elasticity_enabled ........... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   fp16_auto_cast ............... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   fp16_enabled ................. True\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   global_rank .................. 0\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   gradient_accumulation_steps .. 1\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   gradient_clipping ............ 0.0\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   load_universal_checkpoint .... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   loss_scale ................... 0\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   memory_breakdown ............. False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f60d283a150>\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   optimizer_name ............... adam\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   pld_enabled .................. False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   pld_params ................... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   prescale_gradients ........... False\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   scheduler_name ............... None\n",
            "[2022-10-25 13:47:52,386] [INFO] [config.py:1006:print]   scheduler_params ............. None\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   sparse_attention ............. None\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   steps_per_print .............. 10\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   train_batch_size ............. 5\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   train_micro_batch_size_per_gpu  5\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   world_size ................... 1\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=False allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=False prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   zero_enabled ................. True\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:1006:print]   zero_optimization_stage ...... 2\n",
            "[2022-10-25 13:47:52,387] [INFO] [config.py:997:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 5, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 5e-05, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": false, \n",
            "        \"cpu_offload\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 1000\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0004131793975830078 seconds\n",
            "train 7897\n",
            " Run   4, iteration:   1:   Loss at step 1: 1.0849609375, mean for epoch: 1.0849609375, mem_alloc: 1323024896\n",
            "[2022-10-25 13:47:53,278] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 4294967296\n",
            " Run   4, iteration:   1:   Loss at step 2: 0.90380859375, mean for epoch: 0.994384765625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,403] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
            " Run   4, iteration:   1:   Loss at step 3: 0.98193359375, mean for epoch: 0.990234375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,526] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
            " Run   4, iteration:   1:   Loss at step 4: 0.7197265625, mean for epoch: 0.922607421875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,642] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
            " Run   4, iteration:   1:   Loss at step 5: 1.0126953125, mean for epoch: 0.940625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,763] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
            " Run   4, iteration:   1:   Loss at step 6: 1.115234375, mean for epoch: 0.9697265625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,876] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
            " Run   4, iteration:   1:   Loss at step 7: 0.8720703125, mean for epoch: 0.9557756696428571, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:53,991] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
            " Run   4, iteration:   1:   Loss at step 8: 0.8251953125, mean for epoch: 0.939453125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,107] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
            " Run   4, iteration:   1:   Loss at step 9: 1.283203125, mean for epoch: 0.9776475694444444, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,224] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
            " Run   4, iteration:   1:   Loss at step 10: 1.1484375, mean for epoch: 0.9947265625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,346] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
            "[2022-10-25 13:47:54,347] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=10, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:54,347] [INFO] [timer.py:207:stop] 0/10, RunningAvgSamplesPerSec=43.96947205077194, CurrSamplesPerSec=41.86809610796674, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 11: 0.91748046875, mean for epoch: 0.9877041903409091, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,461] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
            " Run   4, iteration:   1:   Loss at step 12: 0.93212890625, mean for epoch: 0.9830729166666666, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,582] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
            " Run   4, iteration:   1:   Loss at step 13: 0.85498046875, mean for epoch: 0.9732196514423077, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,698] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
            " Run   4, iteration:   1:   Loss at step 14: 0.89404296875, mean for epoch: 0.9675641741071429, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,817] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
            " Run   4, iteration:   1:   Loss at step 15: 0.91796875, mean for epoch: 0.9642578125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:54,932] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            " Run   4, iteration:   1:   Loss at step 16: 0.986328125, mean for epoch: 0.96563720703125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:55,053] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            " Run   4, iteration:   1:   Loss at step 17: 0.8662109375, mean for epoch: 0.9597886029411765, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:55,176] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            " Run   4, iteration:   1:   Loss at step 18: 1.0751953125, mean for epoch: 0.9662000868055556, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:55,295] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            " Run   4, iteration:   1:   Loss at step 19: 1.15234375, mean for epoch: 0.9759971217105263, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 20: 0.8583984375, mean for epoch: 0.9701171875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:55,558] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:55,559] [INFO] [timer.py:207:stop] 0/20, RunningAvgSamplesPerSec=43.102748174808674, CurrSamplesPerSec=38.613974778450654, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 21: 0.6318359375, mean for epoch: 0.9540085565476191, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 22: 0.33935546875, mean for epoch: 0.9260697798295454, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 23: 0.2216796875, mean for epoch: 0.8954441236413043, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 24: 0.309326171875, mean for epoch: 0.8710225423177084, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 25: 0.19921875, mean for epoch: 0.844150390625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 26: 0.23291015625, mean for epoch: 0.8206411508413461, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 27: 0.2099609375, mean for epoch: 0.7980233651620371, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 28: 0.2490234375, mean for epoch: 0.7784162248883929, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 29: 0.254638671875, mean for epoch: 0.7603549299568966, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 30: 0.2069091796875, mean for epoch: 0.74190673828125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:56,885] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:56,886] [INFO] [timer.py:207:stop] 0/30, RunningAvgSamplesPerSec=41.402366495929655, CurrSamplesPerSec=37.24992229060649, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 31: 0.254638671875, mean for epoch: 0.7261884135584677, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 32: 0.214111328125, mean for epoch: 0.7101860046386719, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 33: 0.2139892578125, mean for epoch: 0.6951497395833334, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 34: 0.2330322265625, mean for epoch: 0.6815580480238971, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 35: 0.2445068359375, mean for epoch: 0.6690708705357142, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 36: 0.1365966796875, mean for epoch: 0.6542799207899306, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 37: 0.1671142578125, mean for epoch: 0.64111328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 38: 0.287841796875, mean for epoch: 0.6318166632401315, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 39: 0.140869140625, mean for epoch: 0.6192282652243589, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 40: 0.11962890625, mean for epoch: 0.60673828125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:58,202] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:58,203] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=40.70711416693999, CurrSamplesPerSec=37.51915628270612, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 41: 0.1650390625, mean for epoch: 0.5959651295731707, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 42: 0.1551513671875, mean for epoch: 0.5854695638020834, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 43: 0.15087890625, mean for epoch: 0.5753628043241279, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 44: 0.12286376953125, mean for epoch: 0.5650787353515625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 45: 0.1702880859375, mean for epoch: 0.5563056098090278, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 46: 0.1915283203125, mean for epoch: 0.5483756687330164, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 47: 0.1558837890625, mean for epoch: 0.5400247776761968, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 48: 0.1956787109375, mean for epoch: 0.5328509012858073, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 49: 0.1468505859375, mean for epoch: 0.5249733438297194, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 50: 0.1568603515625, mean for epoch: 0.517611083984375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:47:59,569] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:47:59,570] [INFO] [timer.py:207:stop] 0/50, RunningAvgSamplesPerSec=40.01398734437102, CurrSamplesPerSec=35.9649465795476, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 51: 0.13134765625, mean for epoch: 0.510037291283701, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 52: 0.1312255859375, mean for epoch: 0.5027524507962741, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 53: 0.1412353515625, mean for epoch: 0.4959313734522406, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 54: 0.13232421875, mean for epoch: 0.4891979076244213, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 55: 0.149658203125, mean for epoch: 0.48302445845170455, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 56: 0.168212890625, mean for epoch: 0.47740282331194195, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 57: 0.13916015625, mean for epoch: 0.4714687414336623, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 58: 0.1280517578125, mean for epoch: 0.46554775895743533, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 59: 0.14208984375, mean for epoch: 0.4600654214115466, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 60: 0.1484375, mean for epoch: 0.4548716227213542, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:00,943] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:00,944] [INFO] [timer.py:207:stop] 0/60, RunningAvgSamplesPerSec=39.562053728885736, CurrSamplesPerSec=38.216405439930604, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 61: 0.139404296875, mean for epoch: 0.44970002721567626, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 62: 0.1043701171875, mean for epoch: 0.44413018995715725, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 63: 0.1566162109375, mean for epoch: 0.4395664760044643, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 64: 0.1226806640625, mean for epoch: 0.4346151351928711, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 65: 0.1551513671875, mean for epoch: 0.4303156926081731, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 66: 0.127197265625, mean for epoch: 0.4257229891690341, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 67: 0.153076171875, mean for epoch: 0.42165363368703357, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 68: 0.1282958984375, mean for epoch: 0.4173395493451287, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 69: 0.12005615234375, mean for epoch: 0.41303109431612317, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 70: 0.12890625, mean for epoch: 0.40897216796875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:02,325] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:02,325] [INFO] [timer.py:207:stop] 0/70, RunningAvgSamplesPerSec=39.185182262354076, CurrSamplesPerSec=37.071477183337606, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 71: 0.190185546875, mean for epoch: 0.40589066626320425, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 72: 0.1998291015625, mean for epoch: 0.4030287000868056, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 73: 0.1446533203125, mean for epoch: 0.399489311322774, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 74: 0.1185302734375, mean for epoch: 0.39569256756756754, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 75: 0.12939453125, mean for epoch: 0.39214192708333334, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 76: 0.170166015625, mean for epoch: 0.38922119140625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 77: 0.1199951171875, mean for epoch: 0.38572474888392855, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 78: 0.11041259765625, mean for epoch: 0.38219510591947115, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 79: 0.1656494140625, mean for epoch: 0.3794540212124209, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 80: 0.1295166015625, mean for epoch: 0.3763298034667969, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:03,646] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:03,647] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=39.12397689268127, CurrSamplesPerSec=38.83809005265078, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 81: 0.151123046875, mean for epoch: 0.37354947313850306, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 82: 0.09735107421875, mean for epoch: 0.3701811999809451, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 83: 0.12890625, mean for epoch: 0.36727427287274095, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 84: 0.1551513671875, mean for epoch: 0.3647490001860119, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 85: 0.144775390625, mean for epoch: 0.3621610753676471, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 86: 0.1634521484375, mean for epoch: 0.35985050644985467, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 87: 0.12225341796875, mean for epoch: 0.35711950543283044, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 88: 0.1251220703125, mean for epoch: 0.3544831709428267, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 89: 0.265625, mean for epoch: 0.35348476452773875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 90: 0.1337890625, mean for epoch: 0.351043701171875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:04,963] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:04,963] [INFO] [timer.py:207:stop] 0/90, RunningAvgSamplesPerSec=39.0920811736942, CurrSamplesPerSec=39.54107769437735, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 91: 0.11334228515625, mean for epoch: 0.3484315976991758, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 92: 0.14794921875, mean for epoch: 0.34625244140625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 93: 0.1207275390625, mean for epoch: 0.3438274424563172, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 94: 0.1507568359375, mean for epoch: 0.3417734998337766, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 95: 0.09576416015625, mean for epoch: 0.33918392783717105, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 96: 0.11181640625, mean for epoch: 0.3368155161539714, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 97: 0.10296630859375, mean for epoch: 0.33440469958118557, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 98: 0.1007080078125, mean for epoch: 0.3320200394610969, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 99: 0.178466796875, mean for epoch: 0.33046899660669193, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 100: 0.1353759765625, mean for epoch: 0.32851806640625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:06,291] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:06,291] [INFO] [timer.py:207:stop] 0/100, RunningAvgSamplesPerSec=39.04179779324381, CurrSamplesPerSec=39.37670277344359, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 101: 0.1741943359375, mean for epoch: 0.32699010867883666, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 102: 0.1171875, mean for epoch: 0.3249332203584559, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 103: 0.09716796875, mean for epoch: 0.3227219072360437, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 104: 0.1287841796875, mean for epoch: 0.3208571213942308, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 105: 0.129638671875, mean for epoch: 0.3190359933035714, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 106: 0.19140625, mean for epoch: 0.31783193912146224, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 107: 0.0965576171875, mean for epoch: 0.31576395480432246, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 108: 0.11297607421875, mean for epoch: 0.3138862892433449, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 109: 0.165771484375, mean for epoch: 0.3125274378225344, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 110: 0.09039306640625, mean for epoch: 0.3105080344460227, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:07,616] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:07,617] [INFO] [timer.py:207:stop] 0/110, RunningAvgSamplesPerSec=39.010116411118595, CurrSamplesPerSec=39.75063355680782, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 111: 0.09539794921875, mean for epoch: 0.30857010575028154, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 112: 0.15478515625, mean for epoch: 0.307197025844029, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 113: 0.10980224609375, mean for epoch: 0.30545016938606195, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 114: 0.1566162109375, mean for epoch: 0.3041446083470395, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 115: 0.10400390625, mean for epoch: 0.30240425441576085, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 116: 0.11822509765625, mean for epoch: 0.3008165030643858, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 117: 0.09625244140625, mean for epoch: 0.2990680922809829, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 118: 0.09112548828125, mean for epoch: 0.2973058668233581, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 119: 0.11785888671875, mean for epoch: 0.2957979090073529, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 120: 0.09423828125, mean for epoch: 0.2941182454427083, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:08,970] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:08,970] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=38.92370632916043, CurrSamplesPerSec=37.67181016364584, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 121: 0.0889892578125, mean for epoch: 0.2924229645532025, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 122: 0.1864013671875, mean for epoch: 0.2915539350665984, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 123: 0.1494140625, mean for epoch: 0.2903983263465447, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 124: 0.07855224609375, mean for epoch: 0.2886898902154738, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 125: 0.0941162109375, mean for epoch: 0.28713330078125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 126: 0.10205078125, mean for epoch: 0.28566439189608134, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 127: 0.11492919921875, mean for epoch: 0.2843200203001969, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 128: 0.1304931640625, mean for epoch: 0.28311824798583984, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 129: 0.13134765625, mean for epoch: 0.2819417317708333, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 130: 0.10113525390625, mean for epoch: 0.28055091271033655, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:10,332] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:10,332] [INFO] [timer.py:207:stop] 0/130, RunningAvgSamplesPerSec=38.83677014329498, CurrSamplesPerSec=38.795771807859225, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 131: 0.102783203125, mean for epoch: 0.27919390729365456, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 132: 0.09808349609375, mean for epoch: 0.2778218587239583, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 133: 0.1143798828125, mean for epoch: 0.27659297168703006, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 134: 0.07952880859375, mean for epoch: 0.2751223436042444, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 135: 0.10833740234375, mean for epoch: 0.2738868995949074, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 136: 0.0972900390625, mean for epoch: 0.27258839326746326, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 137: 0.10107421875, mean for epoch: 0.27133646498631386, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 138: 0.10797119140625, mean for epoch: 0.27015265865602356, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 139: 0.0875244140625, mean for epoch: 0.26883878639276076, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 140: 0.09222412109375, mean for epoch: 0.26757725306919644, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:11,681] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:11,682] [INFO] [timer.py:207:stop] 0/140, RunningAvgSamplesPerSec=38.77948337137914, CurrSamplesPerSec=38.831473989242035, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 141: 0.1328125, mean for epoch: 0.26662147467863473, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 142: 0.11785888671875, mean for epoch: 0.2655738508197623, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 143: 0.1112060546875, mean for epoch: 0.2644943557419143, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 144: 0.08319091796875, mean for epoch: 0.26323530409071183, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 145: 0.10906982421875, mean for epoch: 0.26217209388469825, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 146: 0.099365234375, mean for epoch: 0.2610569784086045, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 147: 0.130615234375, mean for epoch: 0.26016961960565477, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 148: 0.08251953125, mean for epoch: 0.25896928117081924, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 149: 0.11126708984375, mean for epoch: 0.25797799129614096, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 150: 0.08941650390625, mean for epoch: 0.256854248046875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:13,072] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:13,073] [INFO] [timer.py:207:stop] 0/150, RunningAvgSamplesPerSec=38.642119451963, CurrSamplesPerSec=35.053077243225985, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 151: 0.1241455078125, mean for epoch: 0.25597538221750826, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 152: 0.09814453125, mean for epoch: 0.2549370213558799, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 153: 0.07470703125, mean for epoch: 0.25375904756433826, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 154: 0.0950927734375, mean for epoch: 0.25272874708299514, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 155: 0.100341796875, mean for epoch: 0.25174560546875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 156: 0.11712646484375, mean for epoch: 0.25088266225961536, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 157: 0.1278076171875, mean for epoch: 0.2500987447750796, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 158: 0.10455322265625, mean for epoch: 0.2491775705844541, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 159: 0.09393310546875, mean for epoch: 0.24820119030070756, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 160: 0.06707763671875, mean for epoch: 0.2470691680908203, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:14,439] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:14,440] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=38.57188776886138, CurrSamplesPerSec=36.51774473560945, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   1:   Loss at step 161: 0.10638427734375, mean for epoch: 0.24619534889363354, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 162: 0.080810546875, mean for epoch: 0.24517445505401234, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 163: 0.09759521484375, mean for epoch: 0.24426906094229295, mem_alloc: 2342824960\n",
            " Run   4, iteration:   1:   Loss at step 164: 0.0751953125, mean for epoch: 0.24323812345179116, mem_alloc: 2342824960\n",
            "Loss after iteration 1 ; MSE: 0.2432861328125, MAE: 0.35009765625\n",
            "Connected by ('127.0.0.1', 51060)\n",
            "\u001b[94mReceived training result: b'1;0.24329;0.35010' \u001b[0m\n",
            "Time per iteration 22.491609573364258, memory OrderedDict([('active.all.allocated', 361654), ('active.all.current', 7), ('active.all.freed', 361647), ('active.all.peak', 295), ('active.large_pool.allocated', 124592), ('active.large_pool.current', 5), ('active.large_pool.freed', 124587), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 237062), ('active.small_pool.current', 2), ('active.small_pool.freed', 237060), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 1208935046656), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 1208884153856), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 1179036943872), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 1178987011584), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 29898102784), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 29897142272), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 1208935046656), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 1208890245632), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 1179036943872), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 1178993103360), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 29898102784), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 29897142272), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 361654), ('allocation.all.current', 6), ('allocation.all.freed', 361648), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 124592), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 124588), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 237062), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 237060), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 155851), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 155847), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 82458), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 82457), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 73393), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 73390), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 731915439104), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 731903417344), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 696765737984), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 696756950016), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 35149701120), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 35146467328), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   4, iteration:   2:   Loss at step 1: 0.0955810546875, mean for epoch: 0.0955810546875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 2: 0.1138916015625, mean for epoch: 0.104736328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 3: 0.09063720703125, mean for epoch: 0.10003662109375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 4: 0.0999755859375, mean for epoch: 0.1000213623046875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 5: 0.086181640625, mean for epoch: 0.09725341796875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 6: 0.100830078125, mean for epoch: 0.09784952799479167, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:15,970] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:15,971] [INFO] [timer.py:207:stop] 0/170, RunningAvgSamplesPerSec=38.4617304939169, CurrSamplesPerSec=36.524422739986555, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 7: 0.08953857421875, mean for epoch: 0.09666224888392858, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 8: 0.10894775390625, mean for epoch: 0.09819793701171875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 9: 0.10113525390625, mean for epoch: 0.09852430555555555, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 10: 0.09027099609375, mean for epoch: 0.097698974609375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 11: 0.118896484375, mean for epoch: 0.09962602095170454, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 12: 0.12744140625, mean for epoch: 0.1019439697265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 13: 0.11932373046875, mean for epoch: 0.10328087439903846, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 14: 0.1260986328125, mean for epoch: 0.10491071428571429, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 15: 0.0628662109375, mean for epoch: 0.10210774739583334, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 16: 0.08258056640625, mean for epoch: 0.10088729858398438, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:17,354] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:17,354] [INFO] [timer.py:207:stop] 0/180, RunningAvgSamplesPerSec=38.375698456101404, CurrSamplesPerSec=34.25168673655878, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 17: 0.10333251953125, mean for epoch: 0.10103113511029412, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 18: 0.0941162109375, mean for epoch: 0.10064697265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 19: 0.0831298828125, mean for epoch: 0.09972502055921052, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 20: 0.09368896484375, mean for epoch: 0.0994232177734375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 21: 0.1375732421875, mean for epoch: 0.10123988560267858, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 22: 0.0877685546875, mean for epoch: 0.10062755237926137, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 23: 0.1307373046875, mean for epoch: 0.10193667204483696, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 24: 0.097900390625, mean for epoch: 0.10176849365234375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 25: 0.095703125, mean for epoch: 0.10152587890625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 26: 0.08392333984375, mean for epoch: 0.10084885817307693, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:18,725] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:18,726] [INFO] [timer.py:207:stop] 0/190, RunningAvgSamplesPerSec=38.32382109859432, CurrSamplesPerSec=37.67167482198415, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 27: 0.10137939453125, mean for epoch: 0.10086850766782407, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 28: 0.10101318359375, mean for epoch: 0.10087367466517858, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 29: 0.075439453125, mean for epoch: 0.09999663254310345, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 30: 0.08355712890625, mean for epoch: 0.09944864908854166, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 31: 0.0733642578125, mean for epoch: 0.09860721711189516, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 32: 0.07086181640625, mean for epoch: 0.09774017333984375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 33: 0.1014404296875, mean for epoch: 0.09785230232007576, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 34: 0.115966796875, mean for epoch: 0.09838508157169118, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 35: 0.07806396484375, mean for epoch: 0.09780447823660714, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 36: 0.08624267578125, mean for epoch: 0.09748331705729167, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:20,108] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:20,109] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=38.261054652243466, CurrSamplesPerSec=36.96438139823458, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 37: 0.0816650390625, mean for epoch: 0.0970557960304054, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 38: 0.09600830078125, mean for epoch: 0.09702823036595394, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 39: 0.1199951171875, mean for epoch: 0.09761712489983974, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 40: 0.10479736328125, mean for epoch: 0.097796630859375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 41: 0.0936279296875, mean for epoch: 0.09769495522103659, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 42: 0.09112548828125, mean for epoch: 0.09753853934151786, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 43: 0.11663818359375, mean for epoch: 0.09798271711482558, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 44: 0.07012939453125, mean for epoch: 0.09734968705610796, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 45: 0.08538818359375, mean for epoch: 0.09708387586805556, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 46: 0.12646484375, mean for epoch: 0.09772259256114131, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:21,497] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:21,497] [INFO] [timer.py:207:stop] 0/210, RunningAvgSamplesPerSec=38.19465243398704, CurrSamplesPerSec=36.02963940329483, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 47: 0.10205078125, mean for epoch: 0.09781468168218085, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 48: 0.07415771484375, mean for epoch: 0.0973218282063802, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 49: 0.086181640625, mean for epoch: 0.09709447743941327, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 50: 0.07830810546875, mean for epoch: 0.09671875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 51: 0.09539794921875, mean for epoch: 0.09669285194546569, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 52: 0.06781005859375, mean for epoch: 0.09613741361177884, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 53: 0.0936279296875, mean for epoch: 0.09609006485849056, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 54: 0.083984375, mean for epoch: 0.09586588541666667, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 55: 0.086669921875, mean for epoch: 0.09569868607954546, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 56: 0.129638671875, mean for epoch: 0.09630475725446429, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:22,882] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:22,882] [INFO] [timer.py:207:stop] 0/220, RunningAvgSamplesPerSec=38.14528652468358, CurrSamplesPerSec=37.358814580460816, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 57: 0.11639404296875, mean for epoch: 0.09665720086348684, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 58: 0.08538818359375, mean for epoch: 0.09646290746228449, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 59: 0.1201171875, mean for epoch: 0.09686382746292373, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 60: 0.092529296875, mean for epoch: 0.09679158528645833, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 61: 0.1246337890625, mean for epoch: 0.09724801485655737, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 62: 0.07598876953125, mean for epoch: 0.09690512380292339, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 63: 0.114013671875, mean for epoch: 0.09717668805803571, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 64: 0.1112060546875, mean for epoch: 0.0973958969116211, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 65: 0.062103271484375, mean for epoch: 0.09685293344350962, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 66: 0.09912109375, mean for epoch: 0.09688729950875948, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:24,276] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:24,277] [INFO] [timer.py:207:stop] 0/230, RunningAvgSamplesPerSec=38.09405601130709, CurrSamplesPerSec=37.87934397803627, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 67: 0.08123779296875, mean for epoch: 0.09665372478428172, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 68: 0.077880859375, mean for epoch: 0.09637765323414522, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 69: 0.0997314453125, mean for epoch: 0.09642625891644022, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 70: 0.11041259765625, mean for epoch: 0.09662606375558036, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 71: 0.0802001953125, mean for epoch: 0.09639471349581866, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 72: 0.11090087890625, mean for epoch: 0.09659618801540798, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 73: 0.11480712890625, mean for epoch: 0.09684565295911815, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 74: 0.0955810546875, mean for epoch: 0.09682856379328547, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 75: 0.08355712890625, mean for epoch: 0.096651611328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 76: 0.1654052734375, mean for epoch: 0.09755626477693256, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:25,653] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:25,654] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=38.05961444677555, CurrSamplesPerSec=35.24524509383765, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 77: 0.09002685546875, mean for epoch: 0.09745848024046266, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 78: 0.09051513671875, mean for epoch: 0.09736946301582532, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 79: 0.07659912109375, mean for epoch: 0.09710654729529272, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 80: 0.101806640625, mean for epoch: 0.09716529846191406, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 81: 0.119140625, mean for epoch: 0.09743659878954475, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 82: 0.102783203125, mean for epoch: 0.09750180128144055, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 83: 0.08636474609375, mean for epoch: 0.09736761989363704, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 84: 0.0927734375, mean for epoch: 0.09731292724609375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 85: 0.07452392578125, mean for epoch: 0.09704482134650735, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 86: 0.07470703125, mean for epoch: 0.09678507960119913, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:27,020] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:27,021] [INFO] [timer.py:207:stop] 0/250, RunningAvgSamplesPerSec=38.04034119929989, CurrSamplesPerSec=36.7504253943331, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 87: 0.0828857421875, mean for epoch: 0.09662531710219109, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 88: 0.080810546875, mean for epoch: 0.09644560380415483, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 89: 0.09979248046875, mean for epoch: 0.0964832091599368, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 90: 0.10394287109375, mean for epoch: 0.09656609429253472, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 91: 0.0751953125, mean for epoch: 0.09633125053657281, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 92: 0.0987548828125, mean for epoch: 0.09635759436565897, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 93: 0.0679931640625, mean for epoch: 0.09605260049143145, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 94: 0.1075439453125, mean for epoch: 0.09617484884059176, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 95: 0.09747314453125, mean for epoch: 0.09618851511101974, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 96: 0.0589599609375, mean for epoch: 0.09580071767171223, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:28,379] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:28,380] [INFO] [timer.py:207:stop] 0/260, RunningAvgSamplesPerSec=38.03274116065366, CurrSamplesPerSec=36.33357242105774, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 97: 0.102783203125, mean for epoch: 0.09587270205782861, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 98: 0.0792236328125, mean for epoch: 0.09570281359614158, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 99: 0.068603515625, mean for epoch: 0.09542908331360479, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 100: 0.0986328125, mean for epoch: 0.09546112060546875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 101: 0.10479736328125, mean for epoch: 0.09555355865176361, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 102: 0.07904052734375, mean for epoch: 0.09539166618795956, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 103: 0.08721923828125, mean for epoch: 0.09531232222770024, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 104: 0.1044921875, mean for epoch: 0.09540059016301082, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 105: 0.11627197265625, mean for epoch: 0.095599365234375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 106: 0.08935546875, mean for epoch: 0.09554046055056015, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:29,738] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:29,738] [INFO] [timer.py:207:stop] 0/270, RunningAvgSamplesPerSec=38.02214015749608, CurrSamplesPerSec=37.43604024305779, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 107: 0.07391357421875, mean for epoch: 0.09533834011755257, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 108: 0.0830078125, mean for epoch: 0.0952241685655382, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 109: 0.136474609375, mean for epoch: 0.09560261297663418, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 110: 0.1064453125, mean for epoch: 0.09570118297230114, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 111: 0.08428955078125, mean for epoch: 0.09559837547508446, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 112: 0.07635498046875, mean for epoch: 0.09542655944824219, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 113: 0.06829833984375, mean for epoch: 0.09518648670837943, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 114: 0.07391357421875, mean for epoch: 0.09499988221285637, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 115: 0.093505859375, mean for epoch: 0.09498689070991848, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 116: 0.07562255859375, mean for epoch: 0.0948199568123653, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:31,133] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:31,134] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=37.972888705371055, CurrSamplesPerSec=37.37672545158042, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 117: 0.1123046875, mean for epoch: 0.09496939895499466, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 118: 0.08551025390625, mean for epoch: 0.09488923670881885, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 119: 0.07354736328125, mean for epoch: 0.0947098932346376, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 120: 0.08831787109375, mean for epoch: 0.09465662638346355, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 121: 0.1024169921875, mean for epoch: 0.09472076163804236, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 122: 0.0772705078125, mean for epoch: 0.09457772677061987, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 123: 0.1097412109375, mean for epoch: 0.0947010071297002, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 124: 0.11260986328125, mean for epoch: 0.09484543338898689, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 125: 0.09930419921875, mean for epoch: 0.094881103515625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 126: 0.08050537109375, mean for epoch: 0.09476701040116567, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:32,504] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:32,504] [INFO] [timer.py:207:stop] 0/290, RunningAvgSamplesPerSec=37.95571324880992, CurrSamplesPerSec=37.86730610888815, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 127: 0.07733154296875, mean for epoch: 0.09462972325602854, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 128: 0.08526611328125, mean for epoch: 0.09455657005310059, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 129: 0.1019287109375, mean for epoch: 0.09461371843204942, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 130: 0.09197998046875, mean for epoch: 0.0945934589092548, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 131: 0.09820556640625, mean for epoch: 0.09462103224892653, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 132: 0.0648193359375, mean for epoch: 0.09439526182232481, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 133: 0.1026611328125, mean for epoch: 0.09445741122826598, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 134: 0.1597900390625, mean for epoch: 0.09494496815240205, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 135: 0.10443115234375, mean for epoch: 0.09501523618344908, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 136: 0.11785888671875, mean for epoch: 0.09518320420209099, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:33,873] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:33,873] [INFO] [timer.py:207:stop] 0/300, RunningAvgSamplesPerSec=37.94200790280086, CurrSamplesPerSec=37.19178896031922, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 137: 0.09130859375, mean for epoch: 0.09515492237397354, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 138: 0.08349609375, mean for epoch: 0.09507043810858243, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 139: 0.10791015625, mean for epoch: 0.09516281018154227, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 140: 0.1287841796875, mean for epoch: 0.09540296282087053, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 141: 0.07696533203125, mean for epoch: 0.09527219948193706, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 142: 0.0865478515625, mean for epoch: 0.09521076041208186, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 143: 0.12469482421875, mean for epoch: 0.09541694267646417, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 144: 0.1434326171875, mean for epoch: 0.09575038486056858, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 145: 0.10833740234375, mean for epoch: 0.09583719187769396, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 146: 0.11273193359375, mean for epoch: 0.09595290928670805, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:35,257] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:35,258] [INFO] [timer.py:207:stop] 0/310, RunningAvgSamplesPerSec=37.91773042474441, CurrSamplesPerSec=38.02674190471701, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 147: 0.1024169921875, mean for epoch: 0.09599688263977466, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 148: 0.09991455078125, mean for epoch: 0.09602335337046031, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 149: 0.08453369140625, mean for epoch: 0.09594624154519715, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 150: 0.05902099609375, mean for epoch: 0.0957000732421875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 151: 0.1328125, mean for epoch: 0.09594585090283526, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 152: 0.0667724609375, mean for epoch: 0.0957539207056949, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 153: 0.072021484375, mean for epoch: 0.09559880674274918, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 154: 0.05401611328125, mean for epoch: 0.09532878925273945, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 155: 0.10699462890625, mean for epoch: 0.095404052734375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 156: 0.061431884765625, mean for epoch: 0.09518628242688301, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:36,638] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:36,639] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=37.89380413539409, CurrSamplesPerSec=37.25740030770215, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   2:   Loss at step 157: 0.08795166015625, mean for epoch: 0.09514020203025478, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 158: 0.1163330078125, mean for epoch: 0.09527433371242089, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 159: 0.0982666015625, mean for epoch: 0.09529315300707547, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 160: 0.0833740234375, mean for epoch: 0.09521865844726562, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 161: 0.10833740234375, mean for epoch: 0.09530014132861025, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 162: 0.08331298828125, mean for epoch: 0.09522614655671297, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 163: 0.07470703125, mean for epoch: 0.09510026241372699, mem_alloc: 2342824960\n",
            " Run   4, iteration:   2:   Loss at step 164: 0.11798095703125, mean for epoch: 0.09523977884432165, mem_alloc: 2342824960\n",
            "Loss after iteration 2 ; MSE: 0.09521484375, MAE: 0.234619140625\n",
            "Connected by ('127.0.0.1', 39802)\n",
            "\u001b[94mReceived training result: b'2;0.09521;0.23462' \u001b[0m\n",
            "Time per iteration 22.61087679862976, memory OrderedDict([('active.all.allocated', 735902), ('active.all.current', 7), ('active.all.freed', 735895), ('active.all.peak', 295), ('active.large_pool.allocated', 249232), ('active.large_pool.current', 5), ('active.large_pool.freed', 249227), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 486670), ('active.small_pool.current', 2), ('active.small_pool.freed', 486668), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 2418899820032), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 2418848927232), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 2358449876480), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 2358399944192), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 60449943552), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 60448983040), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 2418899820032), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 2418855019008), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 2358449876480), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 2358406035968), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 60449943552), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 60448983040), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 735902), ('allocation.all.current', 6), ('allocation.all.freed', 735896), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 249232), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 249228), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 486670), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 486668), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 315416), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 315412), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 164950), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 164949), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 150466), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 150463), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 1464827961856), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 1464815940096), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 1393895699456), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 1393886911488), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 70932262400), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 70929028608), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   4, iteration:   3:   Loss at step 1: 0.08087158203125, mean for epoch: 0.08087158203125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 2: 0.08148193359375, mean for epoch: 0.0811767578125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:38,146] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:38,147] [INFO] [timer.py:207:stop] 0/330, RunningAvgSamplesPerSec=37.88077394169018, CurrSamplesPerSec=38.5779615683187, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 3: 0.1153564453125, mean for epoch: 0.09256998697916667, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 4: 0.07940673828125, mean for epoch: 0.0892791748046875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 5: 0.09686279296875, mean for epoch: 0.0907958984375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 6: 0.06817626953125, mean for epoch: 0.08702596028645833, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 7: 0.0811767578125, mean for epoch: 0.08619035993303571, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 8: 0.076416015625, mean for epoch: 0.08496856689453125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 9: 0.0999755859375, mean for epoch: 0.0866360134548611, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 10: 0.08294677734375, mean for epoch: 0.08626708984375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 11: 0.0950927734375, mean for epoch: 0.08706942471590909, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 12: 0.0762939453125, mean for epoch: 0.08617146809895833, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:39,506] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:39,507] [INFO] [timer.py:207:stop] 0/340, RunningAvgSamplesPerSec=37.87606765217371, CurrSamplesPerSec=38.52537677549251, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 13: 0.06683349609375, mean for epoch: 0.08468393179086539, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 14: 0.087158203125, mean for epoch: 0.08486066545758929, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 15: 0.075439453125, mean for epoch: 0.08423258463541666, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 16: 0.07293701171875, mean for epoch: 0.083526611328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 17: 0.065673828125, mean for epoch: 0.08247644761029412, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 18: 0.11578369140625, mean for epoch: 0.08432685004340278, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 19: 0.09112548828125, mean for epoch: 0.08468467310855263, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 20: 0.06378173828125, mean for epoch: 0.0836395263671875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 21: 0.10009765625, mean for epoch: 0.08442324683779762, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 22: 0.090087890625, mean for epoch: 0.08468073064630682, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:40,881] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:40,881] [INFO] [timer.py:207:stop] 0/350, RunningAvgSamplesPerSec=37.858365602380935, CurrSamplesPerSec=37.723717630467476, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 23: 0.08001708984375, mean for epoch: 0.08447796365489131, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 24: 0.07427978515625, mean for epoch: 0.08405303955078125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 25: 0.0987548828125, mean for epoch: 0.08464111328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 26: 0.08404541015625, mean for epoch: 0.08461820162259616, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 27: 0.08367919921875, mean for epoch: 0.08458342375578703, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 28: 0.09942626953125, mean for epoch: 0.085113525390625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 29: 0.09832763671875, mean for epoch: 0.08556918440193965, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 30: 0.09210205078125, mean for epoch: 0.08578694661458333, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 31: 0.10052490234375, mean for epoch: 0.08626236454133064, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 32: 0.06829833984375, mean for epoch: 0.08570098876953125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:42,277] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:42,277] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=37.8286315068077, CurrSamplesPerSec=36.83194469812991, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 33: 0.0714111328125, mean for epoch: 0.08526796283143939, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 34: 0.08038330078125, mean for epoch: 0.08512429630055147, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 35: 0.1007080078125, mean for epoch: 0.08556954520089285, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 36: 0.1033935546875, mean for epoch: 0.08606465657552083, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 37: 0.11126708984375, mean for epoch: 0.08674580342060811, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 38: 0.083251953125, mean for epoch: 0.08665385999177631, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 39: 0.09912109375, mean for epoch: 0.08697353265224358, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 40: 0.101806640625, mean for epoch: 0.0873443603515625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 41: 0.08428955078125, mean for epoch: 0.08726985280106707, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 42: 0.09844970703125, mean for epoch: 0.08753603980654762, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:43,631] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:43,632] [INFO] [timer.py:207:stop] 0/370, RunningAvgSamplesPerSec=37.82774261204841, CurrSamplesPerSec=36.70122433550573, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 43: 0.08782958984375, mean for epoch: 0.08754286655159883, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 44: 0.0914306640625, mean for epoch: 0.0876312255859375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 45: 0.08245849609375, mean for epoch: 0.08751627604166666, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 46: 0.1380615234375, mean for epoch: 0.08861508576766304, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 47: 0.08392333984375, mean for epoch: 0.0885152613863032, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 48: 0.0843505859375, mean for epoch: 0.08842849731445312, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 49: 0.1263427734375, mean for epoch: 0.08920225805165816, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 50: 0.09490966796875, mean for epoch: 0.08931640625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 51: 0.09869384765625, mean for epoch: 0.08950027765012254, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 52: 0.100341796875, mean for epoch: 0.08970876840444711, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:45,007] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:45,009] [INFO] [timer.py:207:stop] 0/380, RunningAvgSamplesPerSec=37.818334160880106, CurrSamplesPerSec=36.93215858720517, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 53: 0.07586669921875, mean for epoch: 0.08944759728773585, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 54: 0.07391357421875, mean for epoch: 0.08915993019386574, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 55: 0.09661865234375, mean for epoch: 0.08929554332386364, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 56: 0.117919921875, mean for epoch: 0.08980669294084821, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 57: 0.1314697265625, mean for epoch: 0.09053762335526316, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 58: 0.08868408203125, mean for epoch: 0.09050566574622845, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 59: 0.0826416015625, mean for epoch: 0.09037237652277542, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 60: 0.11181640625, mean for epoch: 0.09072977701822917, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 61: 0.09429931640625, mean for epoch: 0.09078829405737705, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 62: 0.08123779296875, mean for epoch: 0.0906342537172379, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:46,381] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:46,381] [INFO] [timer.py:207:stop] 0/390, RunningAvgSamplesPerSec=37.80983525153565, CurrSamplesPerSec=35.367750726866745, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 63: 0.07666015625, mean for epoch: 0.09041244264632936, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 64: 0.06298828125, mean for epoch: 0.08998394012451172, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 65: 0.12420654296875, mean for epoch: 0.09051044170673077, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 66: 0.08837890625, mean for epoch: 0.09047814571496213, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 67: 0.08123779296875, mean for epoch: 0.09034023000233209, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 68: 0.0859375, mean for epoch: 0.09027548397288603, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 69: 0.08001708984375, mean for epoch: 0.0901268115942029, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 70: 0.10894775390625, mean for epoch: 0.09039568219866072, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 71: 0.07763671875, mean for epoch: 0.0902159784881162, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 72: 0.07110595703125, mean for epoch: 0.0899505615234375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:47,742] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:47,743] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=37.80807889566843, CurrSamplesPerSec=38.1368316536401, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 73: 0.071044921875, mean for epoch: 0.0896915801583904, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 74: 0.106689453125, mean for epoch: 0.08992128114442567, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 75: 0.09210205078125, mean for epoch: 0.08995035807291667, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 76: 0.060699462890625, mean for epoch: 0.08956547787314967, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 77: 0.10650634765625, mean for epoch: 0.08978548916903409, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 78: 0.10302734375, mean for epoch: 0.08995525653545673, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 79: 0.07244873046875, mean for epoch: 0.08973365493967564, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 80: 0.08233642578125, mean for epoch: 0.08964118957519532, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 81: 0.06829833984375, mean for epoch: 0.08937769760320216, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 82: 0.08905029296875, mean for epoch: 0.08937370486375762, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:49,103] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:49,103] [INFO] [timer.py:207:stop] 0/410, RunningAvgSamplesPerSec=37.8051504577916, CurrSamplesPerSec=37.11024678206521, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 83: 0.09027099609375, mean for epoch: 0.08938451560146837, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 84: 0.06658935546875, mean for epoch: 0.08911314464750744, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 85: 0.08709716796875, mean for epoch: 0.08908942727481618, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 86: 0.070556640625, mean for epoch: 0.08887392975563227, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 87: 0.1038818359375, mean for epoch: 0.08904643442438936, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 88: 0.08929443359375, mean for epoch: 0.08904925259676846, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 89: 0.0860595703125, mean for epoch: 0.08901566066099016, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 90: 0.08978271484375, mean for epoch: 0.08902418348524306, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 91: 0.0948486328125, mean for epoch: 0.08908818842290522, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 92: 0.09307861328125, mean for epoch: 0.0891315626061481, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:50,491] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:50,491] [INFO] [timer.py:207:stop] 0/420, RunningAvgSamplesPerSec=37.78722210491375, CurrSamplesPerSec=38.84585961305141, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 93: 0.08990478515625, mean for epoch: 0.08913987682711694, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 94: 0.07208251953125, mean for epoch: 0.08895841557928856, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 95: 0.07080078125, mean for epoch: 0.08876728258634868, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 96: 0.11248779296875, mean for epoch: 0.08901437123616536, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 97: 0.0802001953125, mean for epoch: 0.08892350344313789, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 98: 0.09716796875, mean for epoch: 0.08900763064014669, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 99: 0.08892822265625, mean for epoch: 0.08900682853929924, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 100: 0.07757568359375, mean for epoch: 0.08889251708984375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 101: 0.11663818359375, mean for epoch: 0.08916722665918936, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 102: 0.07342529296875, mean for epoch: 0.08901289397594976, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:51,866] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:51,867] [INFO] [timer.py:207:stop] 0/430, RunningAvgSamplesPerSec=37.778353911704926, CurrSamplesPerSec=38.07154462689141, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 103: 0.119873046875, mean for epoch: 0.08931250711089199, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 104: 0.07318115234375, mean for epoch: 0.0891573979304387, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 105: 0.0765380859375, mean for epoch: 0.08903721400669642, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 106: 0.07220458984375, mean for epoch: 0.08887841566553656, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 107: 0.09014892578125, mean for epoch: 0.08889028959185163, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 108: 0.0655517578125, mean for epoch: 0.08867419207537616, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 109: 0.075439453125, mean for epoch: 0.0885527724519782, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 110: 0.075439453125, mean for epoch: 0.0884335604580966, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 111: 0.08795166015625, mean for epoch: 0.08842921901393581, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 112: 0.054534912109375, mean for epoch: 0.08812659127371651, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:53,237] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:53,238] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=37.77228375912399, CurrSamplesPerSec=36.12901447467707, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 113: 0.06915283203125, mean for epoch: 0.08795868189988938, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 114: 0.103759765625, mean for epoch: 0.08809728789747807, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 115: 0.05535888671875, mean for epoch: 0.08781260614809783, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 116: 0.07012939453125, mean for epoch: 0.08766016466864224, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 117: 0.10760498046875, mean for epoch: 0.08783063317975427, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 118: 0.06170654296875, mean for epoch: 0.08760924258474577, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 119: 0.080322265625, mean for epoch: 0.0875480074842437, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 120: 0.07891845703125, mean for epoch: 0.08747609456380208, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 121: 0.07916259765625, mean for epoch: 0.08740738797778926, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 122: 0.07861328125, mean for epoch: 0.0873353051357582, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:54,613] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:54,614] [INFO] [timer.py:207:stop] 0/450, RunningAvgSamplesPerSec=37.762527279561006, CurrSamplesPerSec=38.4342962286904, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 123: 0.08349609375, mean for epoch: 0.08730409203506098, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 124: 0.082275390625, mean for epoch: 0.08726353799143145, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 125: 0.09393310546875, mean for epoch: 0.08731689453125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 126: 0.0645751953125, mean for epoch: 0.08713640485491071, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 127: 0.07183837890625, mean for epoch: 0.08701594795767717, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 128: 0.1015625, mean for epoch: 0.08712959289550781, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 129: 0.07989501953125, mean for epoch: 0.0870735109314438, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 130: 0.07635498046875, mean for epoch: 0.08699106069711539, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 131: 0.08203125, mean for epoch: 0.08695319954675572, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 132: 0.086181640625, mean for epoch: 0.08694735440340909, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:55,996] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:55,997] [INFO] [timer.py:207:stop] 0/460, RunningAvgSamplesPerSec=37.751582222018435, CurrSamplesPerSec=37.9647172765865, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 133: 0.061431884765625, mean for epoch: 0.08675550876703478, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 134: 0.10516357421875, mean for epoch: 0.08689288238980877, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 135: 0.08502197265625, mean for epoch: 0.08687902379918981, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 136: 0.0838623046875, mean for epoch: 0.08685684204101562, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 137: 0.06451416015625, mean for epoch: 0.08669375677178376, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 138: 0.07196044921875, mean for epoch: 0.08658699367357336, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 139: 0.080322265625, mean for epoch: 0.0865419236876124, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 140: 0.10711669921875, mean for epoch: 0.08668888636997768, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 141: 0.08026123046875, mean for epoch: 0.08664330015791223, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 142: 0.09210205078125, mean for epoch: 0.08668174206371039, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:57,362] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:57,362] [INFO] [timer.py:207:stop] 0/470, RunningAvgSamplesPerSec=37.75212163930871, CurrSamplesPerSec=36.676833533872454, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 143: 0.0972900390625, mean for epoch: 0.08675592595880682, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 144: 0.08343505859375, mean for epoch: 0.08673286437988281, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 145: 0.10247802734375, mean for epoch: 0.08684145171066811, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 146: 0.0828857421875, mean for epoch: 0.08681435780982448, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 147: 0.10430908203125, mean for epoch: 0.08693336953922194, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 148: 0.1072998046875, mean for epoch: 0.08707098058752112, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 149: 0.057708740234375, mean for epoch: 0.08687391857172819, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 150: 0.08392333984375, mean for epoch: 0.086854248046875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 151: 0.07855224609375, mean for epoch: 0.08679926790149006, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 152: 0.09326171875, mean for epoch: 0.08684178402549342, mem_alloc: 2342824960\n",
            "[2022-10-25 13:48:58,721] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:48:58,722] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=37.75258489972462, CurrSamplesPerSec=38.63303852523492, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 153: 0.06768798828125, mean for epoch: 0.0867165958180147, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 154: 0.08282470703125, mean for epoch: 0.08669132381290584, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 155: 0.0726318359375, mean for epoch: 0.08660061743951612, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 156: 0.07489013671875, mean for epoch: 0.08652555025540866, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 157: 0.071533203125, mean for epoch: 0.08643005759852707, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 158: 0.07867431640625, mean for epoch: 0.0863809706289557, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 159: 0.08355712890625, mean for epoch: 0.08636321061812106, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 160: 0.06268310546875, mean for epoch: 0.0862152099609375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 161: 0.1112060546875, mean for epoch: 0.08637043259899069, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 162: 0.07379150390625, mean for epoch: 0.0862927848910108, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:00,064] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:00,065] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=37.760132952128274, CurrSamplesPerSec=37.598529873156735, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   3:   Loss at step 163: 0.07818603515625, mean for epoch: 0.08624305023006135, mem_alloc: 2342824960\n",
            " Run   4, iteration:   3:   Loss at step 164: 0.058807373046875, mean for epoch: 0.08607575951552973, mem_alloc: 2342824960\n",
            "Loss after iteration 3 ; MSE: 0.0860595703125, MAE: 0.2215576171875\n",
            "Connected by ('127.0.0.1', 46318)\n",
            "\u001b[94mReceived training result: b'3;0.08606;0.22156' \u001b[0m\n",
            "Time per iteration 22.62619638442993, memory OrderedDict([('active.all.allocated', 1110150), ('active.all.current', 7), ('active.all.freed', 1110143), ('active.all.peak', 295), ('active.large_pool.allocated', 373872), ('active.large_pool.current', 5), ('active.large_pool.freed', 373867), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 736278), ('active.small_pool.current', 2), ('active.small_pool.freed', 736276), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 3628864593408), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 3628813700608), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 3537862809088), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 3537812876800), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 91001784320), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 91000823808), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 3628864593408), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 3628819792384), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 3537862809088), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 3537818968576), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 91001784320), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 91000823808), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1110150), ('allocation.all.current', 6), ('allocation.all.freed', 1110144), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 373872), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 373868), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 736278), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 736276), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 474981), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 474977), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 247442), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 247441), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 227539), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 227536), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2197740484608), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2197728462848), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2091025660928), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2091016872960), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 106714823680), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 106711589888), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   4, iteration:   4:   Loss at step 1: 0.090087890625, mean for epoch: 0.090087890625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 2: 0.0845947265625, mean for epoch: 0.08734130859375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 3: 0.08050537109375, mean for epoch: 0.08506266276041667, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 4: 0.11798095703125, mean for epoch: 0.093292236328125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 5: 0.08685302734375, mean for epoch: 0.09200439453125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 6: 0.079833984375, mean for epoch: 0.08997599283854167, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 7: 0.08331298828125, mean for epoch: 0.08902413504464286, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 8: 0.0711669921875, mean for epoch: 0.0867919921875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:01,635] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:01,636] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=37.73218675381071, CurrSamplesPerSec=36.57965746340119, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 9: 0.09185791015625, mean for epoch: 0.08735487196180555, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 10: 0.10186767578125, mean for epoch: 0.08880615234375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 11: 0.0811767578125, mean for epoch: 0.08811257102272728, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 12: 0.0806884765625, mean for epoch: 0.087493896484375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 13: 0.0672607421875, mean for epoch: 0.0859375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 14: 0.080078125, mean for epoch: 0.08551897321428571, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 15: 0.0716552734375, mean for epoch: 0.0845947265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 16: 0.0899658203125, mean for epoch: 0.084930419921875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 17: 0.046722412109375, mean for epoch: 0.08268289005055147, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 18: 0.07269287109375, mean for epoch: 0.08212788899739583, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:02,998] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:02,999] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=37.73206450324326, CurrSamplesPerSec=38.60111027668566, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 19: 0.08740234375, mean for epoch: 0.08240549187911184, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 20: 0.0726318359375, mean for epoch: 0.08191680908203125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 21: 0.1068115234375, mean for epoch: 0.0831022716703869, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 22: 0.06451416015625, mean for epoch: 0.08225735751065341, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 23: 0.08551025390625, mean for epoch: 0.08239878778872282, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 24: 0.081298828125, mean for epoch: 0.0823529561360677, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 25: 0.07916259765625, mean for epoch: 0.082225341796875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 26: 0.07574462890625, mean for epoch: 0.08197608360877404, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 27: 0.07012939453125, mean for epoch: 0.08153731734664352, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 28: 0.050933837890625, mean for epoch: 0.0804443359375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:04,381] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:04,382] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=37.72282842750954, CurrSamplesPerSec=36.83246220423762, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 29: 0.07757568359375, mean for epoch: 0.0803454168911638, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 30: 0.0726318359375, mean for epoch: 0.08008829752604167, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 31: 0.061309814453125, mean for epoch: 0.07948254000756048, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 32: 0.0859375, mean for epoch: 0.07968425750732422, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 33: 0.0970458984375, mean for epoch: 0.08021036783854167, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 34: 0.07635498046875, mean for epoch: 0.08009697409237132, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 35: 0.07806396484375, mean for epoch: 0.08003888811383929, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 36: 0.06365966796875, mean for epoch: 0.0795839097764757, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 37: 0.06787109375, mean for epoch: 0.07926734718116554, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 38: 0.12939453125, mean for epoch: 0.0805864836040296, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:05,778] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:05,779] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=37.7061479770573, CurrSamplesPerSec=35.97623716177154, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 39: 0.0950927734375, mean for epoch: 0.08095843975360577, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 40: 0.07415771484375, mean for epoch: 0.08078842163085938, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 41: 0.08209228515625, mean for epoch: 0.08082022318025915, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 42: 0.06884765625, mean for epoch: 0.08053516206287202, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 43: 0.07598876953125, mean for epoch: 0.08042943200399709, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 44: 0.06622314453125, mean for epoch: 0.08010656183416193, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 45: 0.0640869140625, mean for epoch: 0.07975056966145834, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 46: 0.05316162109375, mean for epoch: 0.07917254904042119, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 47: 0.06915283203125, mean for epoch: 0.07895936357214096, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 48: 0.09136962890625, mean for epoch: 0.07921791076660156, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:07,150] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:07,150] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=37.69939990250469, CurrSamplesPerSec=37.747618670487356, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 49: 0.0751953125, mean for epoch: 0.07913581692442602, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 50: 0.07354736328125, mean for epoch: 0.0790240478515625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 51: 0.0794677734375, mean for epoch: 0.07903274835324754, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 52: 0.064208984375, mean for epoch: 0.07874767596905048, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 53: 0.0723876953125, mean for epoch: 0.07862767633402122, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 54: 0.07293701171875, mean for epoch: 0.07852229365596065, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 55: 0.07476806640625, mean for epoch: 0.07845403497869319, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 56: 0.07171630859375, mean for epoch: 0.07833371843610491, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 57: 0.08563232421875, mean for epoch: 0.07846176415158991, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 58: 0.06866455078125, mean for epoch: 0.0782928466796875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:08,531] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:08,531] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=37.69171498313429, CurrSamplesPerSec=36.12689837656073, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 59: 0.07489013671875, mean for epoch: 0.07823517362950212, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 60: 0.09619140625, mean for epoch: 0.07853444417317708, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 61: 0.080322265625, mean for epoch: 0.07856375272156763, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 62: 0.09619140625, mean for epoch: 0.07884806971396169, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 63: 0.09063720703125, mean for epoch: 0.07903519887772817, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 64: 0.0660400390625, mean for epoch: 0.07883214950561523, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 65: 0.081298828125, mean for epoch: 0.07887009840745192, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 66: 0.08905029296875, mean for epoch: 0.0790243437795928, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 67: 0.082275390625, mean for epoch: 0.07907286686683769, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 68: 0.08612060546875, mean for epoch: 0.07917651008157169, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:09,902] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:09,902] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=37.68686535158177, CurrSamplesPerSec=38.18314564803772, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 69: 0.07867431640625, mean for epoch: 0.07916923191236414, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 70: 0.08404541015625, mean for epoch: 0.0792388916015625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 71: 0.075927734375, mean for epoch: 0.07919225558428697, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 72: 0.08636474609375, mean for epoch: 0.07929187350802952, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 73: 0.10968017578125, mean for epoch: 0.0797081516213613, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 74: 0.0704345703125, mean for epoch: 0.07958283295502534, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 75: 0.0826416015625, mean for epoch: 0.07962361653645833, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 76: 0.08575439453125, mean for epoch: 0.07970428466796875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 77: 0.08734130859375, mean for epoch: 0.079803466796875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 78: 0.0816650390625, mean for epoch: 0.07982733310797276, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:11,266] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:11,266] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=37.68498620635338, CurrSamplesPerSec=38.83003601284983, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 79: 0.09271240234375, mean for epoch: 0.07999043525019779, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 80: 0.07061767578125, mean for epoch: 0.07987327575683593, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 81: 0.09600830078125, mean for epoch: 0.08007247359664352, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 82: 0.07769775390625, mean for epoch: 0.08004351360041921, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 83: 0.1348876953125, mean for epoch: 0.08070428687405873, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 84: 0.05401611328125, mean for epoch: 0.08038657052176339, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 85: 0.062408447265625, mean for epoch: 0.08017506318933823, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 86: 0.08453369140625, mean for epoch: 0.08022574491279069, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 87: 0.094970703125, mean for epoch: 0.08039522719109195, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 88: 0.08642578125, mean for epoch: 0.08046375621448863, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:12,634] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:12,634] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=37.680732330684506, CurrSamplesPerSec=37.06165006936406, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 89: 0.10931396484375, mean for epoch: 0.08078791586200842, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 90: 0.0718994140625, mean for epoch: 0.08068915473090278, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 91: 0.09869384765625, mean for epoch: 0.08088700849931318, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 92: 0.1185302734375, mean for epoch: 0.08129617442255435, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 93: 0.054595947265625, mean for epoch: 0.08100907520581317, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 94: 0.070068359375, mean for epoch: 0.08089268461186835, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 95: 0.058563232421875, mean for epoch: 0.08065763774671053, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 96: 0.0819091796875, mean for epoch: 0.08067067464192708, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 97: 0.069580078125, mean for epoch: 0.08055633859536082, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 98: 0.099609375, mean for epoch: 0.08075075733418367, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:14,027] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:14,027] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=37.66838180792733, CurrSamplesPerSec=37.41566919595148, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 99: 0.07427978515625, mean for epoch: 0.08068539397885101, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 100: 0.07281494140625, mean for epoch: 0.080606689453125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 101: 0.08392333984375, mean for epoch: 0.08063952757580446, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 102: 0.0784912109375, mean for epoch: 0.08061846564797794, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 103: 0.068359375, mean for epoch: 0.08049944535042476, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 104: 0.10113525390625, mean for epoch: 0.08069786658653846, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 105: 0.0745849609375, mean for epoch: 0.0806396484375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 106: 0.068115234375, mean for epoch: 0.08052149358785378, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 107: 0.0711669921875, mean for epoch: 0.08043406834112149, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 108: 0.07330322265625, mean for epoch: 0.0803680419921875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:15,410] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:15,410] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=37.658862507473984, CurrSamplesPerSec=35.348554977599036, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 109: 0.0770263671875, mean for epoch: 0.08033738442517202, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 110: 0.061553955078125, mean for epoch: 0.0801666259765625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 111: 0.0748291015625, mean for epoch: 0.0801185401710304, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 112: 0.1448974609375, mean for epoch: 0.0806969233921596, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 113: 0.071533203125, mean for epoch: 0.08061582852253872, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 114: 0.07830810546875, mean for epoch: 0.08059558533785637, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 115: 0.1107177734375, mean for epoch: 0.08085751740828805, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 116: 0.0927734375, mean for epoch: 0.08096024085735452, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 117: 0.09075927734375, mean for epoch: 0.0810439933059562, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 118: 0.09832763671875, mean for epoch: 0.0811904648603019, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:16,796] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:16,797] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=37.649025589939285, CurrSamplesPerSec=33.74187486324027, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 119: 0.0662841796875, mean for epoch: 0.08106520195969012, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 120: 0.06915283203125, mean for epoch: 0.08096593221028646, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 121: 0.07049560546875, mean for epoch: 0.08087940058432334, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 122: 0.042724609375, mean for epoch: 0.08056665639408299, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 123: 0.0806884765625, mean for epoch: 0.0805676468019563, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 124: 0.07177734375, mean for epoch: 0.08049675726121472, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 125: 0.07098388671875, mean for epoch: 0.080420654296875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 126: 0.07391357421875, mean for epoch: 0.08036901080419147, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 127: 0.07073974609375, mean for epoch: 0.08029318982221949, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 128: 0.081787109375, mean for epoch: 0.08030486106872559, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:18,159] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:18,160] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=37.64859698242489, CurrSamplesPerSec=38.46573734409391, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 129: 0.08154296875, mean for epoch: 0.08031445880268895, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 130: 0.06939697265625, mean for epoch: 0.08023047814002404, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 131: 0.07073974609375, mean for epoch: 0.08015802980379294, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 132: 0.08526611328125, mean for epoch: 0.08019672740589488, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 133: 0.08612060546875, mean for epoch: 0.0802412678424577, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 134: 0.08404541015625, mean for epoch: 0.08026965696420242, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 135: 0.06103515625, mean for epoch: 0.08012717918113425, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 136: 0.10528564453125, mean for epoch: 0.08031216789694394, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 137: 0.1302490234375, mean for epoch: 0.08067667049213048, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 138: 0.0843505859375, mean for epoch: 0.08070329306782156, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:19,525] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:19,526] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=37.64939647270304, CurrSamplesPerSec=38.998497448638034, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 139: 0.06695556640625, mean for epoch: 0.08060438855946493, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 140: 0.0841064453125, mean for epoch: 0.08062940325055803, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 141: 0.07373046875, mean for epoch: 0.0805804746370789, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 142: 0.080810546875, mean for epoch: 0.08058209486410652, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 143: 0.081298828125, mean for epoch: 0.08058710698481206, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 144: 0.073974609375, mean for epoch: 0.08054118686252171, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 145: 0.07684326171875, mean for epoch: 0.08051568393049569, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 146: 0.08941650390625, mean for epoch: 0.08057664845087757, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 147: 0.0732421875, mean for epoch: 0.08052675415869473, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 148: 0.0672607421875, mean for epoch: 0.08043711894267314, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:20,892] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:20,892] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=37.647290066170456, CurrSamplesPerSec=35.970313349559106, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 149: 0.06378173828125, mean for epoch: 0.08032533786440856, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 150: 0.09783935546875, mean for epoch: 0.08044209798177084, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 151: 0.0938720703125, mean for epoch: 0.08053103819588162, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 152: 0.07086181640625, mean for epoch: 0.08046742489463404, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 153: 0.0694580078125, mean for epoch: 0.080395467920241, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 154: 0.08514404296875, mean for epoch: 0.08042630282315341, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 155: 0.091796875, mean for epoch: 0.08049966135332662, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 156: 0.0914306640625, mean for epoch: 0.08056973188351362, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 157: 0.09100341796875, mean for epoch: 0.08063618848278264, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 158: 0.0758056640625, mean for epoch: 0.08060561554341376, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:22,277] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:22,277] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=37.638217334182585, CurrSamplesPerSec=38.50097576468558, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   4:   Loss at step 159: 0.0517578125, mean for epoch: 0.08042418281987028, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 160: 0.07684326171875, mean for epoch: 0.08040180206298828, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 161: 0.058319091796875, mean for epoch: 0.08026464237189442, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 162: 0.07452392578125, mean for epoch: 0.08022920584972994, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 163: 0.080078125, mean for epoch: 0.08022827897335123, mem_alloc: 2342824960\n",
            " Run   4, iteration:   4:   Loss at step 164: 0.07586669921875, mean for epoch: 0.08020168397484756, mem_alloc: 2342824960\n",
            "Loss after iteration 4 ; MSE: 0.0802001953125, MAE: 0.2122802734375\n",
            "Connected by ('127.0.0.1', 34208)\n",
            "\u001b[94mReceived training result: b'4;0.08020;0.21228' \u001b[0m\n",
            "Time per iteration 22.651571571826935, memory OrderedDict([('active.all.allocated', 1484398), ('active.all.current', 7), ('active.all.freed', 1484391), ('active.all.peak', 295), ('active.large_pool.allocated', 498512), ('active.large_pool.current', 5), ('active.large_pool.freed', 498507), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 985886), ('active.small_pool.current', 2), ('active.small_pool.freed', 985884), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 4838829366784), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 4838778473984), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 4717275741696), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 4717225809408), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 121553625088), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 121552664576), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 4838829366784), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 4838784565760), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 4717275741696), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 4717231901184), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 121553625088), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 121552664576), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1484398), ('allocation.all.current', 6), ('allocation.all.freed', 1484392), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 498512), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 498508), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 985886), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 985884), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 634546), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 634542), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 329934), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 329933), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 304612), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 304609), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2930653007360), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2930640985600), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2788155622400), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2788146834432), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 142497384960), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 142494151168), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   4, iteration:   5:   Loss at step 1: 0.0726318359375, mean for epoch: 0.0726318359375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 2: 0.08050537109375, mean for epoch: 0.076568603515625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 3: 0.1038818359375, mean for epoch: 0.08567301432291667, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 4: 0.0787353515625, mean for epoch: 0.0839385986328125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:23,809] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:23,810] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=37.62696016331129, CurrSamplesPerSec=37.63287191395133, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 5: 0.08087158203125, mean for epoch: 0.0833251953125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 6: 0.0965576171875, mean for epoch: 0.08553059895833333, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 7: 0.061065673828125, mean for epoch: 0.08203560965401786, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 8: 0.09136962890625, mean for epoch: 0.08320236206054688, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 9: 0.0784912109375, mean for epoch: 0.08267890082465278, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 10: 0.055816650390625, mean for epoch: 0.07999267578125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 11: 0.07904052734375, mean for epoch: 0.07990611683238637, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 12: 0.061279296875, mean for epoch: 0.0783538818359375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 13: 0.06781005859375, mean for epoch: 0.07754281850961539, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 14: 0.071533203125, mean for epoch: 0.07711356026785714, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:25,195] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:25,196] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=37.61806090292334, CurrSamplesPerSec=36.725004465520925, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 15: 0.068359375, mean for epoch: 0.07652994791666666, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 16: 0.07550048828125, mean for epoch: 0.07646560668945312, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 17: 0.071044921875, mean for epoch: 0.07614674287683823, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 18: 0.08416748046875, mean for epoch: 0.07659233940972222, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 19: 0.07330322265625, mean for epoch: 0.07641922800164473, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 20: 0.1068115234375, mean for epoch: 0.0779388427734375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 21: 0.0625, mean for epoch: 0.07720365978422619, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 22: 0.07220458984375, mean for epoch: 0.07697642933238637, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 23: 0.1046142578125, mean for epoch: 0.07817807404891304, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 24: 0.06524658203125, mean for epoch: 0.07763926188151042, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:26,579] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:26,580] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=37.60935934208369, CurrSamplesPerSec=38.77267584177014, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 25: 0.09942626953125, mean for epoch: 0.0785107421875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 26: 0.08056640625, mean for epoch: 0.07858980618990384, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 27: 0.073974609375, mean for epoch: 0.07841887297453703, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 28: 0.0777587890625, mean for epoch: 0.07839529854910714, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 29: 0.09942626953125, mean for epoch: 0.07912050444504311, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 30: 0.09283447265625, mean for epoch: 0.07957763671875, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 31: 0.056488037109375, mean for epoch: 0.07883281092489919, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 32: 0.07318115234375, mean for epoch: 0.07865619659423828, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 33: 0.148193359375, mean for epoch: 0.08076338334517046, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 34: 0.08831787109375, mean for epoch: 0.08098557416130514, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:27,945] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:27,946] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=37.61138657450409, CurrSamplesPerSec=37.630913609488694, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 35: 0.071533203125, mean for epoch: 0.08071550641741071, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 36: 0.0736083984375, mean for epoch: 0.08051808675130208, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 37: 0.076171875, mean for epoch: 0.08040062156883446, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 38: 0.1138916015625, mean for epoch: 0.08128196314761513, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 39: 0.0931396484375, mean for epoch: 0.08158600636017628, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 40: 0.0809326171875, mean for epoch: 0.08156967163085938, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 41: 0.09130859375, mean for epoch: 0.08180720631669207, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 42: 0.0814208984375, mean for epoch: 0.08179800851004464, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 43: 0.0548095703125, mean for epoch: 0.08117037041242732, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 44: 0.061126708984375, mean for epoch: 0.08071483265269887, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:29,330] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:29,331] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=37.603128283150085, CurrSamplesPerSec=34.840810467766694, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 45: 0.0693359375, mean for epoch: 0.08046196831597222, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 46: 0.07501220703125, mean for epoch: 0.08034349524456522, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 47: 0.08709716796875, mean for epoch: 0.08048719040890957, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 48: 0.08148193359375, mean for epoch: 0.08050791422526042, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 49: 0.0714111328125, mean for epoch: 0.080322265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 50: 0.0731201171875, mean for epoch: 0.08017822265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 51: 0.06927490234375, mean for epoch: 0.07996443206188726, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 52: 0.0999755859375, mean for epoch: 0.08034926194411057, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 53: 0.06402587890625, mean for epoch: 0.08004127358490566, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 54: 0.0865478515625, mean for epoch: 0.08016176576967593, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:30,687] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:30,687] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=37.60695043482212, CurrSamplesPerSec=38.68834434373864, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 55: 0.0849609375, mean for epoch: 0.0802490234375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 56: 0.08404541015625, mean for epoch: 0.08031681605747767, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 57: 0.09808349609375, mean for epoch: 0.08062851219846491, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 58: 0.10491943359375, mean for epoch: 0.0810473211880388, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 59: 0.100830078125, mean for epoch: 0.08138262215307203, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 60: 0.10491943359375, mean for epoch: 0.08177490234375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 61: 0.07098388671875, mean for epoch: 0.0815980004482582, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 62: 0.0557861328125, mean for epoch: 0.08118168000252016, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 63: 0.072509765625, mean for epoch: 0.08104403056795635, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 64: 0.07757568359375, mean for epoch: 0.08098983764648438, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:32,066] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:32,067] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=37.602340974043024, CurrSamplesPerSec=36.09916308340592, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 65: 0.080322265625, mean for epoch: 0.0809795673076923, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 66: 0.086181640625, mean for epoch: 0.08105838660037878, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 67: 0.055023193359375, mean for epoch: 0.08066980162663247, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 68: 0.051361083984375, mean for epoch: 0.08023879107306986, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 69: 0.1307373046875, mean for epoch: 0.08097065358922101, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 70: 0.052978515625, mean for epoch: 0.08057076590401786, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 71: 0.07806396484375, mean for epoch: 0.08053545884683098, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 72: 0.07440185546875, mean for epoch: 0.0804502699110243, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 73: 0.06756591796875, mean for epoch: 0.08027377193921233, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 74: 0.0997314453125, mean for epoch: 0.08053671347128379, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:33,434] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:33,435] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=37.6007198366748, CurrSamplesPerSec=38.39404779776573, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 75: 0.078369140625, mean for epoch: 0.0805078125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 76: 0.0816650390625, mean for epoch: 0.08052303916529606, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 77: 0.09588623046875, mean for epoch: 0.08072256113027597, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 78: 0.08135986328125, mean for epoch: 0.08073073167067307, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 79: 0.08355712890625, mean for epoch: 0.08076650885087025, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 80: 0.1290283203125, mean for epoch: 0.08136978149414062, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 81: 0.07635498046875, mean for epoch: 0.08130787037037036, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 82: 0.06903076171875, mean for epoch: 0.08115814953315549, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 83: 0.11065673828125, mean for epoch: 0.08151355421686747, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 84: 0.07916259765625, mean for epoch: 0.08148556663876488, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:34,806] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:34,806] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=37.59699215546106, CurrSamplesPerSec=38.741518402272966, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 85: 0.0799560546875, mean for epoch: 0.0814675723805147, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 86: 0.0775146484375, mean for epoch: 0.08142160814861919, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 87: 0.0999755859375, mean for epoch: 0.08163487226113506, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 88: 0.0633544921875, mean for epoch: 0.0814271406693892, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 89: 0.07037353515625, mean for epoch: 0.08130294285463484, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 90: 0.0704345703125, mean for epoch: 0.08118218315972223, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 91: 0.0809326171875, mean for epoch: 0.08117944067651099, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 92: 0.0753173828125, mean for epoch: 0.08111572265625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 93: 0.07232666015625, mean for epoch: 0.0810212166078629, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 94: 0.0855712890625, mean for epoch: 0.08106962163397606, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:36,209] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:36,210] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=37.5842180496223, CurrSamplesPerSec=32.58962273680154, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 95: 0.0941162109375, mean for epoch: 0.08120695415296053, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 96: 0.0802001953125, mean for epoch: 0.08119646708170573, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 97: 0.0499267578125, mean for epoch: 0.0808740989449098, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 98: 0.0789794921875, mean for epoch: 0.0808547662228954, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 99: 0.07940673828125, mean for epoch: 0.0808401396780303, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 100: 0.074951171875, mean for epoch: 0.08078125, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 101: 0.0853271484375, mean for epoch: 0.08082625889542079, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 102: 0.07232666015625, mean for epoch: 0.08074292949601716, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 103: 0.06207275390625, mean for epoch: 0.0805616656553398, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 104: 0.10455322265625, mean for epoch: 0.08079235370342548, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:37,609] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:37,610] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=37.57358233427487, CurrSamplesPerSec=36.604494154527146, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 105: 0.048492431640625, mean for epoch: 0.08048473539806547, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 106: 0.0631103515625, mean for epoch: 0.08032082611659788, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 107: 0.05035400390625, mean for epoch: 0.08004076235762267, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 108: 0.06768798828125, mean for epoch: 0.07992638481987847, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 109: 0.0706787109375, mean for epoch: 0.07984154377508601, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 110: 0.0802001953125, mean for epoch: 0.07984480424360796, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 111: 0.052490234375, mean for epoch: 0.0795983666772241, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 112: 0.07232666015625, mean for epoch: 0.07953344072614398, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 113: 0.0753173828125, mean for epoch: 0.07949613047912057, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 114: 0.1280517578125, mean for epoch: 0.07992205703467653, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:38,999] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:38,999] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=37.570062585780235, CurrSamplesPerSec=36.88694627419596, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 115: 0.119140625, mean for epoch: 0.08026308806046195, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 116: 0.054046630859375, mean for epoch: 0.08003708411907327, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 117: 0.08746337890625, mean for epoch: 0.08010055672409189, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 118: 0.06658935546875, mean for epoch: 0.07998605501853813, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 119: 0.0771484375, mean for epoch: 0.07996220949317227, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 120: 0.08380126953125, mean for epoch: 0.07999420166015625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 121: 0.081787109375, mean for epoch: 0.08000901907928719, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 122: 0.06817626953125, mean for epoch: 0.07991202932889344, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 123: 0.0916748046875, mean for epoch: 0.08000766164888211, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 124: 0.0797119140625, mean for epoch: 0.08000527658770161, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:40,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:40,386] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=37.56740456037832, CurrSamplesPerSec=37.38818675980054, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 125: 0.06927490234375, mean for epoch: 0.07991943359375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 126: 0.07958984375, mean for epoch: 0.07991681780133929, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 127: 0.0518798828125, mean for epoch: 0.07969605453371063, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 128: 0.0731201171875, mean for epoch: 0.07964468002319336, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 129: 0.06964111328125, mean for epoch: 0.07956713299418605, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 130: 0.07464599609375, mean for epoch: 0.07952927809495192, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 131: 0.0830078125, mean for epoch: 0.07955583179270038, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 132: 0.08416748046875, mean for epoch: 0.0795907685250947, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 133: 0.07763671875, mean for epoch: 0.07957607642152256, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 134: 0.078857421875, mean for epoch: 0.07957071332789178, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:41,776] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:41,777] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=37.56110487735248, CurrSamplesPerSec=38.70312407724561, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 135: 0.07257080078125, mean for epoch: 0.0795188621238426, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 136: 0.08642578125, mean for epoch: 0.07956964829388787, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 137: 0.0677490234375, mean for epoch: 0.07948336636062957, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 138: 0.061859130859375, mean for epoch: 0.07935565450917119, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 139: 0.10595703125, mean for epoch: 0.0795470313202563, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 140: 0.060211181640625, mean for epoch: 0.07940891810825892, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 141: 0.06591796875, mean for epoch: 0.07931323761635638, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 142: 0.07684326171875, mean for epoch: 0.07929584341989436, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 143: 0.07025146484375, mean for epoch: 0.07923259601726398, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 144: 0.092529296875, mean for epoch: 0.07932493421766493, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:43,167] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:43,168] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=37.5528836225184, CurrSamplesPerSec=39.359114155679634, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 145: 0.09088134765625, mean for epoch: 0.07940463362068965, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 146: 0.0740966796875, mean for epoch: 0.0793682777718322, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 147: 0.0889892578125, mean for epoch: 0.07943372661564625, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 148: 0.07427978515625, mean for epoch: 0.07939890268686656, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 149: 0.0732421875, mean for epoch: 0.07935758245071309, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 150: 0.052581787109375, mean for epoch: 0.0791790771484375, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 151: 0.12213134765625, mean for epoch: 0.07946352927100579, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 152: 0.061859130859375, mean for epoch: 0.07934771086040296, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 153: 0.08905029296875, mean for epoch: 0.07941112642973856, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 154: 0.117431640625, mean for epoch: 0.07965801288555195, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:44,516] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:44,517] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=37.5612900544362, CurrSamplesPerSec=39.714274893004585, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   4, iteration:   5:   Loss at step 155: 0.0771484375, mean for epoch: 0.0796418220766129, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 156: 0.09759521484375, mean for epoch: 0.07975690792768429, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 157: 0.0997314453125, mean for epoch: 0.07988413428045382, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 158: 0.05804443359375, mean for epoch: 0.0797459083267405, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 159: 0.072509765625, mean for epoch: 0.07970039799528301, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 160: 0.07012939453125, mean for epoch: 0.07964057922363281, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 161: 0.0836181640625, mean for epoch: 0.0796652847195264, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 162: 0.07421875, mean for epoch: 0.07963166413483797, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 163: 0.06646728515625, mean for epoch: 0.07955090107361963, mem_alloc: 2342824960\n",
            " Run   4, iteration:   5:   Loss at step 164: 0.07708740234375, mean for epoch: 0.07953587973990091, mem_alloc: 2342824960\n",
            "[2022-10-25 13:49:45,908] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:49:45,909] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=37.553508704472634, CurrSamplesPerSec=38.17716781262686, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            "Loss after iteration 5 ; MSE: 0.07952880859375, MAE: 0.212158203125\n",
            "Connected by ('127.0.0.1', 45560)\n",
            "\u001b[94mReceived training result: b'5;0.07953;0.21216' \u001b[0m\n",
            "Time per iteration 22.68362021446228, memory OrderedDict([('active.all.allocated', 1858646), ('active.all.current', 7), ('active.all.freed', 1858639), ('active.all.peak', 295), ('active.large_pool.allocated', 623152), ('active.large_pool.current', 5), ('active.large_pool.freed', 623147), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 1235494), ('active.small_pool.current', 2), ('active.small_pool.freed', 1235492), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 6048794140160), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 6048743247360), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 5896688674304), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 5896638742016), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 152105465856), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 152104505344), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 6048794140160), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 6048749339136), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 5896688674304), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 5896644833792), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 152105465856), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 152104505344), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1858646), ('allocation.all.current', 6), ('allocation.all.freed', 1858640), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 623152), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 623148), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 1235494), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 1235492), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 794111), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 794107), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 412426), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 412425), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 381685), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 381682), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 3663565530112), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 3663553508352), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 3485285583872), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 3485276795904), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 178279946240), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 178276712448), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            "2342824960\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.0194091796875, mean for epoch: 0.0194091796875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 2: 0.031402587890625, mean for epoch: 0.0254058837890625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 3: 0.020751953125, mean for epoch: 0.023854573567708332, mem_alloc: 2342824960\n",
            "Validation set Loss at step 4: 0.034942626953125, mean for epoch: 0.0266265869140625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 5: 0.034423828125, mean for epoch: 0.02818603515625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 6: 0.03851318359375, mean for epoch: 0.0299072265625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 7: 0.033935546875, mean for epoch: 0.030482700892857144, mem_alloc: 2342824960\n",
            "Validation set Loss at step 8: 0.061065673828125, mean for epoch: 0.034305572509765625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 9: 0.045074462890625, mean for epoch: 0.035502115885416664, mem_alloc: 2342824960\n",
            "Validation set Loss at step 10: 0.02569580078125, mean for epoch: 0.034521484375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 11: 0.0136871337890625, mean for epoch: 0.03262745250355114, mem_alloc: 2342824960\n",
            "Validation set Loss at step 12: 0.0406494140625, mean for epoch: 0.03329594930013021, mem_alloc: 2342824960\n",
            "Validation set Loss at step 13: 0.028228759765625, mean for epoch: 0.03290616548978365, mem_alloc: 2342824960\n",
            "Validation set Loss at step 14: 0.02801513671875, mean for epoch: 0.03255680629185268, mem_alloc: 2342824960\n",
            "Validation set Loss at step 15: 0.016326904296875, mean for epoch: 0.03147481282552083, mem_alloc: 2342824960\n",
            "Validation set Loss at step 16: 0.01189422607421875, mean for epoch: 0.030251026153564453, mem_alloc: 2342824960\n",
            "Validation set Loss at step 17: 0.0263824462890625, mean for epoch: 0.03002346263212316, mem_alloc: 2342824960\n",
            "Validation set Loss at step 18: 0.0421142578125, mean for epoch: 0.03069517347547743, mem_alloc: 2342824960\n",
            "Validation set Loss at step 19: 0.192138671875, mean for epoch: 0.03919219970703125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 20: 0.0770263671875, mean for epoch: 0.041083908081054686, mem_alloc: 2342824960\n",
            "Validation set Loss at step 21: 0.0616455078125, mean for epoch: 0.04206303187779018, mem_alloc: 2342824960\n",
            "Validation set Loss at step 22: 0.03619384765625, mean for epoch: 0.04179625077681108, mem_alloc: 2342824960\n",
            "Validation set Loss at step 23: 0.043914794921875, mean for epoch: 0.04188836139181386, mem_alloc: 2342824960\n",
            "Validation set Loss at step 24: 0.01514434814453125, mean for epoch: 0.040774027506510414, mem_alloc: 2342824960\n",
            "Validation set Loss at step 25: 0.0252532958984375, mean for epoch: 0.0401531982421875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 26: 0.083251953125, mean for epoch: 0.041810842660757214, mem_alloc: 2342824960\n",
            "Validation set Loss at step 27: 0.050872802734375, mean for epoch: 0.04214647081163195, mem_alloc: 2342824960\n",
            "Validation set Loss at step 28: 0.12237548828125, mean for epoch: 0.04501179286411831, mem_alloc: 2342824960\n",
            "Validation set Loss at step 29: 0.052337646484375, mean for epoch: 0.04526440850619612, mem_alloc: 2342824960\n",
            "Validation set Loss at step 30: 0.028717041015625, mean for epoch: 0.04471282958984375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 31: 0.048828125, mean for epoch: 0.0448455810546875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 32: 0.0802001953125, mean for epoch: 0.04595041275024414, mem_alloc: 2342824960\n",
            "Validation set Loss at step 33: 0.03167724609375, mean for epoch: 0.045517892548532196, mem_alloc: 2342824960\n",
            "Validation set Loss at step 34: 0.112060546875, mean for epoch: 0.047475029440487135, mem_alloc: 2342824960\n",
            "Validation set Loss at step 35: 0.04095458984375, mean for epoch: 0.047288731166294645, mem_alloc: 2342824960\n",
            "Validation set Loss at step 36: 0.03338623046875, mean for epoch: 0.04690255059136285, mem_alloc: 2342824960\n",
            "Validation set Loss at step 37: 0.1632080078125, mean for epoch: 0.05004594132706926, mem_alloc: 2342824960\n",
            "Validation set Loss at step 38: 0.1500244140625, mean for epoch: 0.05267695376747533, mem_alloc: 2342824960\n",
            "Validation set Loss at step 39: 0.11065673828125, mean for epoch: 0.054163614908854164, mem_alloc: 2342824960\n",
            "Validation set Loss at step 40: 0.08013916015625, mean for epoch: 0.05481300354003906, mem_alloc: 2342824960\n",
            "Validation set Loss at step 41: 0.07525634765625, mean for epoch: 0.05531162168921494, mem_alloc: 2342824960\n",
            "Validation set Loss at step 42: 0.047576904296875, mean for epoch: 0.055127461751302086, mem_alloc: 2342824960\n",
            "Validation set Loss at step 43: 0.040191650390625, mean for epoch: 0.05478011730105378, mem_alloc: 2342824960\n",
            "Validation set Loss at step 44: 0.0311431884765625, mean for epoch: 0.054242914373224434, mem_alloc: 2342824960\n",
            "Validation set Loss at step 45: 0.0294342041015625, mean for epoch: 0.05369160970052083, mem_alloc: 2342824960\n",
            "Validation set Loss at step 46: 0.08599853515625, mean for epoch: 0.05439393416694973, mem_alloc: 2342824960\n",
            "Validation set Loss at step 47: 0.028106689453125, mean for epoch: 0.05383463108793218, mem_alloc: 2342824960\n",
            "Validation set Loss at step 48: 0.091796875, mean for epoch: 0.054625511169433594, mem_alloc: 2342824960\n",
            "Validation set Loss at step 49: 0.035919189453125, mean for epoch: 0.05424374950175383, mem_alloc: 2342824960\n",
            "Validation set Loss at step 50: 0.02618408203125, mean for epoch: 0.05368255615234375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 51: 0.08984375, mean for epoch: 0.05439159916896446, mem_alloc: 2342824960\n",
            "Validation set Loss at step 52: 0.060028076171875, mean for epoch: 0.05449999295748197, mem_alloc: 2342824960\n",
            "Validation set Loss at step 53: 0.0870361328125, mean for epoch: 0.05511388238870873, mem_alloc: 2342824960\n",
            "Validation set Loss at step 54: 0.482421875, mean for epoch: 0.0630269933629919, mem_alloc: 2342824960\n",
            "Validation set Loss at step 55: 0.1719970703125, mean for epoch: 0.06500826748934659, mem_alloc: 2342824960\n",
            "Validation set Loss at step 56: 0.2039794921875, mean for epoch: 0.06748989650181361, mem_alloc: 2342824960\n",
            "Validation set Loss at step 57: 0.219482421875, mean for epoch: 0.07015643203467653, mem_alloc: 2342824960\n",
            "Validation set Loss at step 58: 0.129638671875, mean for epoch: 0.07118198789399245, mem_alloc: 2342824960\n",
            "Validation set Loss at step 59: 0.09954833984375, mean for epoch: 0.07166277352025953, mem_alloc: 2342824960\n",
            "Validation set Loss at step 60: 0.09124755859375, mean for epoch: 0.0719891866048177, mem_alloc: 2342824960\n",
            "Validation set Loss at step 61: 0.126708984375, mean for epoch: 0.07288623246990267, mem_alloc: 2342824960\n",
            "Validation set Loss at step 62: 0.03790283203125, mean for epoch: 0.07232198407573084, mem_alloc: 2342824960\n",
            "Validation set Loss at step 63: 0.03485107421875, mean for epoch: 0.07172720772879464, mem_alloc: 2342824960\n",
            "Validation set Loss at step 64: 0.057220458984375, mean for epoch: 0.07150053977966309, mem_alloc: 2342824960\n",
            "Validation set Loss at step 65: 0.049224853515625, mean for epoch: 0.0711578369140625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 66: 0.0193023681640625, mean for epoch: 0.07037214799360796, mem_alloc: 2342824960\n",
            "Validation set Loss at step 67: 0.051239013671875, mean for epoch: 0.07008657882462686, mem_alloc: 2342824960\n",
            "Validation set Loss at step 68: 0.05078125, mean for epoch: 0.06980267693014706, mem_alloc: 2342824960\n",
            "Validation set Loss at step 69: 0.208251953125, mean for epoch: 0.07180918817934782, mem_alloc: 2342824960\n",
            "Validation set Loss at step 70: 0.424072265625, mean for epoch: 0.07684151785714285, mem_alloc: 2342824960\n",
            "Validation set Loss at step 71: 0.283203125, mean for epoch: 0.07974801936619719, mem_alloc: 2342824960\n",
            "Validation set Loss at step 72: 0.360107421875, mean for epoch: 0.08364189995659722, mem_alloc: 2342824960\n",
            "Validation set Loss at step 73: 0.185302734375, mean for epoch: 0.08503451412671233, mem_alloc: 2342824960\n",
            "Validation set Loss at step 74: 0.12646484375, mean for epoch: 0.08559438344594594, mem_alloc: 2342824960\n",
            "Validation set Loss at step 75: 0.1204833984375, mean for epoch: 0.0860595703125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 76: 0.08026123046875, mean for epoch: 0.0859832763671875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 77: 0.1634521484375, mean for epoch: 0.0869893656148539, mem_alloc: 2342824960\n",
            "Validation set Loss at step 78: 0.06573486328125, mean for epoch: 0.0867168719951923, mem_alloc: 2342824960\n",
            "Validation set Loss at step 79: 0.10614013671875, mean for epoch: 0.08696273610561708, mem_alloc: 2342824960\n",
            "Validation set Loss at step 80: 0.06243896484375, mean for epoch: 0.08665618896484376, mem_alloc: 2342824960\n",
            "Validation set Loss at step 81: 0.075927734375, mean for epoch: 0.08652373890817901, mem_alloc: 2342824960\n",
            "Validation set Loss at step 82: 0.07464599609375, mean for epoch: 0.08637888838605183, mem_alloc: 2342824960\n",
            "Validation set Loss at step 83: 0.085693359375, mean for epoch: 0.08637062900037651, mem_alloc: 2342824960\n",
            "Validation set Loss at step 84: 0.06585693359375, mean for epoch: 0.08612641834077381, mem_alloc: 2342824960\n",
            "Validation set Loss at step 85: 0.01265716552734375, mean for epoch: 0.08526207419002757, mem_alloc: 2342824960\n",
            "Validation set Loss at step 86: 0.12017822265625, mean for epoch: 0.085668075916379, mem_alloc: 2342824960\n",
            "Validation set Loss at step 87: 0.053192138671875, mean for epoch: 0.0852947892813847, mem_alloc: 2342824960\n",
            "Validation set Loss at step 88: 0.1038818359375, mean for epoch: 0.08550600572065874, mem_alloc: 2342824960\n",
            "Validation set Loss at step 89: 0.1156005859375, mean for epoch: 0.08584414707140976, mem_alloc: 2342824960\n",
            "Loss for validation set  ; MSE: 0.0858154296875, MAE: 0.23876953125\n",
            "Connected by ('127.0.0.1', 46188)\n",
            "\u001b[94mReceived result: b'0.08582;0.23877' \u001b[0m\n",
            "Iteration  1| MSE 0.0688 | MAE 0.2087\n",
            "Iteration  2| MSE 0.0545 | MAE 0.1807\n",
            "Iteration  3| MSE 0.0377 | MAE 0.1499\n",
            "Iteration  4| MSE 0.0858 | MAE 0.2388\n",
            "Mean        | MSE 0.0617 | MAE 0.1945\n",
            "[2022-10-25 13:49:51,958] [INFO] [launch.py:318:main] Process 712 exits successfully.\n",
            "[2022-10-25 13:49:53,220] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-25 13:49:53,220] [INFO] [runner.py:507:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --deepspeed_config settings/ds_config_zero.json --data ETTh1 --seq_len 720 --pred_len 24 --dec_seq_len 48 --hidden_size 312 --n_encoder_layers 3 --n_decoder_layers 3 --encoder_attention query_selector_0.8 --decoder_attention full --n_heads 4 --batch_size 48 --embedding_size 96 --iterations 5 --exps 5 --dropout 0.1 --fp16 --deepspeed --features S --input_len 1 --output_len 1 --run_num 5\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-25 13:49:55,123] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-25 13:49:55,124] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-25 13:49:55,124] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-25 13:49:55,124] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-25 13:49:55,124] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Number of parameters: 177\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([312, 96])\n",
            "torch.Size([96, 384])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([96, 1])\n",
            "torch.Size([96])\n",
            "torch.Size([24, 4608])\n",
            "torch.Size([24])\n",
            "[2022-10-25 13:49:57,356] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.4, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-25 13:49:57,358] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-25 13:49:57,369] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2022-10-25 13:49:59,275] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.25113844871520996 seconds\n",
            "[2022-10-25 13:50:00,332] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2022-10-25 13:50:00,339] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2022-10-25 13:50:00,339] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2022-10-25 13:50:00,339] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "[2022-10-25 13:50:00,339] [INFO] [stage_1_and_2.py:140:__init__] Reduce bucket size 500000000\n",
            "[2022-10-25 13:50:00,339] [INFO] [stage_1_and_2.py:141:__init__] Allgather bucket size 500000000\n",
            "[2022-10-25 13:50:00,339] [INFO] [stage_1_and_2.py:142:__init__] CPU Offload: False\n",
            "[2022-10-25 13:50:00,339] [INFO] [stage_1_and_2.py:143:__init__] Round robin gradient partitioning: False\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.2669246196746826 seconds\n",
            "Rank: 0 partition count [1] and sizes[(3045720, False)] \n",
            "[2022-10-25 13:50:00,835] [INFO] [utils.py:827:see_memory_usage] Before initializing optimizer states\n",
            "[2022-10-25 13:50:00,836] [INFO] [utils.py:832:see_memory_usage] MA 0.02 GB         Max_MA 0.02 GB         CA 0.04 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:50:00,836] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:50:00,909] [INFO] [utils.py:827:see_memory_usage] After initializing optimizer states\n",
            "[2022-10-25 13:50:00,910] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.05 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:50:00,910] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:50:00,910] [INFO] [stage_1_and_2.py:523:__init__] optimizer state initialized\n",
            "[2022-10-25 13:50:00,980] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-25 13:50:00,981] [INFO] [utils.py:832:see_memory_usage] MA 0.04 GB         Max_MA 0.04 GB         CA 0.06 GB         Max_CA 0 GB \n",
            "[2022-10-25 13:50:00,981] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 2.38 GB, percent = 18.8%\n",
            "[2022-10-25 13:50:00,986] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2022-10-25 13:50:00,986] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2022-10-25 13:50:00,986] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2022-10-25 13:50:00,986] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:00,987] [INFO] [config.py:1002:print] DeepSpeedEngine configuration:\n",
            "[2022-10-25 13:50:00,987] [INFO] [config.py:1006:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-25 13:50:00,987] [INFO] [config.py:1006:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-25 13:50:00,987] [INFO] [config.py:1006:print]   amp_enabled .................. False\n",
            "[2022-10-25 13:50:00,987] [INFO] [config.py:1006:print]   amp_params ................... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   bfloat16_enabled ............. False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5ad15e9190>\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   communication_data_type ...... None\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   curriculum_enabled ........... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   curriculum_params ............ False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   dataloader_drop_last ......... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   disable_allgather ............ False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   dump_state ................... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-25 13:50:00,988] [INFO] [config.py:1006:print]   elasticity_enabled ........... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   fp16_auto_cast ............... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   fp16_enabled ................. True\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   global_rank .................. 0\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   gradient_accumulation_steps .. 1\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   gradient_clipping ............ 0.0\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   load_universal_checkpoint .... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   loss_scale ................... 0\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   memory_breakdown ............. False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5ad15e9090>\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   optimizer_name ............... adam\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   pld_enabled .................. False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   pld_params ................... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   prescale_gradients ........... False\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   scheduler_name ............... None\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   scheduler_params ............. None\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   sparse_attention ............. None\n",
            "[2022-10-25 13:50:00,989] [INFO] [config.py:1006:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   steps_per_print .............. 10\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   train_batch_size ............. 5\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   train_micro_batch_size_per_gpu  5\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   world_size ................... 1\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=False allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=False prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   zero_enabled ................. True\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:1006:print]   zero_optimization_stage ...... 2\n",
            "[2022-10-25 13:50:00,990] [INFO] [config.py:997:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 5, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 5e-05, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": false, \n",
            "        \"cpu_offload\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 1000\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.000457763671875 seconds\n",
            "train 7897\n",
            " Run   5, iteration:   1:   Loss at step 1: 1.107421875, mean for epoch: 1.107421875, mem_alloc: 1323024896\n",
            "[2022-10-25 13:50:01,911] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 4294967296\n",
            " Run   5, iteration:   1:   Loss at step 2: 1.15234375, mean for epoch: 1.1298828125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,046] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
            " Run   5, iteration:   1:   Loss at step 3: 0.99169921875, mean for epoch: 1.0838216145833333, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,169] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
            " Run   5, iteration:   1:   Loss at step 4: 1.125, mean for epoch: 1.0941162109375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,286] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
            " Run   5, iteration:   1:   Loss at step 5: 1.2548828125, mean for epoch: 1.12626953125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,411] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
            " Run   5, iteration:   1:   Loss at step 6: 1.150390625, mean for epoch: 1.1302897135416667, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,524] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
            " Run   5, iteration:   1:   Loss at step 7: 1.0009765625, mean for epoch: 1.11181640625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,638] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
            " Run   5, iteration:   1:   Loss at step 8: 1.166015625, mean for epoch: 1.11859130859375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,774] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
            " Run   5, iteration:   1:   Loss at step 9: 1.283203125, mean for epoch: 1.1368815104166667, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:02,888] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
            " Run   5, iteration:   1:   Loss at step 10: 1.029296875, mean for epoch: 1.126123046875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,009] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
            "[2022-10-25 13:50:03,010] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=10, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:03,010] [INFO] [timer.py:207:stop] 0/10, RunningAvgSamplesPerSec=42.51694434399128, CurrSamplesPerSec=42.157961286639285, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 11: 1.3583984375, mean for epoch: 1.1472389914772727, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,127] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
            " Run   5, iteration:   1:   Loss at step 12: 0.78076171875, mean for epoch: 1.11669921875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,241] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
            " Run   5, iteration:   1:   Loss at step 13: 1.025390625, mean for epoch: 1.1096754807692308, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,368] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
            " Run   5, iteration:   1:   Loss at step 14: 1.1015625, mean for epoch: 1.1090959821428572, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,483] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
            " Run   5, iteration:   1:   Loss at step 15: 0.8408203125, mean for epoch: 1.0912109375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,602] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            " Run   5, iteration:   1:   Loss at step 16: 1.2431640625, mean for epoch: 1.1007080078125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,723] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            " Run   5, iteration:   1:   Loss at step 17: 0.97314453125, mean for epoch: 1.0932042738970589, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,846] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            " Run   5, iteration:   1:   Loss at step 18: 1.041015625, mean for epoch: 1.0903049045138888, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:03,960] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            " Run   5, iteration:   1:   Loss at step 19: 0.95849609375, mean for epoch: 1.0833675986842106, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 20: 0.79736328125, mean for epoch: 1.0690673828125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:04,232] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:04,232] [INFO] [timer.py:207:stop] 0/20, RunningAvgSamplesPerSec=42.30775636416822, CurrSamplesPerSec=38.532596912471014, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 21: 0.693359375, mean for epoch: 1.051176525297619, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 22: 0.5595703125, mean for epoch: 1.0288307883522727, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 23: 0.3994140625, mean for epoch: 1.00146484375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 24: 0.415771484375, mean for epoch: 0.9770609537760416, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 25: 0.2127685546875, mean for epoch: 0.9464892578125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 26: 0.2001953125, mean for epoch: 0.91778564453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 27: 0.286376953125, mean for epoch: 0.8944001374421297, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 28: 0.210693359375, mean for epoch: 0.8699820382254464, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 29: 0.202392578125, mean for epoch: 0.8469617120150862, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 30: 0.22705078125, mean for epoch: 0.8262980143229167, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:05,625] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:05,625] [INFO] [timer.py:207:stop] 0/30, RunningAvgSamplesPerSec=40.14748667368379, CurrSamplesPerSec=36.1443947502219, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 31: 0.2255859375, mean for epoch: 0.8069202053931451, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 32: 0.1851806640625, mean for epoch: 0.7874908447265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 33: 0.269775390625, mean for epoch: 0.7718024976325758, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 34: 0.264404296875, mean for epoch: 0.7568790211397058, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 35: 0.2197265625, mean for epoch: 0.7415318080357143, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 36: 0.1959228515625, mean for epoch: 0.7263760036892362, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 37: 0.192138671875, mean for epoch: 0.7119371568834459, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 38: 0.1666259765625, mean for epoch: 0.6975868626644737, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 39: 0.1619873046875, mean for epoch: 0.6838535406650641, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 40: 0.1795654296875, mean for epoch: 0.671246337890625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:07,003] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:07,003] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=39.35503235890358, CurrSamplesPerSec=36.13044609338794, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 41: 0.1427001953125, mean for epoch: 0.6583549685594512, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 42: 0.1396484375, mean for epoch: 0.6460048130580357, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 43: 0.189208984375, mean for epoch: 0.6353816542514535, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 44: 0.18017578125, mean for epoch: 0.6250360662286932, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 45: 0.169189453125, mean for epoch: 0.6149061414930556, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 46: 0.1478271484375, mean for epoch: 0.604752250339674, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 47: 0.1387939453125, mean for epoch: 0.594838243849734, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 48: 0.1328125, mean for epoch: 0.5852127075195312, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 49: 0.1319580078125, mean for epoch: 0.5759626116071429, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 50: 0.168212890625, mean for epoch: 0.5678076171875, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:08,382] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:08,382] [INFO] [timer.py:207:stop] 0/50, RunningAvgSamplesPerSec=38.872038797550275, CurrSamplesPerSec=35.79643427127873, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 51: 0.09716796875, mean for epoch: 0.5585793887867647, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 52: 0.16552734375, mean for epoch: 0.5510206956129807, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 53: 0.14794921875, mean for epoch: 0.5434155734080188, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 54: 0.1600341796875, mean for epoch: 0.53631591796875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 55: 0.1588134765625, mean for epoch: 0.5294522372159091, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 56: 0.10498046875, mean for epoch: 0.5218723842075893, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 57: 0.171142578125, mean for epoch: 0.5157192297149122, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 58: 0.1424560546875, mean for epoch: 0.509283657731681, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 59: 0.1236572265625, mean for epoch: 0.5027476165254238, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 60: 0.12127685546875, mean for epoch: 0.4963897705078125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:09,714] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:09,715] [INFO] [timer.py:207:stop] 0/60, RunningAvgSamplesPerSec=38.80044480143112, CurrSamplesPerSec=38.2877121235634, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 61: 0.230712890625, mean for epoch: 0.492034411821209, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 62: 0.1402587890625, mean for epoch: 0.48636061145413306, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 63: 0.132568359375, mean for epoch: 0.48074486142113093, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 64: 0.1292724609375, mean for epoch: 0.4752531051635742, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 65: 0.1612548828125, mean for epoch: 0.47042236328125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 66: 0.145751953125, mean for epoch: 0.4655031146425189, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 67: 0.1326904296875, mean for epoch: 0.46053576113572764, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 68: 0.08935546875, mean for epoch: 0.4550772274241728, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 69: 0.1444091796875, mean for epoch: 0.45057479194972827, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 70: 0.1153564453125, mean for epoch: 0.4457859584263393, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:11,070] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:11,070] [INFO] [timer.py:207:stop] 0/70, RunningAvgSamplesPerSec=38.67515648978939, CurrSamplesPerSec=38.57334934768494, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 71: 0.1322021484375, mean for epoch: 0.4413692850462148, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 72: 0.09619140625, mean for epoch: 0.43657514784071183, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 73: 0.11822509765625, mean for epoch: 0.4322141882491438, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 74: 0.10784912109375, mean for epoch: 0.4278308765308277, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 75: 0.0897216796875, mean for epoch: 0.42332275390625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 76: 0.123291015625, mean for epoch: 0.4193749678762336, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 77: 0.1451416015625, mean for epoch: 0.4158134955864448, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 78: 0.09954833984375, mean for epoch: 0.4117588141025641, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 79: 0.169921875, mean for epoch: 0.40869758702531644, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 80: 0.125244140625, mean for epoch: 0.4051544189453125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:12,441] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:12,441] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=38.50819854247453, CurrSamplesPerSec=38.49419141441675, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 81: 0.113037109375, mean for epoch: 0.4015480324074074, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 82: 0.1107177734375, mean for epoch: 0.39800132193216464, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 83: 0.1287841796875, mean for epoch: 0.3947577419051205, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 84: 0.11785888671875, mean for epoch: 0.3914613269624256, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 85: 0.1771240234375, mean for epoch: 0.3889397116268382, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 86: 0.10992431640625, mean for epoch: 0.38569534656613375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 87: 0.1673583984375, mean for epoch: 0.38318572647270116, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 88: 0.149169921875, mean for epoch: 0.3805264559659091, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 89: 0.12274169921875, mean for epoch: 0.3776299980249298, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 90: 0.10968017578125, mean for epoch: 0.3746527777777778, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:13,796] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:13,796] [INFO] [timer.py:207:stop] 0/90, RunningAvgSamplesPerSec=38.429509431857916, CurrSamplesPerSec=35.8365003417635, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 91: 0.127197265625, mean for epoch: 0.37193348643543955, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 92: 0.1279296875, mean for epoch: 0.36928127122961957, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 93: 0.101806640625, mean for epoch: 0.3664051999327957, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 94: 0.109619140625, mean for epoch: 0.3636734333444149, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 95: 0.1300048828125, mean for epoch: 0.36121376439144737, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 96: 0.0986328125, mean for epoch: 0.3584785461425781, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 97: 0.10205078125, mean for epoch: 0.3558349609375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 98: 0.1492919921875, mean for epoch: 0.35372737962372447, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 99: 0.10980224609375, mean for epoch: 0.35126348938604796, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 100: 0.121826171875, mean for epoch: 0.3489691162109375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:15,163] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:15,164] [INFO] [timer.py:207:stop] 0/100, RunningAvgSamplesPerSec=38.34004019940913, CurrSamplesPerSec=39.59408151975879, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 101: 0.10797119140625, mean for epoch: 0.34658299814356436, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 102: 0.152099609375, mean for epoch: 0.34467629825367646, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 103: 0.154541015625, mean for epoch: 0.34283032463592233, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 104: 0.11016845703125, mean for epoch: 0.3405931912935697, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 105: 0.1668701171875, mean for epoch: 0.33893868582589287, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 106: 0.1097412109375, mean for epoch: 0.33677644549675706, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 107: 0.1805419921875, mean for epoch: 0.3353163104191005, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 108: 0.1099853515625, mean for epoch: 0.3332299126519097, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 109: 0.088623046875, mean for epoch: 0.33098581296588303, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 110: 0.1595458984375, mean for epoch: 0.3294272682883523, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:16,525] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:16,525] [INFO] [timer.py:207:stop] 0/110, RunningAvgSamplesPerSec=38.29964058346189, CurrSamplesPerSec=38.75741318100082, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 111: 0.1021728515625, mean for epoch: 0.327379931200732, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 112: 0.1248779296875, mean for epoch: 0.3255718776157924, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 113: 0.1302490234375, mean for epoch: 0.3238433567823562, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 114: 0.119873046875, mean for epoch: 0.32205414353755485, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 115: 0.1043701171875, mean for epoch: 0.32016123896059784, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 116: 0.1273193359375, mean for epoch: 0.31849880876212283, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 117: 0.11627197265625, mean for epoch: 0.31677037426549143, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 118: 0.11590576171875, mean for epoch: 0.3150681317862818, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 119: 0.07611083984375, mean for epoch: 0.31306008731617646, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 120: 0.090087890625, mean for epoch: 0.31120198567708335, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:17,880] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:17,880] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=38.26460336329474, CurrSamplesPerSec=39.06824244772649, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 121: 0.09967041015625, mean for epoch: 0.3094537908380682, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 122: 0.11376953125, mean for epoch: 0.3078498214971824, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 123: 0.08782958984375, mean for epoch: 0.3060610391260163, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 124: 0.12646484375, mean for epoch: 0.30461268271169356, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 125: 0.09161376953125, mean for epoch: 0.30290869140625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 126: 0.1256103515625, mean for epoch: 0.3015015617249504, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 127: 0.114013671875, mean for epoch: 0.3000252791277067, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 128: 0.1312255859375, mean for epoch: 0.2987065315246582, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 129: 0.08209228515625, mean for epoch: 0.29702735132025193, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 130: 0.083251953125, mean for epoch: 0.29538292518028847, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:19,263] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:19,263] [INFO] [timer.py:207:stop] 0/130, RunningAvgSamplesPerSec=38.184220531916445, CurrSamplesPerSec=36.046607962680625, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 131: 0.1893310546875, mean for epoch: 0.2945733689169847, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 132: 0.125244140625, mean for epoch: 0.29329057173295453, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 133: 0.09197998046875, mean for epoch: 0.29177695826480265, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 134: 0.08673095703125, mean for epoch: 0.29024676422574625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 135: 0.1014404296875, mean for epoch: 0.28884819878472223, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 136: 0.07940673828125, mean for epoch: 0.2873081880457261, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 137: 0.09356689453125, mean for epoch: 0.28589401802007297, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 138: 0.130859375, mean for epoch: 0.28477057857789856, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 139: 0.10418701171875, mean for epoch: 0.2834714162263939, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 140: 0.0982666015625, mean for epoch: 0.2821485246930804, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:20,606] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:20,607] [INFO] [timer.py:207:stop] 0/140, RunningAvgSamplesPerSec=38.18867635920469, CurrSamplesPerSec=38.43788891027227, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 141: 0.11956787109375, mean for epoch: 0.28099547041223405, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 142: 0.09088134765625, mean for epoch: 0.2796566385618398, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 143: 0.1087646484375, mean for epoch: 0.2784615896798514, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 144: 0.0860595703125, mean for epoch: 0.2771254645453559, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 145: 0.079345703125, mean for epoch: 0.2757614661907328, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 146: 0.1583251953125, mean for epoch: 0.2749571081710188, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 147: 0.1036376953125, mean for epoch: 0.27379166998830784, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 148: 0.11065673828125, mean for epoch: 0.2726894069362331, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 149: 0.10162353515625, mean for epoch: 0.2715413138370386, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 150: 0.12451171875, mean for epoch: 0.2705611165364583, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:21,964] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:21,965] [INFO] [timer.py:207:stop] 0/150, RunningAvgSamplesPerSec=38.16038793607058, CurrSamplesPerSec=36.436659189903416, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 151: 0.1341552734375, mean for epoch: 0.2696577665821606, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 152: 0.0933837890625, mean for epoch: 0.2684980693616365, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 153: 0.0772705078125, mean for epoch: 0.2672482160181781, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 154: 0.104248046875, mean for epoch: 0.2661897733614042, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 155: 0.10137939453125, mean for epoch: 0.2651264805947581, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 156: 0.11077880859375, mean for epoch: 0.26413707244090545, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 157: 0.1256103515625, mean for epoch: 0.2632547366391322, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 158: 0.148681640625, mean for epoch: 0.26252959046182756, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 159: 0.096435546875, mean for epoch: 0.2614849738354953, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 160: 0.09698486328125, mean for epoch: 0.26045684814453124, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:23,332] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:23,332] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=38.12144127274043, CurrSamplesPerSec=39.35268862401297, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   1:   Loss at step 161: 0.123046875, mean for epoch: 0.25960337005046585, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 162: 0.10076904296875, mean for epoch: 0.2586229112413194, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 163: 0.1114501953125, mean for epoch: 0.2577200111435966, mem_alloc: 2342824960\n",
            " Run   5, iteration:   1:   Loss at step 164: 0.138916015625, mean for epoch: 0.2569955965367759, mem_alloc: 2342824960\n",
            "Loss after iteration 1 ; MSE: 0.257080078125, MAE: 0.35595703125\n",
            "Connected by ('127.0.0.1', 49740)\n",
            "\u001b[94mReceived training result: b'1;0.25708;0.35596' \u001b[0m\n",
            "Time per iteration 22.749635457992554, memory OrderedDict([('active.all.allocated', 361654), ('active.all.current', 7), ('active.all.freed', 361647), ('active.all.peak', 295), ('active.large_pool.allocated', 124592), ('active.large_pool.current', 5), ('active.large_pool.freed', 124587), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 237062), ('active.small_pool.current', 2), ('active.small_pool.freed', 237060), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 1208935046656), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 1208884153856), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 1179036943872), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 1178987011584), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 29898102784), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 29897142272), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 1208935046656), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 1208890245632), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 1179036943872), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 1178993103360), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 29898102784), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 29897142272), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 361654), ('allocation.all.current', 6), ('allocation.all.freed', 361648), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 124592), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 124588), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 237062), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 237060), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 155851), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 155847), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 82458), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 82457), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 73393), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 73390), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 731915439104), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 731903417344), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 696765737984), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 696756950016), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 35149701120), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 35146467328), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   5, iteration:   2:   Loss at step 1: 0.084228515625, mean for epoch: 0.084228515625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 2: 0.1116943359375, mean for epoch: 0.09796142578125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 3: 0.08221435546875, mean for epoch: 0.09271240234375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 4: 0.0858154296875, mean for epoch: 0.0909881591796875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 5: 0.09136962890625, mean for epoch: 0.091064453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 6: 0.09759521484375, mean for epoch: 0.09215291341145833, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:24,812] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:24,813] [INFO] [timer.py:207:stop] 0/170, RunningAvgSamplesPerSec=38.12032764425917, CurrSamplesPerSec=39.31941285765979, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 7: 0.08203125, mean for epoch: 0.09070696149553571, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 8: 0.0936279296875, mean for epoch: 0.09107208251953125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 9: 0.08563232421875, mean for epoch: 0.09046766493055555, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 10: 0.09051513671875, mean for epoch: 0.090472412109375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 11: 0.08172607421875, mean for epoch: 0.08967729048295454, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 12: 0.09246826171875, mean for epoch: 0.08990987141927083, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 13: 0.06768798828125, mean for epoch: 0.08820049579326923, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 14: 0.12359619140625, mean for epoch: 0.090728759765625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 15: 0.09814453125, mean for epoch: 0.09122314453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 16: 0.07403564453125, mean for epoch: 0.09014892578125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:26,187] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:26,188] [INFO] [timer.py:207:stop] 0/180, RunningAvgSamplesPerSec=38.071072477676196, CurrSamplesPerSec=36.09450325894079, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 17: 0.09637451171875, mean for epoch: 0.09051513671875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 18: 0.07452392578125, mean for epoch: 0.0896267361111111, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 19: 0.06781005859375, mean for epoch: 0.08847848992598684, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 20: 0.10308837890625, mean for epoch: 0.089208984375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 21: 0.08135986328125, mean for epoch: 0.08883521670386904, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 22: 0.08111572265625, mean for epoch: 0.08848433061079546, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 23: 0.1463623046875, mean for epoch: 0.09100076426630435, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 24: 0.07830810546875, mean for epoch: 0.09047190348307292, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 25: 0.10784912109375, mean for epoch: 0.0911669921875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 26: 0.08819580078125, mean for epoch: 0.09105271559495193, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:27,550] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:27,550] [INFO] [timer.py:207:stop] 0/190, RunningAvgSamplesPerSec=38.04823927268468, CurrSamplesPerSec=36.52639480829822, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 27: 0.081787109375, mean for epoch: 0.09070954499421297, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 28: 0.08270263671875, mean for epoch: 0.090423583984375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 29: 0.08758544921875, mean for epoch: 0.09032571726831896, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 30: 0.0941162109375, mean for epoch: 0.09045206705729167, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 31: 0.10125732421875, mean for epoch: 0.09080062373991936, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 32: 0.0777587890625, mean for epoch: 0.09039306640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 33: 0.125244140625, mean for epoch: 0.09144915956439394, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 34: 0.1007080078125, mean for epoch: 0.0917214786305147, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 35: 0.09228515625, mean for epoch: 0.09173758370535715, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 36: 0.1417236328125, mean for epoch: 0.09312608506944445, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:28,901] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:28,902] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=38.04088167140768, CurrSamplesPerSec=38.98399857236333, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 37: 0.0826416015625, mean for epoch: 0.09284272065033784, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 38: 0.088623046875, mean for epoch: 0.09273167660361842, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 39: 0.09906005859375, mean for epoch: 0.09289394280849358, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 40: 0.06427001953125, mean for epoch: 0.0921783447265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 41: 0.061187744140625, mean for epoch: 0.09142247641958841, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 42: 0.08837890625, mean for epoch: 0.09135001046316964, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 43: 0.1302490234375, mean for epoch: 0.092254638671875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 44: 0.1024169921875, mean for epoch: 0.09248560125177557, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 45: 0.068603515625, mean for epoch: 0.09195488823784723, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 46: 0.0738525390625, mean for epoch: 0.09156135890794836, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:30,268] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:30,268] [INFO] [timer.py:207:stop] 0/210, RunningAvgSamplesPerSec=38.01777525693863, CurrSamplesPerSec=36.6674068388412, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 47: 0.07861328125, mean for epoch: 0.09128586789394946, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 48: 0.07989501953125, mean for epoch: 0.09104855855305989, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 49: 0.09088134765625, mean for epoch: 0.09104514608577806, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 50: 0.08868408203125, mean for epoch: 0.0909979248046875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 51: 0.0777587890625, mean for epoch: 0.09073833390778187, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 52: 0.1263427734375, mean for epoch: 0.09142303466796875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 53: 0.08184814453125, mean for epoch: 0.09124237636350235, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 54: 0.1092529296875, mean for epoch: 0.09157590512876157, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 55: 0.087158203125, mean for epoch: 0.09149558327414772, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 56: 0.10150146484375, mean for epoch: 0.09167425973074776, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:31,626] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:31,627] [INFO] [timer.py:207:stop] 0/220, RunningAvgSamplesPerSec=38.01093216695306, CurrSamplesPerSec=38.68320621247475, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 57: 0.07952880859375, mean for epoch: 0.091461181640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 58: 0.0797119140625, mean for epoch: 0.09125860806169181, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 59: 0.110595703125, mean for epoch: 0.09158635543564618, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 60: 0.08709716796875, mean for epoch: 0.09151153564453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 61: 0.09832763671875, mean for epoch: 0.09162327500640369, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 62: 0.12200927734375, mean for epoch: 0.09211337181829637, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 63: 0.08905029296875, mean for epoch: 0.09206475151909722, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 64: 0.08575439453125, mean for epoch: 0.09196615219116211, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 65: 0.09735107421875, mean for epoch: 0.09204899714543269, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 66: 0.074462890625, mean for epoch: 0.0917825409860322, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:32,994] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:32,994] [INFO] [timer.py:207:stop] 0/230, RunningAvgSamplesPerSec=37.99562698467579, CurrSamplesPerSec=36.99659521919379, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 67: 0.09423828125, mean for epoch: 0.09181919382579291, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 68: 0.1409912109375, mean for epoch: 0.09254231172449448, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 69: 0.08929443359375, mean for epoch: 0.09249524102694746, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 70: 0.09814453125, mean for epoch: 0.09257594517299107, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 71: 0.095703125, mean for epoch: 0.09261998995928697, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 72: 0.10614013671875, mean for epoch: 0.09280776977539062, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 73: 0.09783935546875, mean for epoch: 0.0928766956068065, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 74: 0.098388671875, mean for epoch: 0.0929511817725929, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 75: 0.073974609375, mean for epoch: 0.09269816080729167, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 76: 0.06500244140625, mean for epoch: 0.09233374344675165, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:34,353] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:34,354] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=37.9940649223875, CurrSamplesPerSec=36.58118882863208, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 77: 0.094970703125, mean for epoch: 0.09236798967633929, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 78: 0.09228515625, mean for epoch: 0.09236692770933494, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 79: 0.08538818359375, mean for epoch: 0.09227858917622626, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 80: 0.098388671875, mean for epoch: 0.09235496520996093, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 81: 0.09136962890625, mean for epoch: 0.0923428005642361, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 82: 0.1072998046875, mean for epoch: 0.09252520305354421, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 83: 0.08447265625, mean for epoch: 0.09242818441735692, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 84: 0.08099365234375, mean for epoch: 0.09229205903552827, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 85: 0.07220458984375, mean for epoch: 0.09205573586856618, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 86: 0.09027099609375, mean for epoch: 0.09203498308048692, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:35,729] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:35,730] [INFO] [timer.py:207:stop] 0/250, RunningAvgSamplesPerSec=37.970293612486195, CurrSamplesPerSec=36.29961193213486, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 87: 0.09173583984375, mean for epoch: 0.09203154465247845, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 88: 0.1090087890625, mean for epoch: 0.09222446788441051, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 89: 0.10400390625, mean for epoch: 0.09235682112447331, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 90: 0.11651611328125, mean for epoch: 0.09262525770399306, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 91: 0.095458984375, mean for epoch: 0.0926563975575206, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 92: 0.08782958984375, mean for epoch: 0.09260393225628397, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 93: 0.059356689453125, mean for epoch: 0.09224643502184139, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 94: 0.0740966796875, mean for epoch: 0.09205335251828457, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 95: 0.1007080078125, mean for epoch: 0.09214445415296052, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 96: 0.08404541015625, mean for epoch: 0.09206008911132812, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:37,093] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:37,093] [INFO] [timer.py:207:stop] 0/260, RunningAvgSamplesPerSec=37.9552932960596, CurrSamplesPerSec=37.84366304438053, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 97: 0.1077880859375, mean for epoch: 0.09222223340850516, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 98: 0.08349609375, mean for epoch: 0.09213319116709184, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 99: 0.10174560546875, mean for epoch: 0.09223028626104798, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 100: 0.09136962890625, mean for epoch: 0.0922216796875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 101: 0.08819580078125, mean for epoch: 0.0921818195003094, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 102: 0.0721435546875, mean for epoch: 0.09198536592371323, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 103: 0.10418701171875, mean for epoch: 0.09210382850424757, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 104: 0.07666015625, mean for epoch: 0.09195533165564904, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 105: 0.11016845703125, mean for epoch: 0.09212878999255952, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 106: 0.09979248046875, mean for epoch: 0.09220108895931604, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:38,449] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:38,450] [INFO] [timer.py:207:stop] 0/270, RunningAvgSamplesPerSec=37.94877535118874, CurrSamplesPerSec=36.0061946082185, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 107: 0.09112548828125, mean for epoch: 0.09219103661653037, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 108: 0.076171875, mean for epoch: 0.09204271104600695, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 109: 0.086669921875, mean for epoch: 0.09199341940223624, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 110: 0.1461181640625, mean for epoch: 0.09248546253551136, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 111: 0.0909423828125, mean for epoch: 0.09247156091638513, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 112: 0.1064453125, mean for epoch: 0.09259632655552455, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 113: 0.0904541015625, mean for epoch: 0.09257736881222345, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 114: 0.11248779296875, mean for epoch: 0.09275202165570176, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 115: 0.11175537109375, mean for epoch: 0.09291726817255434, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 116: 0.0784912109375, mean for epoch: 0.09279290561018319, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:39,798] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:39,798] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=37.95190293907678, CurrSamplesPerSec=39.24414187497427, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 117: 0.10113525390625, mean for epoch: 0.09286420773237179, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 118: 0.0772705078125, mean for epoch: 0.09273205773305085, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 119: 0.07666015625, mean for epoch: 0.09259699973739496, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 120: 0.09136962890625, mean for epoch: 0.09258677164713541, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 121: 0.1231689453125, mean for epoch: 0.09283951688403926, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 122: 0.06878662109375, mean for epoch: 0.09264236200051229, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 123: 0.07513427734375, mean for epoch: 0.0925000198488313, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 124: 0.067626953125, mean for epoch: 0.09229943060105847, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 125: 0.0662841796875, mean for epoch: 0.09209130859375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 126: 0.0677490234375, mean for epoch: 0.09189811585441468, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:41,181] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:41,181] [INFO] [timer.py:207:stop] 0/290, RunningAvgSamplesPerSec=37.93200114447945, CurrSamplesPerSec=37.153375450432094, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 127: 0.1685791015625, mean for epoch: 0.09250190314345473, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 128: 0.10595703125, mean for epoch: 0.09260702133178711, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 129: 0.08111572265625, mean for epoch: 0.09251794149709303, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 130: 0.132080078125, mean for epoch: 0.092822265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 131: 0.084228515625, mean for epoch: 0.09275666447996184, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 132: 0.06573486328125, mean for epoch: 0.09255195386482007, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 133: 0.069580078125, mean for epoch: 0.09237923299459587, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 134: 0.14990234375, mean for epoch: 0.09280850994053172, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 135: 0.099609375, mean for epoch: 0.09285888671875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 136: 0.08013916015625, mean for epoch: 0.09276535931755514, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:42,547] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:42,547] [INFO] [timer.py:207:stop] 0/300, RunningAvgSamplesPerSec=37.92438024730759, CurrSamplesPerSec=37.1350861287398, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 137: 0.114501953125, mean for epoch: 0.09292402058622262, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 138: 0.08306884765625, mean for epoch: 0.09285260628962862, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 139: 0.08984375, mean for epoch: 0.0928309598415018, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 140: 0.08050537109375, mean for epoch: 0.092742919921875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 141: 0.0740966796875, mean for epoch: 0.09261067708333333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 142: 0.1051025390625, mean for epoch: 0.09269864794234155, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 143: 0.1099853515625, mean for epoch: 0.09281953398164336, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 144: 0.07452392578125, mean for epoch: 0.0926924811469184, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 145: 0.07196044921875, mean for epoch: 0.09254950161637931, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 146: 0.09130859375, mean for epoch: 0.0925410022474315, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:43,884] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:43,885] [INFO] [timer.py:207:stop] 0/310, RunningAvgSamplesPerSec=37.94063688349054, CurrSamplesPerSec=37.61680633681552, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 147: 0.0897216796875, mean for epoch: 0.09252182318239796, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 148: 0.08648681640625, mean for epoch: 0.09248104610958614, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 149: 0.11956787109375, mean for epoch: 0.09266283688129194, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 150: 0.09100341796875, mean for epoch: 0.09265177408854167, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 151: 0.06585693359375, mean for epoch: 0.09247432481374172, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 152: 0.085693359375, mean for epoch: 0.09242971319901316, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 153: 0.08392333984375, mean for epoch: 0.09237411598754085, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 154: 0.09130859375, mean for epoch: 0.09236719701197241, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 155: 0.1116943359375, mean for epoch: 0.09249188823084678, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 156: 0.1015625, mean for epoch: 0.09255003317808494, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:45,246] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:45,246] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=37.9315634160438, CurrSamplesPerSec=36.871122175748404, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   2:   Loss at step 157: 0.097412109375, mean for epoch: 0.09258100181628184, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 158: 0.102783203125, mean for epoch: 0.09264557271064082, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 159: 0.08740234375, mean for epoch: 0.0926125964278695, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 160: 0.06829833984375, mean for epoch: 0.09246063232421875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 161: 0.08782958984375, mean for epoch: 0.09243186808520963, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 162: 0.09063720703125, mean for epoch: 0.09242078993055555, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 163: 0.08917236328125, mean for epoch: 0.09240086093270705, mem_alloc: 2342824960\n",
            " Run   5, iteration:   2:   Loss at step 164: 0.1160888671875, mean for epoch: 0.09254529999523628, mem_alloc: 2342824960\n",
            "Loss after iteration 2 ; MSE: 0.092529296875, MAE: 0.2308349609375\n",
            "Connected by ('127.0.0.1', 59194)\n",
            "\u001b[94mReceived training result: b'2;0.09253;0.23083' \u001b[0m\n",
            "Time per iteration 22.621360301971436, memory OrderedDict([('active.all.allocated', 735902), ('active.all.current', 7), ('active.all.freed', 735895), ('active.all.peak', 295), ('active.large_pool.allocated', 249232), ('active.large_pool.current', 5), ('active.large_pool.freed', 249227), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 486670), ('active.small_pool.current', 2), ('active.small_pool.freed', 486668), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 2418899820032), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 2418848927232), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 2358449876480), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 2358399944192), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 60449943552), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 60448983040), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 2418899820032), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 2418855019008), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 2358449876480), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 2358406035968), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 60449943552), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 60448983040), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 735902), ('allocation.all.current', 6), ('allocation.all.freed', 735896), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 249232), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 249228), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 486670), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 486668), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 315416), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 315412), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 164950), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 164949), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 150466), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 150463), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 1464827961856), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 1464815940096), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 1393895699456), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 1393886911488), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 70932262400), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 70929028608), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   5, iteration:   3:   Loss at step 1: 0.0836181640625, mean for epoch: 0.0836181640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 2: 0.08013916015625, mean for epoch: 0.081878662109375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:46,780] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:46,781] [INFO] [timer.py:207:stop] 0/330, RunningAvgSamplesPerSec=37.89468349157339, CurrSamplesPerSec=37.89803150531203, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 3: 0.08709716796875, mean for epoch: 0.0836181640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 4: 0.0703125, mean for epoch: 0.080291748046875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 5: 0.0745849609375, mean for epoch: 0.079150390625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 6: 0.08447265625, mean for epoch: 0.08003743489583333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 7: 0.0865478515625, mean for epoch: 0.08096749441964286, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 8: 0.112548828125, mean for epoch: 0.0849151611328125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 9: 0.083984375, mean for epoch: 0.0848117404513889, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 10: 0.10107421875, mean for epoch: 0.08643798828125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 11: 0.093505859375, mean for epoch: 0.08708052201704546, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 12: 0.1195068359375, mean for epoch: 0.08978271484375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:48,131] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:48,131] [INFO] [timer.py:207:stop] 0/340, RunningAvgSamplesPerSec=37.892886819573086, CurrSamplesPerSec=36.19636095011581, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 13: 0.076904296875, mean for epoch: 0.0887920673076923, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 14: 0.10772705078125, mean for epoch: 0.09014456612723214, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 15: 0.06817626953125, mean for epoch: 0.08868001302083334, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 16: 0.08349609375, mean for epoch: 0.08835601806640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 17: 0.06671142578125, mean for epoch: 0.0870828067555147, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 18: 0.10333251953125, mean for epoch: 0.0879855685763889, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 19: 0.08563232421875, mean for epoch: 0.08786171361019737, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 20: 0.07952880859375, mean for epoch: 0.087445068359375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 21: 0.10382080078125, mean for epoch: 0.08822486514136904, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 22: 0.0870361328125, mean for epoch: 0.08817083185369318, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:49,487] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:49,487] [INFO] [timer.py:207:stop] 0/350, RunningAvgSamplesPerSec=37.89000555400071, CurrSamplesPerSec=39.14532371414972, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 23: 0.11126708984375, mean for epoch: 0.08917501698369565, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 24: 0.1009521484375, mean for epoch: 0.08966573079427083, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 25: 0.10540771484375, mean for epoch: 0.09029541015625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 26: 0.0789794921875, mean for epoch: 0.0898601825420673, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 27: 0.1005859375, mean for epoch: 0.09025743272569445, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 28: 0.10174560546875, mean for epoch: 0.090667724609375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 29: 0.08953857421875, mean for epoch: 0.09062878838900862, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 30: 0.08123779296875, mean for epoch: 0.09031575520833333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 31: 0.0579833984375, mean for epoch: 0.0892727759576613, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 32: 0.11859130859375, mean for epoch: 0.09018898010253906, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:50,873] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:50,874] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=37.864190325716336, CurrSamplesPerSec=36.23432249146905, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 33: 0.074951171875, mean for epoch: 0.08972722833806818, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 34: 0.09375, mean for epoch: 0.08984554515165441, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 35: 0.08349609375, mean for epoch: 0.08966413225446429, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 36: 0.07568359375, mean for epoch: 0.0892757839626736, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 37: 0.11932373046875, mean for epoch: 0.090087890625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 38: 0.09600830078125, mean for epoch: 0.09024369089226973, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 39: 0.0740966796875, mean for epoch: 0.0898296649639423, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 40: 0.075927734375, mean for epoch: 0.08948211669921875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 41: 0.08233642578125, mean for epoch: 0.08930783155487805, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 42: 0.0738525390625, mean for epoch: 0.08893984840029762, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:52,234] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:52,234] [INFO] [timer.py:207:stop] 0/370, RunningAvgSamplesPerSec=37.85830854112939, CurrSamplesPerSec=39.42585674994313, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 43: 0.06427001953125, mean for epoch: 0.08836613144985465, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 44: 0.10455322265625, mean for epoch: 0.08873401988636363, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 45: 0.0772705078125, mean for epoch: 0.08847927517361111, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 46: 0.07745361328125, mean for epoch: 0.08823958687160326, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 47: 0.07745361328125, mean for epoch: 0.08801009807180851, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 48: 0.08319091796875, mean for epoch: 0.08790969848632812, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 49: 0.09356689453125, mean for epoch: 0.08802515146683673, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 50: 0.085693359375, mean for epoch: 0.087978515625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 51: 0.09002685546875, mean for epoch: 0.08801867915134803, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 52: 0.065673828125, mean for epoch: 0.08758897047776443, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:53,594] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:53,594] [INFO] [timer.py:207:stop] 0/380, RunningAvgSamplesPerSec=37.85574029738259, CurrSamplesPerSec=36.78097700171702, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 53: 0.09027099609375, mean for epoch: 0.08763957473466981, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 54: 0.08282470703125, mean for epoch: 0.08755041051793981, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 55: 0.062347412109375, mean for epoch: 0.08709217418323864, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 56: 0.07269287109375, mean for epoch: 0.08683504377092634, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 57: 0.0916748046875, mean for epoch: 0.08691995185718202, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 58: 0.089111328125, mean for epoch: 0.08695773420662715, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 59: 0.080810546875, mean for epoch: 0.08685354459083687, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 60: 0.12188720703125, mean for epoch: 0.08743743896484375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 61: 0.07366943359375, mean for epoch: 0.08721173395876025, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 62: 0.09649658203125, mean for epoch: 0.08736148957283266, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:54,954] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:54,955] [INFO] [timer.py:207:stop] 0/390, RunningAvgSamplesPerSec=37.8577400445963, CurrSamplesPerSec=39.206944192576834, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 63: 0.110107421875, mean for epoch: 0.08772253611731151, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 64: 0.07666015625, mean for epoch: 0.08754968643188477, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 65: 0.1026611328125, mean for epoch: 0.08778217022235577, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 66: 0.1158447265625, mean for epoch: 0.08820736046993372, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 67: 0.0777587890625, mean for epoch: 0.08805141164295709, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 68: 0.07666015625, mean for epoch: 0.08788389318129596, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 69: 0.07171630859375, mean for epoch: 0.0876495803611866, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 70: 0.06732177734375, mean for epoch: 0.08735918317522322, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 71: 0.06488037109375, mean for epoch: 0.08704258018816022, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 72: 0.07061767578125, mean for epoch: 0.08681445651584202, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:56,325] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:56,326] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=37.85309918193525, CurrSamplesPerSec=37.41086352714098, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 73: 0.09716796875, mean for epoch: 0.0869562854505565, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 74: 0.0875244140625, mean for epoch: 0.08696396286423141, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 75: 0.10040283203125, mean for epoch: 0.08714314778645833, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 76: 0.0921630859375, mean for epoch: 0.08720919960423519, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 77: 0.109130859375, mean for epoch: 0.087493896484375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 78: 0.08758544921875, mean for epoch: 0.0874950702373798, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 79: 0.06005859375, mean for epoch: 0.08714777306665349, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 80: 0.07220458984375, mean for epoch: 0.08696098327636718, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 81: 0.09625244140625, mean for epoch: 0.08707569263599536, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 82: 0.08831787109375, mean for epoch: 0.08709084115377287, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:57,677] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:57,678] [INFO] [timer.py:207:stop] 0/410, RunningAvgSamplesPerSec=37.85604631179743, CurrSamplesPerSec=38.228108839222074, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 83: 0.1170654296875, mean for epoch: 0.08745198077466114, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 84: 0.0714111328125, mean for epoch: 0.08726101829892113, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 85: 0.06451416015625, mean for epoch: 0.086993408203125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 86: 0.08892822265625, mean for epoch: 0.08701590604560319, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 87: 0.07330322265625, mean for epoch: 0.08685828899515086, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 88: 0.10491943359375, mean for epoch: 0.0870635292746804, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 89: 0.07421875, mean for epoch: 0.08691920591204354, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 90: 0.0655517578125, mean for epoch: 0.0866817898220486, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 91: 0.0633544921875, mean for epoch: 0.08642544589199863, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 92: 0.0916748046875, mean for epoch: 0.08648250413977582, mem_alloc: 2342824960\n",
            "[2022-10-25 13:50:59,056] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:50:59,056] [INFO] [timer.py:207:stop] 0/420, RunningAvgSamplesPerSec=37.84078822566336, CurrSamplesPerSec=36.32904068488357, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 93: 0.08819580078125, mean for epoch: 0.0865009266843078, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 94: 0.06610107421875, mean for epoch: 0.08628390697722739, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 95: 0.06732177734375, mean for epoch: 0.08608430561266447, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 96: 0.0699462890625, mean for epoch: 0.08591620127360027, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 97: 0.08251953125, mean for epoch: 0.08588118405686211, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 98: 0.0980224609375, mean for epoch: 0.08600507463727679, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 99: 0.1080322265625, mean for epoch: 0.08622757112136994, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 100: 0.08154296875, mean for epoch: 0.08618072509765624, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 101: 0.06695556640625, mean for epoch: 0.08599037699180075, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 102: 0.060638427734375, mean for epoch: 0.08574182846966912, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:00,421] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:00,422] [INFO] [timer.py:207:stop] 0/430, RunningAvgSamplesPerSec=37.834272164498664, CurrSamplesPerSec=37.855002563195406, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 103: 0.08343505859375, mean for epoch: 0.08571943264563107, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 104: 0.06829833984375, mean for epoch: 0.08555192213792068, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 105: 0.06024169921875, mean for epoch: 0.08531087239583333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 106: 0.134765625, mean for epoch: 0.08577742666568396, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 107: 0.08099365234375, mean for epoch: 0.08573271849445094, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 108: 0.06353759765625, mean for epoch: 0.08552720811631945, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 109: 0.06756591796875, mean for epoch: 0.08536242563790138, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 110: 0.11962890625, mean for epoch: 0.08567393909801137, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 111: 0.07037353515625, mean for epoch: 0.08553609762105856, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 112: 0.06298828125, mean for epoch: 0.08533477783203125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:01,813] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:01,813] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=37.81393509769491, CurrSamplesPerSec=35.82187042544142, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 113: 0.0711669921875, mean for epoch: 0.08520939919800885, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 114: 0.086181640625, mean for epoch: 0.08521792763157894, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 115: 0.07403564453125, mean for epoch: 0.08512069038722826, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 116: 0.0819091796875, mean for epoch: 0.08509300495016164, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 117: 0.07879638671875, mean for epoch: 0.08503918770032051, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 118: 0.084228515625, mean for epoch: 0.0850323175979873, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 119: 0.08685302734375, mean for epoch: 0.08504761767988446, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 120: 0.0960693359375, mean for epoch: 0.08513946533203125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 121: 0.07318115234375, mean for epoch: 0.08504063629907024, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 122: 0.085205078125, mean for epoch: 0.08504198418288934, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:03,197] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:03,198] [INFO] [timer.py:207:stop] 0/450, RunningAvgSamplesPerSec=37.79845478810639, CurrSamplesPerSec=38.23396322731789, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 123: 0.08062744140625, mean for epoch: 0.08500609359120935, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 124: 0.067138671875, mean for epoch: 0.08486200148059476, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 125: 0.0650634765625, mean for epoch: 0.08470361328125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 126: 0.10504150390625, mean for epoch: 0.08486502511160714, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 127: 0.0755615234375, mean for epoch: 0.08479176919291338, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 128: 0.10430908203125, mean for epoch: 0.08494424819946289, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 129: 0.059478759765625, mean for epoch: 0.08474684131237888, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 130: 0.08282470703125, mean for epoch: 0.0847320556640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 131: 0.06695556640625, mean for epoch: 0.08459635727278149, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 132: 0.0699462890625, mean for epoch: 0.08448537190755208, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:04,563] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:04,564] [INFO] [timer.py:207:stop] 0/460, RunningAvgSamplesPerSec=37.79493170525009, CurrSamplesPerSec=38.94787083690066, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 133: 0.100341796875, mean for epoch: 0.08460459314790883, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 134: 0.08197021484375, mean for epoch: 0.08458493360832556, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 135: 0.07666015625, mean for epoch: 0.08452623155381944, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 136: 0.07562255859375, mean for epoch: 0.08446076337028952, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 137: 0.0928955078125, mean for epoch: 0.0845223308479699, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 138: 0.0802001953125, mean for epoch: 0.0844910110252491, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 139: 0.08685302734375, mean for epoch: 0.08450800394840377, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 140: 0.0762939453125, mean for epoch: 0.08444933210100447, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 141: 0.08599853515625, mean for epoch: 0.08446031935671543, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 142: 0.0579833984375, mean for epoch: 0.08427386216714348, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:05,937] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:05,937] [INFO] [timer.py:207:stop] 0/470, RunningAvgSamplesPerSec=37.7851360201301, CurrSamplesPerSec=38.53989058184217, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 143: 0.102294921875, mean for epoch: 0.08439988356370193, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 144: 0.08184814453125, mean for epoch: 0.08438216315375434, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 145: 0.07757568359375, mean for epoch: 0.08433522191540949, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 146: 0.10565185546875, mean for epoch: 0.08448122625481592, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 147: 0.09710693359375, mean for epoch: 0.0845671154203869, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 148: 0.0684814453125, mean for epoch: 0.08445842846019848, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 149: 0.07720947265625, mean for epoch: 0.08440977775010487, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 150: 0.10589599609375, mean for epoch: 0.08455301920572916, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 151: 0.07977294921875, mean for epoch: 0.08452136311310017, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 152: 0.085693359375, mean for epoch: 0.08452907361482319, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:07,323] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:07,324] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=37.76772507488621, CurrSamplesPerSec=38.32556643530448, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 153: 0.078857421875, mean for epoch: 0.08449200399560866, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 154: 0.1109619140625, mean for epoch: 0.08466388652851055, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 155: 0.08026123046875, mean for epoch: 0.08463548229586694, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 156: 0.062744140625, mean for epoch: 0.08449515318259215, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 157: 0.06854248046875, mean for epoch: 0.0843935438022492, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 158: 0.051971435546875, mean for epoch: 0.08418834058544304, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 159: 0.10137939453125, mean for epoch: 0.08429646042158019, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 160: 0.08001708984375, mean for epoch: 0.08426971435546875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 161: 0.07403564453125, mean for epoch: 0.08420614870438664, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 162: 0.07122802734375, mean for epoch: 0.0841260368441358, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:08,693] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:08,694] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=37.7627222754036, CurrSamplesPerSec=37.983764340231616, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   3:   Loss at step 163: 0.12408447265625, mean for epoch: 0.08437118062212423, mem_alloc: 2342824960\n",
            " Run   5, iteration:   3:   Loss at step 164: 0.09344482421875, mean for epoch: 0.08442650771722561, mem_alloc: 2342824960\n",
            "Loss after iteration 3 ; MSE: 0.08441162109375, MAE: 0.2193603515625\n",
            "Connected by ('127.0.0.1', 43288)\n",
            "\u001b[94mReceived training result: b'3;0.08441;0.21936' \u001b[0m\n",
            "Time per iteration 22.62370689709981, memory OrderedDict([('active.all.allocated', 1110150), ('active.all.current', 7), ('active.all.freed', 1110143), ('active.all.peak', 295), ('active.large_pool.allocated', 373872), ('active.large_pool.current', 5), ('active.large_pool.freed', 373867), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 736278), ('active.small_pool.current', 2), ('active.small_pool.freed', 736276), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 3628864593408), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 3628813700608), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 3537862809088), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 3537812876800), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 91001784320), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 91000823808), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 3628864593408), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 3628819792384), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 3537862809088), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 3537818968576), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 91001784320), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 91000823808), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1110150), ('allocation.all.current', 6), ('allocation.all.freed', 1110144), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 373872), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 373868), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 736278), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 736276), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 474981), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 474977), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 247442), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 247441), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 227539), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 227536), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2197740484608), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2197728462848), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2091025660928), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2091016872960), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 106714823680), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 106711589888), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   5, iteration:   4:   Loss at step 1: 0.1080322265625, mean for epoch: 0.1080322265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 2: 0.0762939453125, mean for epoch: 0.0921630859375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 3: 0.10650634765625, mean for epoch: 0.09694417317708333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 4: 0.068359375, mean for epoch: 0.0897979736328125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 5: 0.11041259765625, mean for epoch: 0.0939208984375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 6: 0.08447265625, mean for epoch: 0.09234619140625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 7: 0.06640625, mean for epoch: 0.08864048549107142, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 8: 0.08758544921875, mean for epoch: 0.08850860595703125, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:10,214] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:10,215] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=37.74725548896965, CurrSamplesPerSec=37.7968740988523, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 9: 0.081787109375, mean for epoch: 0.08776177300347222, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 10: 0.09320068359375, mean for epoch: 0.0883056640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 11: 0.07928466796875, mean for epoch: 0.08748557350852272, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 12: 0.09490966796875, mean for epoch: 0.088104248046875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 13: 0.07684326171875, mean for epoch: 0.08723801832932693, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 14: 0.10760498046875, mean for epoch: 0.08869280133928571, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 15: 0.099853515625, mean for epoch: 0.08943684895833333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 16: 0.126220703125, mean for epoch: 0.09173583984375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 17: 0.08447265625, mean for epoch: 0.09130859375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 18: 0.08203125, mean for epoch: 0.0907931857638889, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:11,559] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:11,560] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=37.754138914555355, CurrSamplesPerSec=38.07320345447977, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 19: 0.0999755859375, mean for epoch: 0.09127646998355263, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 20: 0.073974609375, mean for epoch: 0.090411376953125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 21: 0.0797119140625, mean for epoch: 0.0899018787202381, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 22: 0.06939697265625, mean for epoch: 0.08896983753551137, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 23: 0.087890625, mean for epoch: 0.08892291525135869, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 24: 0.10504150390625, mean for epoch: 0.08959452311197917, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 25: 0.0748291015625, mean for epoch: 0.08900390625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 26: 0.06640625, mean for epoch: 0.088134765625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 27: 0.0859375, mean for epoch: 0.08805338541666667, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 28: 0.05499267578125, mean for epoch: 0.08687264578683036, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:12,939] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:12,939] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=37.74129152296113, CurrSamplesPerSec=36.53797705435, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 29: 0.08477783203125, mean for epoch: 0.08680041082974138, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 30: 0.0738525390625, mean for epoch: 0.08636881510416666, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 31: 0.067626953125, mean for epoch: 0.08576423891129033, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 32: 0.08026123046875, mean for epoch: 0.08559226989746094, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 33: 0.073486328125, mean for epoch: 0.08522542317708333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 34: 0.05938720703125, mean for epoch: 0.08446547564338236, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 35: 0.06402587890625, mean for epoch: 0.08388148716517857, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 36: 0.07635498046875, mean for epoch: 0.08367241753472222, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 37: 0.08843994140625, mean for epoch: 0.08380126953125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 38: 0.08489990234375, mean for epoch: 0.08383018092105263, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:14,324] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:14,324] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=37.72789943848409, CurrSamplesPerSec=37.3814557212476, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 39: 0.078857421875, mean for epoch: 0.08370267427884616, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 40: 0.0701904296875, mean for epoch: 0.0833648681640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 41: 0.0870361328125, mean for epoch: 0.08345441120426829, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 42: 0.10797119140625, mean for epoch: 0.08403814406622023, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 43: 0.07708740234375, mean for epoch: 0.08387649890988372, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 44: 0.10797119140625, mean for epoch: 0.08442410555752841, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 45: 0.07855224609375, mean for epoch: 0.08429361979166666, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 46: 0.05804443359375, mean for epoch: 0.08372298530910326, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 47: 0.0748291015625, mean for epoch: 0.0835337537400266, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 48: 0.07733154296875, mean for epoch: 0.083404541015625, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:15,842] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:15,843] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=37.65277277157765, CurrSamplesPerSec=28.072069177843815, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 49: 0.0628662109375, mean for epoch: 0.08298539142219388, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 50: 0.111572265625, mean for epoch: 0.08355712890625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 51: 0.060638427734375, mean for epoch: 0.08310774260876226, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 52: 0.07373046875, mean for epoch: 0.08292741041917068, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 53: 0.055572509765625, mean for epoch: 0.08241128021816038, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 54: 0.0574951171875, mean for epoch: 0.08194986979166667, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 55: 0.055023193359375, mean for epoch: 0.0814602938565341, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 56: 0.10980224609375, mean for epoch: 0.08196640014648438, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 57: 0.0875244140625, mean for epoch: 0.08206390916255482, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 58: 0.06292724609375, mean for epoch: 0.0817339666958513, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:17,582] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:17,582] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=37.47557505627536, CurrSamplesPerSec=29.638624370030556, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 59: 0.0904541015625, mean for epoch: 0.08188176559189618, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 60: 0.05682373046875, mean for epoch: 0.08146413167317708, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 61: 0.0665283203125, mean for epoch: 0.0812192823066086, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 62: 0.0928955078125, mean for epoch: 0.08140760852444556, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 63: 0.07440185546875, mean for epoch: 0.08129640609499007, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 64: 0.056884765625, mean for epoch: 0.08091497421264648, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 65: 0.1002197265625, mean for epoch: 0.08121197040264423, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 66: 0.0753173828125, mean for epoch: 0.08112265846946022, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 67: 0.0914306640625, mean for epoch: 0.08127650929920709, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 68: 0.058135986328125, mean for epoch: 0.08093620749080882, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:19,029] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:19,029] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=37.44138857877859, CurrSamplesPerSec=38.618027805911055, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 69: 0.080078125, mean for epoch: 0.08092377151268115, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 70: 0.080078125, mean for epoch: 0.08091169084821428, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 71: 0.07476806640625, mean for epoch: 0.08082516092649648, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 72: 0.06011962890625, mean for epoch: 0.08053758409288195, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 73: 0.0714111328125, mean for epoch: 0.08041256421232877, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 74: 0.0625, mean for epoch: 0.08017050253378379, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 75: 0.089599609375, mean for epoch: 0.08029622395833333, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 76: 0.05804443359375, mean for epoch: 0.08000343724300987, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 77: 0.1005859375, mean for epoch: 0.08027074244115259, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 78: 0.061126708984375, mean for epoch: 0.08002530611478366, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:20,413] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:20,414] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=37.43417683612387, CurrSamplesPerSec=36.330614076269704, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 79: 0.07513427734375, mean for epoch: 0.07996339435818829, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 80: 0.0574951171875, mean for epoch: 0.07968254089355468, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 81: 0.0687255859375, mean for epoch: 0.07954726984471451, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 82: 0.06829833984375, mean for epoch: 0.07941008777153201, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 83: 0.07403564453125, mean for epoch: 0.07934533544333584, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 84: 0.11102294921875, mean for epoch: 0.07972244989304315, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 85: 0.08575439453125, mean for epoch: 0.07979341394761029, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 86: 0.08099365234375, mean for epoch: 0.07980737020803053, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 87: 0.08026123046875, mean for epoch: 0.07981258699263649, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 88: 0.08270263671875, mean for epoch: 0.07984542846679688, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:21,779] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:21,779] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=37.436065447602076, CurrSamplesPerSec=38.125391997702096, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 89: 0.07037353515625, mean for epoch: 0.07973900269926264, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 90: 0.07110595703125, mean for epoch: 0.07964307996961806, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 91: 0.056427001953125, mean for epoch: 0.07938795823317307, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 92: 0.0845947265625, mean for epoch: 0.07944455354110054, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 93: 0.0677490234375, mean for epoch: 0.07931879515288978, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 94: 0.06689453125, mean for epoch: 0.07918662213264628, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 95: 0.0921630859375, mean for epoch: 0.07932321648848684, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 96: 0.07281494140625, mean for epoch: 0.0792554219563802, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 97: 0.062255859375, mean for epoch: 0.07908016873389176, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 98: 0.059295654296875, mean for epoch: 0.07887828593351404, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:23,161] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:23,161] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=37.42920323571428, CurrSamplesPerSec=38.704052649937346, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 99: 0.0672607421875, mean for epoch: 0.07876093700678662, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 100: 0.0740966796875, mean for epoch: 0.07871429443359375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 101: 0.07525634765625, mean for epoch: 0.07868005733678837, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 102: 0.061126708984375, mean for epoch: 0.07850796568627451, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 103: 0.1280517578125, mean for epoch: 0.07898897337682038, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 104: 0.06878662109375, mean for epoch: 0.07889087383563702, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 105: 0.058013916015625, mean for epoch: 0.07869204566592262, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 106: 0.059295654296875, mean for epoch: 0.07850906084168632, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 107: 0.0806884765625, mean for epoch: 0.07852942921290888, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 108: 0.0830078125, mean for epoch: 0.0785708957248264, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:24,529] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:24,530] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=37.432671833215956, CurrSamplesPerSec=38.102602489843676, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 109: 0.11236572265625, mean for epoch: 0.07888094000860092, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 110: 0.06927490234375, mean for epoch: 0.07879361239346591, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 111: 0.08197021484375, mean for epoch: 0.07882223043355856, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 112: 0.10760498046875, mean for epoch: 0.07907921927315849, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 113: 0.057464599609375, mean for epoch: 0.078887939453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 114: 0.0882568359375, mean for epoch: 0.07897012275561952, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 115: 0.08892822265625, mean for epoch: 0.07905671492866848, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 116: 0.07171630859375, mean for epoch: 0.07899343556371229, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 117: 0.1044921875, mean for epoch: 0.07921137361444978, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 118: 0.0765380859375, mean for epoch: 0.07918871863413665, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:25,905] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:25,905] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=37.43170877053413, CurrSamplesPerSec=38.26333189803023, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 119: 0.07000732421875, mean for epoch: 0.07911156405921743, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 120: 0.10302734375, mean for epoch: 0.07931086222330729, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 121: 0.07208251953125, mean for epoch: 0.07925112385395144, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 122: 0.0606689453125, mean for epoch: 0.0790988109150871, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 123: 0.071533203125, mean for epoch: 0.07903730190866362, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 124: 0.07550048828125, mean for epoch: 0.07900877921811995, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 125: 0.07781982421875, mean for epoch: 0.078999267578125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 126: 0.07366943359375, mean for epoch: 0.07895696730840773, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 127: 0.087890625, mean for epoch: 0.07902731106975885, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 128: 0.061492919921875, mean for epoch: 0.07889032363891602, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:27,291] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:27,291] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=37.42705269860906, CurrSamplesPerSec=34.38935040486959, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 129: 0.10357666015625, mean for epoch: 0.0790816905886628, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 130: 0.10784912109375, mean for epoch: 0.079302978515625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 131: 0.0694580078125, mean for epoch: 0.07922782606750954, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 132: 0.0838623046875, mean for epoch: 0.07926293575402463, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 133: 0.0755615234375, mean for epoch: 0.0792351055862312, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 134: 0.07373046875, mean for epoch: 0.07919402620685634, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 135: 0.098876953125, mean for epoch: 0.07933982566550926, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 136: 0.1170654296875, mean for epoch: 0.07961721981272978, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 137: 0.100830078125, mean for epoch: 0.07977205819457117, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 138: 0.07708740234375, mean for epoch: 0.07975260416666667, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:28,660] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:28,660] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=37.429376957460164, CurrSamplesPerSec=39.01816064195758, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 139: 0.0799560546875, mean for epoch: 0.07975406783947842, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 140: 0.090576171875, mean for epoch: 0.07983136858258928, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 141: 0.08245849609375, mean for epoch: 0.07985000069259751, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 142: 0.0645751953125, mean for epoch: 0.079742431640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 143: 0.0848388671875, mean for epoch: 0.07977807105004371, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 144: 0.08184814453125, mean for epoch: 0.07979244656032985, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 145: 0.0792236328125, mean for epoch: 0.07978852370689656, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 146: 0.07354736328125, mean for epoch: 0.0797457760327483, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 147: 0.07965087890625, mean for epoch: 0.07974513047406463, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 148: 0.07049560546875, mean for epoch: 0.07968263368348817, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:30,006] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:30,007] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=37.43919676063441, CurrSamplesPerSec=37.66321789744207, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 149: 0.1494140625, mean for epoch: 0.08015062985004194, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 150: 0.089111328125, mean for epoch: 0.08021036783854167, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 151: 0.07000732421875, mean for epoch: 0.08014279801324503, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 152: 0.08111572265625, mean for epoch: 0.08014919883326481, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 153: 0.07110595703125, mean for epoch: 0.08009009267769608, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 154: 0.07611083984375, mean for epoch: 0.08006425337357954, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 155: 0.056854248046875, mean for epoch: 0.07991451140372983, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 156: 0.072265625, mean for epoch: 0.079865480080629, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 157: 0.0838623046875, mean for epoch: 0.07989093756220143, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 158: 0.07293701171875, mean for epoch: 0.07984692537331883, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:31,367] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:31,368] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=37.44250890468607, CurrSamplesPerSec=37.73349166936558, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   4:   Loss at step 159: 0.07672119140625, mean for epoch: 0.07982726666912343, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 160: 0.07110595703125, mean for epoch: 0.07977275848388672, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 161: 0.1182861328125, mean for epoch: 0.08001197198903338, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 162: 0.0621337890625, mean for epoch: 0.07990161283516589, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 163: 0.07489013671875, mean for epoch: 0.07987086758291795, mem_alloc: 2342824960\n",
            " Run   5, iteration:   4:   Loss at step 164: 0.05401611328125, mean for epoch: 0.07971321664205412, mem_alloc: 2342824960\n",
            "Loss after iteration 4 ; MSE: 0.0797119140625, MAE: 0.212646484375\n",
            "Connected by ('127.0.0.1', 50286)\n",
            "\u001b[94mReceived training result: b'4;0.07971;0.21265' \u001b[0m\n",
            "Time per iteration 22.77215564250946, memory OrderedDict([('active.all.allocated', 1484398), ('active.all.current', 7), ('active.all.freed', 1484391), ('active.all.peak', 295), ('active.large_pool.allocated', 498512), ('active.large_pool.current', 5), ('active.large_pool.freed', 498507), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 985886), ('active.small_pool.current', 2), ('active.small_pool.freed', 985884), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 4838829366784), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 4838778473984), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 4717275741696), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 4717225809408), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 121553625088), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 121552664576), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 4838829366784), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 4838784565760), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 4717275741696), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 4717231901184), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 121553625088), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 121552664576), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1484398), ('allocation.all.current', 6), ('allocation.all.freed', 1484392), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 498512), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 498508), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 985886), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 985884), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 634546), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 634542), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 329934), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 329933), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 304612), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 304609), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 2930653007360), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 2930640985600), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 2788155622400), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 2788146834432), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 142497384960), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 142494151168), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            " Run   5, iteration:   5:   Loss at step 1: 0.1016845703125, mean for epoch: 0.1016845703125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 2: 0.0667724609375, mean for epoch: 0.084228515625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 3: 0.094970703125, mean for epoch: 0.08780924479166667, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 4: 0.061126708984375, mean for epoch: 0.08113861083984375, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:32,885] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:32,886] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=37.437631862307036, CurrSamplesPerSec=38.56320634325202, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 5: 0.082763671875, mean for epoch: 0.081463623046875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 6: 0.080810546875, mean for epoch: 0.08135477701822917, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 7: 0.06561279296875, mean for epoch: 0.07910592215401786, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 8: 0.055419921875, mean for epoch: 0.07614517211914062, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 9: 0.08270263671875, mean for epoch: 0.076873779296875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 10: 0.07537841796875, mean for epoch: 0.0767242431640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 11: 0.0618896484375, mean for epoch: 0.07537564364346591, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 12: 0.075439453125, mean for epoch: 0.07538096110026042, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 13: 0.091064453125, mean for epoch: 0.07658738356370193, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 14: 0.0869140625, mean for epoch: 0.07732500348772321, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:34,269] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:34,269] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=37.43298357209116, CurrSamplesPerSec=37.48120267157086, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 15: 0.08428955078125, mean for epoch: 0.077789306640625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 16: 0.08209228515625, mean for epoch: 0.07805824279785156, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 17: 0.04571533203125, mean for epoch: 0.0761557186351103, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 18: 0.101318359375, mean for epoch: 0.07755364312065972, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 19: 0.050567626953125, mean for epoch: 0.07613332648026316, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 20: 0.06640625, mean for epoch: 0.07564697265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 21: 0.0657958984375, mean for epoch: 0.07517787388392858, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 22: 0.077880859375, mean for epoch: 0.07530073686079546, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 23: 0.07440185546875, mean for epoch: 0.07526165506114131, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 24: 0.068115234375, mean for epoch: 0.07496388753255208, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:35,625] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:35,626] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=37.43859708038572, CurrSamplesPerSec=36.36545237632827, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 25: 0.106689453125, mean for epoch: 0.07623291015625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 26: 0.07965087890625, mean for epoch: 0.07636437049278846, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 27: 0.06378173828125, mean for epoch: 0.0758983470775463, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 28: 0.0787353515625, mean for epoch: 0.07599966866629464, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 29: 0.06890869140625, mean for epoch: 0.07575515220905173, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 30: 0.10125732421875, mean for epoch: 0.076605224609375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 31: 0.06689453125, mean for epoch: 0.07629197643649194, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 32: 0.060699462890625, mean for epoch: 0.0758047103881836, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 33: 0.0738525390625, mean for epoch: 0.0757455536813447, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 34: 0.08251953125, mean for epoch: 0.07594478831571691, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:37,020] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:37,021] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=37.42835616932368, CurrSamplesPerSec=33.97308917249043, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 35: 0.053558349609375, mean for epoch: 0.07530517578125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 36: 0.0823974609375, mean for epoch: 0.07550218370225695, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 37: 0.0909423828125, mean for epoch: 0.07591948638091216, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 38: 0.07452392578125, mean for epoch: 0.07588276110197369, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 39: 0.069091796875, mean for epoch: 0.07570863381410256, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 40: 0.0704345703125, mean for epoch: 0.0755767822265625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 41: 0.07049560546875, mean for epoch: 0.07545285108612805, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 42: 0.095703125, mean for epoch: 0.07593500046502977, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 43: 0.0718994140625, mean for epoch: 0.07584114961845931, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 44: 0.058929443359375, mean for epoch: 0.07545679265802557, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:38,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:38,386] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=37.43121345145693, CurrSamplesPerSec=37.776652946527484, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 45: 0.1026611328125, mean for epoch: 0.07606133355034722, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 46: 0.0792236328125, mean for epoch: 0.07613007918648097, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 47: 0.061981201171875, mean for epoch: 0.0758290392287234, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 48: 0.126220703125, mean for epoch: 0.07687886555989583, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 49: 0.066162109375, mean for epoch: 0.07666015625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 50: 0.0968017578125, mean for epoch: 0.07706298828125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 51: 0.046295166015625, mean for epoch: 0.07645969764859069, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 52: 0.08636474609375, mean for epoch: 0.07665017934945914, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 53: 0.057159423828125, mean for epoch: 0.07628242924528301, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 54: 0.07269287109375, mean for epoch: 0.07621595594618055, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:39,760] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:39,761] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=37.428635084169656, CurrSamplesPerSec=36.81687870972952, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 55: 0.06494140625, mean for epoch: 0.07601096413352272, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 56: 0.0772705078125, mean for epoch: 0.07603345598493304, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 57: 0.09002685546875, mean for epoch: 0.07627895422149122, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 58: 0.0794677734375, mean for epoch: 0.07633393386314655, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 59: 0.099853515625, mean for epoch: 0.07673257084216102, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 60: 0.0689697265625, mean for epoch: 0.07660319010416666, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 61: 0.0712890625, mean for epoch: 0.07651607325819672, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 62: 0.1055908203125, mean for epoch: 0.07698502079133064, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 63: 0.08099365234375, mean for epoch: 0.07704864986359126, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 64: 0.084228515625, mean for epoch: 0.07716083526611328, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:41,129] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:41,130] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=37.431534451890414, CurrSamplesPerSec=38.27108269933008, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 65: 0.062164306640625, mean for epoch: 0.07693011944110577, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 66: 0.062042236328125, mean for epoch: 0.07670454545454546, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 67: 0.08740234375, mean for epoch: 0.07686421408582089, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 68: 0.07183837890625, mean for epoch: 0.07679030474494486, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 69: 0.1219482421875, mean for epoch: 0.07744476760643115, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 70: 0.04144287109375, mean for epoch: 0.07693045479910714, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 71: 0.0791015625, mean for epoch: 0.07696103378080986, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 72: 0.07049560546875, mean for epoch: 0.07687123616536458, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 73: 0.08099365234375, mean for epoch: 0.07692770761986302, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 74: 0.06591796875, mean for epoch: 0.07677892736486487, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:42,498] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:42,499] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=37.43529827963864, CurrSamplesPerSec=38.97639097716413, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 75: 0.049285888671875, mean for epoch: 0.076412353515625, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 76: 0.07977294921875, mean for epoch: 0.07645657188013981, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 77: 0.068115234375, mean for epoch: 0.0763482428216315, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 78: 0.09716796875, mean for epoch: 0.07661516238481571, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 79: 0.07342529296875, mean for epoch: 0.07657478429094146, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 80: 0.088623046875, mean for epoch: 0.07672538757324218, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 81: 0.057220458984375, mean for epoch: 0.07648458598572531, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 82: 0.09356689453125, mean for epoch: 0.07669290682164634, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 83: 0.07940673828125, mean for epoch: 0.07672560358621988, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 84: 0.08428955078125, mean for epoch: 0.0768156505766369, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:43,860] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:43,861] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=37.43951183986104, CurrSamplesPerSec=36.019057629750236, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 85: 0.0849609375, mean for epoch: 0.07691147748161764, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 86: 0.1060791015625, mean for epoch: 0.0772506359011628, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 87: 0.06976318359375, mean for epoch: 0.07716457323096264, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 88: 0.07525634765625, mean for epoch: 0.07714288884943182, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 89: 0.0743408203125, mean for epoch: 0.07711140493328651, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 90: 0.0616455078125, mean for epoch: 0.07693956163194444, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 91: 0.058074951171875, mean for epoch: 0.07673225822029534, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 92: 0.07672119140625, mean for epoch: 0.07673213792883832, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 93: 0.0872802734375, mean for epoch: 0.0768455587407594, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 94: 0.133544921875, mean for epoch: 0.07744874345495346, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:45,235] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:45,235] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=37.43836315044592, CurrSamplesPerSec=37.584581581484706, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 95: 0.0745849609375, mean for epoch: 0.07741859837582236, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 96: 0.0731201171875, mean for epoch: 0.07737382253011067, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 97: 0.0594482421875, mean for epoch: 0.07718902273276418, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 98: 0.0845947265625, mean for epoch: 0.07726459113919006, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 99: 0.0601806640625, mean for epoch: 0.07709202621922348, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 100: 0.10302734375, mean for epoch: 0.07735137939453125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 101: 0.06451416015625, mean for epoch: 0.07722427821395421, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 102: 0.07733154296875, mean for epoch: 0.0772253298291973, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 103: 0.08526611328125, mean for epoch: 0.07730339568795509, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 104: 0.0726318359375, mean for epoch: 0.07725847684420072, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:46,592] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:46,593] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=37.442778872579815, CurrSamplesPerSec=35.1320581504823, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 105: 0.09539794921875, mean for epoch: 0.07743123372395834, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 106: 0.09661865234375, mean for epoch: 0.07761224710716391, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 107: 0.0604248046875, mean for epoch: 0.0774516168041764, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 108: 0.059844970703125, mean for epoch: 0.07728859230324074, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 109: 0.0673828125, mean for epoch: 0.07719771358944955, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 110: 0.0885009765625, mean for epoch: 0.07730047052556818, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 111: 0.08203125, mean for epoch: 0.07734309016047297, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 112: 0.08782958984375, mean for epoch: 0.0774367196219308, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 113: 0.09295654296875, mean for epoch: 0.07757406319137168, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 114: 0.109619140625, mean for epoch: 0.0778551603618421, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:47,963] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:47,963] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=37.444967823330465, CurrSamplesPerSec=38.08765519095116, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 115: 0.06536865234375, mean for epoch: 0.07774658203125, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 116: 0.08563232421875, mean for epoch: 0.07781456256734914, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 117: 0.054412841796875, mean for epoch: 0.07761454785990919, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 118: 0.0826416015625, mean for epoch: 0.07765715000993115, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 119: 0.07342529296875, mean for epoch: 0.07762158818605568, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 120: 0.07867431640625, mean for epoch: 0.07763036092122395, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 121: 0.080322265625, mean for epoch: 0.07765260806753616, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 122: 0.09912109375, mean for epoch: 0.0778285792616547, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 123: 0.05206298828125, mean for epoch: 0.07761910291222053, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 124: 0.08544921875, mean for epoch: 0.07768224900768649, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:49,317] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:49,317] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=37.45130536744659, CurrSamplesPerSec=37.11497552394335, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 125: 0.11260986328125, mean for epoch: 0.077961669921875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 126: 0.06964111328125, mean for epoch: 0.07789563375806051, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 127: 0.09246826171875, mean for epoch: 0.0780103788601132, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 128: 0.08721923828125, mean for epoch: 0.07808232307434082, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 129: 0.09295654296875, mean for epoch: 0.07819762710453004, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 130: 0.0667724609375, mean for epoch: 0.0781097412109375, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 131: 0.08935546875, mean for epoch: 0.0781955864593273, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 132: 0.060333251953125, mean for epoch: 0.07806026574337122, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 133: 0.0706787109375, mean for epoch: 0.078004765331297, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 134: 0.08740234375, mean for epoch: 0.07807489651352612, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:50,670] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:50,671] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=37.45912400575535, CurrSamplesPerSec=37.949465904957684, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 135: 0.05718994140625, mean for epoch: 0.07792019314236111, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 136: 0.06060791015625, mean for epoch: 0.07779289694393382, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 137: 0.0762939453125, mean for epoch: 0.07778195569114964, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 138: 0.0533447265625, mean for epoch: 0.07760487432065218, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 139: 0.0623779296875, mean for epoch: 0.07749532795638489, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 140: 0.06573486328125, mean for epoch: 0.07741132463727679, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 141: 0.06787109375, mean for epoch: 0.07734366342531028, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 142: 0.05621337890625, mean for epoch: 0.07719485860475352, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 143: 0.0555419921875, mean for epoch: 0.07704343995847902, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 144: 0.061798095703125, mean for epoch: 0.07693756951226129, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:52,039] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:52,039] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=37.45962690878336, CurrSamplesPerSec=36.14265057915391, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 145: 0.0762939453125, mean for epoch: 0.07693313072467672, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 146: 0.07623291015625, mean for epoch: 0.07692833469338613, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 147: 0.0985107421875, mean for epoch: 0.07707515379198554, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 148: 0.07281494140625, mean for epoch: 0.07704636857316301, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 149: 0.07135009765625, mean for epoch: 0.07700813856700923, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 150: 0.06463623046875, mean for epoch: 0.0769256591796875, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 151: 0.0794677734375, mean for epoch: 0.07694249437344784, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 152: 0.0794677734375, mean for epoch: 0.07695910805150082, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 153: 0.09197998046875, mean for epoch: 0.07705728368821486, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 154: 0.05194091796875, mean for epoch: 0.07689419040432224, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:53,402] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:53,402] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=37.461676722151175, CurrSamplesPerSec=35.861134956001905, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            " Run   5, iteration:   5:   Loss at step 155: 0.0665283203125, mean for epoch: 0.07682731382308468, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 156: 0.06396484375, mean for epoch: 0.07674486209184696, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 157: 0.06231689453125, mean for epoch: 0.07665296420929538, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 158: 0.12451171875, mean for epoch: 0.07695586771904668, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 159: 0.0643310546875, mean for epoch: 0.07687646637922563, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 160: 0.1072998046875, mean for epoch: 0.07706661224365234, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 161: 0.0869140625, mean for epoch: 0.07712777653095886, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 162: 0.0635986328125, mean for epoch: 0.07704426329812886, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 163: 0.057342529296875, mean for epoch: 0.07692339376437883, mem_alloc: 2342824960\n",
            " Run   5, iteration:   5:   Loss at step 164: 0.07611083984375, mean for epoch: 0.07691843916730183, mem_alloc: 2342824960\n",
            "[2022-10-25 13:51:54,782] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-25 13:51:54,782] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=37.46066866945281, CurrSamplesPerSec=34.37170874177851, MemAllocated=0.04GB, MaxMemAllocated=2.18GB\n",
            "Loss after iteration 5 ; MSE: 0.076904296875, MAE: 0.208984375\n",
            "Connected by ('127.0.0.1', 39980)\n",
            "\u001b[94mReceived training result: b'5;0.07690;0.20898' \u001b[0m\n",
            "Time per iteration 22.73578906059265, memory OrderedDict([('active.all.allocated', 1858646), ('active.all.current', 7), ('active.all.freed', 1858639), ('active.all.peak', 295), ('active.large_pool.allocated', 623152), ('active.large_pool.current', 5), ('active.large_pool.freed', 623147), ('active.large_pool.peak', 169), ('active.small_pool.allocated', 1235494), ('active.small_pool.current', 2), ('active.small_pool.freed', 1235492), ('active.small_pool.peak', 129), ('active_bytes.all.allocated', 6048794140160), ('active_bytes.all.current', 50892800), ('active_bytes.all.freed', 6048743247360), ('active_bytes.all.peak', 2342824960), ('active_bytes.large_pool.allocated', 5896688674304), ('active_bytes.large_pool.current', 49932288), ('active_bytes.large_pool.freed', 5896638742016), ('active_bytes.large_pool.peak', 2313672704), ('active_bytes.small_pool.allocated', 152105465856), ('active_bytes.small_pool.current', 960512), ('active_bytes.small_pool.freed', 152104505344), ('active_bytes.small_pool.peak', 33837056), ('allocated_bytes.all.allocated', 6048794140160), ('allocated_bytes.all.current', 44801024), ('allocated_bytes.all.freed', 6048749339136), ('allocated_bytes.all.peak', 2342824960), ('allocated_bytes.large_pool.allocated', 5896688674304), ('allocated_bytes.large_pool.current', 43840512), ('allocated_bytes.large_pool.freed', 5896644833792), ('allocated_bytes.large_pool.peak', 2313672704), ('allocated_bytes.small_pool.allocated', 152105465856), ('allocated_bytes.small_pool.current', 960512), ('allocated_bytes.small_pool.freed', 152104505344), ('allocated_bytes.small_pool.peak', 33837056), ('allocation.all.allocated', 1858646), ('allocation.all.current', 6), ('allocation.all.freed', 1858640), ('allocation.all.peak', 295), ('allocation.large_pool.allocated', 623152), ('allocation.large_pool.current', 4), ('allocation.large_pool.freed', 623148), ('allocation.large_pool.peak', 169), ('allocation.small_pool.allocated', 1235494), ('allocation.small_pool.current', 2), ('allocation.small_pool.freed', 1235492), ('allocation.small_pool.peak', 129), ('inactive_split.all.allocated', 794111), ('inactive_split.all.current', 4), ('inactive_split.all.freed', 794107), ('inactive_split.all.peak', 53), ('inactive_split.large_pool.allocated', 412426), ('inactive_split.large_pool.current', 1), ('inactive_split.large_pool.freed', 412425), ('inactive_split.large_pool.peak', 43), ('inactive_split.small_pool.allocated', 381685), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 381682), ('inactive_split.small_pool.peak', 25), ('inactive_split_bytes.all.allocated', 3663565530112), ('inactive_split_bytes.all.current', 12021760), ('inactive_split_bytes.all.freed', 3663553508352), ('inactive_split_bytes.all.peak', 132499968), ('inactive_split_bytes.large_pool.allocated', 3485285583872), ('inactive_split_bytes.large_pool.current', 8787968), ('inactive_split_bytes.large_pool.freed', 3485276795904), ('inactive_split_bytes.large_pool.peak', 129016832), ('inactive_split_bytes.small_pool.allocated', 178279946240), ('inactive_split_bytes.small_pool.current', 3233792), ('inactive_split_bytes.small_pool.freed', 178276712448), ('inactive_split_bytes.small_pool.peak', 6056960), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 2432696320), ('reserved_bytes.all.current', 2432696320), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 2432696320), ('reserved_bytes.large_pool.allocated', 2394947584), ('reserved_bytes.large_pool.current', 2394947584), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 2394947584), ('reserved_bytes.small_pool.allocated', 37748736), ('reserved_bytes.small_pool.current', 37748736), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 37748736), ('segment.all.allocated', 83), ('segment.all.current', 83), ('segment.all.freed', 0), ('segment.all.peak', 83), ('segment.large_pool.allocated', 65), ('segment.large_pool.current', 65), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 65), ('segment.small_pool.allocated', 18), ('segment.small_pool.current', 18), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 18)])\n",
            "2342824960\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.0182342529296875, mean for epoch: 0.0182342529296875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 2: 0.0308380126953125, mean for epoch: 0.0245361328125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 3: 0.021331787109375, mean for epoch: 0.023468017578125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 4: 0.033416748046875, mean for epoch: 0.0259552001953125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 5: 0.03277587890625, mean for epoch: 0.0273193359375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 6: 0.044403076171875, mean for epoch: 0.0301666259765625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 7: 0.032012939453125, mean for epoch: 0.030430385044642856, mem_alloc: 2342824960\n",
            "Validation set Loss at step 8: 0.06048583984375, mean for epoch: 0.03418731689453125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 9: 0.037750244140625, mean for epoch: 0.034583197699652776, mem_alloc: 2342824960\n",
            "Validation set Loss at step 10: 0.03399658203125, mean for epoch: 0.0345245361328125, mem_alloc: 2342824960\n",
            "Validation set Loss at step 11: 0.01190185546875, mean for epoch: 0.03246792879971591, mem_alloc: 2342824960\n",
            "Validation set Loss at step 12: 0.04193115234375, mean for epoch: 0.03325653076171875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 13: 0.02490234375, mean for epoch: 0.032613900991586536, mem_alloc: 2342824960\n",
            "Validation set Loss at step 14: 0.0184326171875, mean for epoch: 0.0316009521484375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 15: 0.0184326171875, mean for epoch: 0.030723063151041667, mem_alloc: 2342824960\n",
            "Validation set Loss at step 16: 0.0127410888671875, mean for epoch: 0.02959918975830078, mem_alloc: 2342824960\n",
            "Validation set Loss at step 17: 0.0205535888671875, mean for epoch: 0.029067095588235295, mem_alloc: 2342824960\n",
            "Validation set Loss at step 18: 0.031951904296875, mean for epoch: 0.029227362738715276, mem_alloc: 2342824960\n",
            "Validation set Loss at step 19: 0.16015625, mean for epoch: 0.036118356805098686, mem_alloc: 2342824960\n",
            "Validation set Loss at step 20: 0.06646728515625, mean for epoch: 0.03763580322265625, mem_alloc: 2342824960\n",
            "Validation set Loss at step 21: 0.05316162109375, mean for epoch: 0.03837512788318452, mem_alloc: 2342824960\n",
            "Validation set Loss at step 22: 0.0301513671875, mean for epoch: 0.03800132057883523, mem_alloc: 2342824960\n",
            "Validation set Loss at step 23: 0.03302001953125, mean for epoch: 0.03778474227241848, mem_alloc: 2342824960\n",
            "Validation set Loss at step 24: 0.012481689453125, mean for epoch: 0.036730448404947914, mem_alloc: 2342824960\n",
            "Validation set Loss at step 25: 0.0192108154296875, mean for epoch: 0.0360296630859375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 26: 0.0787353515625, mean for epoch: 0.037672189565805286, mem_alloc: 2342824960\n",
            "Validation set Loss at step 27: 0.038970947265625, mean for epoch: 0.03772029170283565, mem_alloc: 2342824960\n",
            "Validation set Loss at step 28: 0.10211181640625, mean for epoch: 0.040019989013671875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 29: 0.045501708984375, mean for epoch: 0.040209013840247845, mem_alloc: 2342824960\n",
            "Validation set Loss at step 30: 0.0286865234375, mean for epoch: 0.03982493082682292, mem_alloc: 2342824960\n",
            "Validation set Loss at step 31: 0.042388916015625, mean for epoch: 0.039907640026461695, mem_alloc: 2342824960\n",
            "Validation set Loss at step 32: 0.07012939453125, mean for epoch: 0.04085206985473633, mem_alloc: 2342824960\n",
            "Validation set Loss at step 33: 0.0280609130859375, mean for epoch: 0.04046445904356061, mem_alloc: 2342824960\n",
            "Validation set Loss at step 34: 0.09539794921875, mean for epoch: 0.04208014993106618, mem_alloc: 2342824960\n",
            "Validation set Loss at step 35: 0.034637451171875, mean for epoch: 0.04186750139508929, mem_alloc: 2342824960\n",
            "Validation set Loss at step 36: 0.0325927734375, mean for epoch: 0.041609870062934026, mem_alloc: 2342824960\n",
            "Validation set Loss at step 37: 0.1397705078125, mean for epoch: 0.04426286027238176, mem_alloc: 2342824960\n",
            "Validation set Loss at step 38: 0.124755859375, mean for epoch: 0.04638109709087171, mem_alloc: 2342824960\n",
            "Validation set Loss at step 39: 0.10003662109375, mean for epoch: 0.047756879757612176, mem_alloc: 2342824960\n",
            "Validation set Loss at step 40: 0.071533203125, mean for epoch: 0.048351287841796875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 41: 0.06793212890625, mean for epoch: 0.04882886933117378, mem_alloc: 2342824960\n",
            "Validation set Loss at step 42: 0.042083740234375, mean for epoch: 0.04866827101934524, mem_alloc: 2342824960\n",
            "Validation set Loss at step 43: 0.033050537109375, mean for epoch: 0.048305067905159885, mem_alloc: 2342824960\n",
            "Validation set Loss at step 44: 0.0272979736328125, mean for epoch: 0.04782763394442471, mem_alloc: 2342824960\n",
            "Validation set Loss at step 45: 0.0294342041015625, mean for epoch: 0.04741889105902778, mem_alloc: 2342824960\n",
            "Validation set Loss at step 46: 0.0726318359375, mean for epoch: 0.04796699855638587, mem_alloc: 2342824960\n",
            "Validation set Loss at step 47: 0.0232086181640625, mean for epoch: 0.04744022450548537, mem_alloc: 2342824960\n",
            "Validation set Loss at step 48: 0.08111572265625, mean for epoch: 0.048141797383626304, mem_alloc: 2342824960\n",
            "Validation set Loss at step 49: 0.0367431640625, mean for epoch: 0.047909172213807395, mem_alloc: 2342824960\n",
            "Validation set Loss at step 50: 0.0247344970703125, mean for epoch: 0.0474456787109375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 51: 0.07708740234375, mean for epoch: 0.04802688897824755, mem_alloc: 2342824960\n",
            "Validation set Loss at step 52: 0.0489501953125, mean for epoch: 0.048044644869290866, mem_alloc: 2342824960\n",
            "Validation set Loss at step 53: 0.07342529296875, mean for epoch: 0.048523525022110846, mem_alloc: 2342824960\n",
            "Validation set Loss at step 54: 0.4306640625, mean for epoch: 0.05560020164207176, mem_alloc: 2342824960\n",
            "Validation set Loss at step 55: 0.160888671875, mean for epoch: 0.05751453746448864, mem_alloc: 2342824960\n",
            "Validation set Loss at step 56: 0.1790771484375, mean for epoch: 0.05968529837472098, mem_alloc: 2342824960\n",
            "Validation set Loss at step 57: 0.19287109375, mean for epoch: 0.062021891276041664, mem_alloc: 2342824960\n",
            "Validation set Loss at step 58: 0.11846923828125, mean for epoch: 0.06299512139682112, mem_alloc: 2342824960\n",
            "Validation set Loss at step 59: 0.08551025390625, mean for epoch: 0.06337673381223517, mem_alloc: 2342824960\n",
            "Validation set Loss at step 60: 0.07745361328125, mean for epoch: 0.06361134847005208, mem_alloc: 2342824960\n",
            "Validation set Loss at step 61: 0.10693359375, mean for epoch: 0.06432154921234631, mem_alloc: 2342824960\n",
            "Validation set Loss at step 62: 0.0374755859375, mean for epoch: 0.0638885498046875, mem_alloc: 2342824960\n",
            "Validation set Loss at step 63: 0.03192138671875, mean for epoch: 0.06338113451760913, mem_alloc: 2342824960\n",
            "Validation set Loss at step 64: 0.05694580078125, mean for epoch: 0.06328058242797852, mem_alloc: 2342824960\n",
            "Validation set Loss at step 65: 0.045379638671875, mean for epoch: 0.06300518329326923, mem_alloc: 2342824960\n",
            "Validation set Loss at step 66: 0.017974853515625, mean for epoch: 0.06232290556936553, mem_alloc: 2342824960\n",
            "Validation set Loss at step 67: 0.048675537109375, mean for epoch: 0.06211921350279851, mem_alloc: 2342824960\n",
            "Validation set Loss at step 68: 0.048065185546875, mean for epoch: 0.06191253662109375, mem_alloc: 2342824960\n",
            "Validation set Loss at step 69: 0.1832275390625, mean for epoch: 0.06367072506227354, mem_alloc: 2342824960\n",
            "Validation set Loss at step 70: 0.381591796875, mean for epoch: 0.06821245465959822, mem_alloc: 2342824960\n",
            "Validation set Loss at step 71: 0.261962890625, mean for epoch: 0.07094133403939261, mem_alloc: 2342824960\n",
            "Validation set Loss at step 72: 0.33203125, mean for epoch: 0.07456758287217882, mem_alloc: 2342824960\n",
            "Validation set Loss at step 73: 0.1712646484375, mean for epoch: 0.07589220020869007, mem_alloc: 2342824960\n",
            "Validation set Loss at step 74: 0.10986328125, mean for epoch: 0.07635126887141047, mem_alloc: 2342824960\n",
            "Validation set Loss at step 75: 0.10394287109375, mean for epoch: 0.07671915690104167, mem_alloc: 2342824960\n",
            "Validation set Loss at step 76: 0.065673828125, mean for epoch: 0.07657382362767269, mem_alloc: 2342824960\n",
            "Validation set Loss at step 77: 0.1383056640625, mean for epoch: 0.07737553584111201, mem_alloc: 2342824960\n",
            "Validation set Loss at step 78: 0.058135986328125, mean for epoch: 0.07712887494991987, mem_alloc: 2342824960\n",
            "Validation set Loss at step 79: 0.09527587890625, mean for epoch: 0.0773585838607595, mem_alloc: 2342824960\n",
            "Validation set Loss at step 80: 0.05682373046875, mean for epoch: 0.07710189819335937, mem_alloc: 2342824960\n",
            "Validation set Loss at step 81: 0.07391357421875, mean for epoch: 0.07706253616898148, mem_alloc: 2342824960\n",
            "Validation set Loss at step 82: 0.06884765625, mean for epoch: 0.07696235470655488, mem_alloc: 2342824960\n",
            "Validation set Loss at step 83: 0.07611083984375, mean for epoch: 0.07695209549134036, mem_alloc: 2342824960\n",
            "Validation set Loss at step 84: 0.0634765625, mean for epoch: 0.07679167247953869, mem_alloc: 2342824960\n",
            "Validation set Loss at step 85: 0.01654052734375, mean for epoch: 0.07608283547794117, mem_alloc: 2342824960\n",
            "Validation set Loss at step 86: 0.10662841796875, mean for epoch: 0.07643801666969477, mem_alloc: 2342824960\n",
            "Validation set Loss at step 87: 0.04541015625, mean for epoch: 0.07608137459590517, mem_alloc: 2342824960\n",
            "Validation set Loss at step 88: 0.08831787109375, mean for epoch: 0.07622042569247159, mem_alloc: 2342824960\n",
            "Validation set Loss at step 89: 0.10400390625, mean for epoch: 0.07653259963132023, mem_alloc: 2342824960\n",
            "Loss for validation set  ; MSE: 0.0765380859375, MAE: 0.22705078125\n",
            "Connected by ('127.0.0.1', 47798)\n",
            "\u001b[94mReceived result: b'0.07654;0.22705' \u001b[0m\n",
            "Iteration  1| MSE 0.0688 | MAE 0.2087\n",
            "Iteration  2| MSE 0.0545 | MAE 0.1807\n",
            "Iteration  3| MSE 0.0377 | MAE 0.1499\n",
            "Iteration  4| MSE 0.0858 | MAE 0.2388\n",
            "Iteration  5| MSE 0.0765 | MAE 0.2271\n",
            "Mean        | MSE 0.0647 | MAE 0.2010\n",
            "Iteration  1| MSE 0.0688 | MAE 0.2087\n",
            "Iteration  2| MSE 0.0545 | MAE 0.1807\n",
            "Iteration  3| MSE 0.0377 | MAE 0.1499\n",
            "Iteration  4| MSE 0.0858 | MAE 0.2388\n",
            "Iteration  5| MSE 0.0765 | MAE 0.2271\n",
            "Mean        | MSE 0.0647 | MAE 0.2010\n",
            "[[[0.25854, 0.35571], [0.25098, 0.3501], [0.23181, 0.34131], [0.24329, 0.3501], [0.25708, 0.35596]], [[0.09497, 0.23389], [0.09351, 0.23254], [0.09418, 0.23303], [0.09521, 0.23462], [0.09253, 0.23083]], [[0.08441, 0.21851], [0.08624, 0.22192], [0.08435, 0.21912], [0.08606, 0.22156], [0.08441, 0.21936]], [[0.08215, 0.21558], [0.07965, 0.21326], [0.07941, 0.21216], [0.0802, 0.21228], [0.07971, 0.21265]], [[0.07782, 0.20947], [0.07611, 0.20862], [0.0766, 0.20837], [0.07953, 0.21216], [0.0769, 0.20898]]]\n",
            "[2022-10-25 13:52:00,260] [INFO] [launch.py:318:main] Process 845 exits successfully.\n"
          ]
        }
      ]
    }
  ]
}