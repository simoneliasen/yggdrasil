{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SafbhDsQWVWM",
        "outputId": "3fc036ad-4749-4548-88d7-ab30766c2e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'query-selector'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 164 (delta 100), reused 28 (delta 12), pack-reused 18\u001b[K\n",
            "Receiving objects: 100% (164/164), 12.42 MiB | 15.70 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.7.4.tar.gz (665 kB)\n",
            "\u001b[K     |████████████████████████████████| 665 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.10.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from pydantic->deepspeed) (4.1.1)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.7.4-py3-none-any.whl size=676699 sha256=2088cfce10714523a473592ee7c0e5f93d3d6df42da11005eb9459ef29d396e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/6b/f8/bf450c749abd7dccc77d0df7f2d5c4466d3288c84bdf7b8ce1\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: py-cpuinfo, ninja, hjson, deepspeed\n",
            "Successfully installed deepspeed-0.7.4 hjson-3.1.0 ninja-1.10.2.4 py-cpuinfo-9.0.0\n"
          ]
        }
      ],
      "source": [
        "#In this version: \n",
        "#replaced \"from deepspeed import deepspeed\" with \"import deepspeed\" in both train.py and config.py\n",
        "#Put 24 hour multivariate hourly prediction as default in run-ds.py\n",
        "!git clone https://github.com/simoneliasen/query-selector.git\n",
        "!pip3 install deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd query-selector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNMb9JBtWAKu",
        "outputId": "9c8c839b-17ba-4b7e-87b5-882823f6ba61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/query-selector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Work on subset of data for testing purposes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "etth1 = pd.read_csv(\"data/ETTh1.csv\")\n",
        "hub = pd.read_csv(\"data/dataset_dropNA.csv\")\n",
        "\n",
        "etth1['date'] = hub['date']\n",
        "etth1['HUFL'] = hub['TH_NP15_GEN-APND']\n",
        "etth1['HULL'] = hub['TH_SP15_GEN-APND']\n",
        "etth1['MUFL'] = hub['TH_ZP26_GEN-APND']\n",
        "etth1['MULL'] = hub['CAISO-SP15 Wind Power Generation Forecast']\n",
        "etth1['LUFL'] = hub['CAISO-NEVP Power Demand Forecast']\n",
        "etth1['LULL'] = hub['CAISO-AZPS Power Demand Forecast']\n",
        "etth1['OT'] = hub['CAISO-SDGE Power Demand Forecast']\n",
        "\n",
        "etth1.to_csv('data/ETTh1.csv', index=False)"
      ],
      "metadata": {
        "id": "fbibiKJIgD66"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration of model can be configured, by configuring the \"conf\" variable to the correct .json\n",
        "!python3 run-ds.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITvIWJvvWg8j",
        "outputId": "65aafc0a-6706-4e01-bc80-c569c84f161e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"data\": \"ETTh1\",\n",
            "  \"seq_len\": 48,\n",
            "  \"pred_len\": 24,\n",
            "  \"dec_seq_len\": 48,\n",
            "  \"hidden_size\": 96,\n",
            "  \"heads\": 2,\n",
            "  \"n_encoder_layers\": 3,\n",
            "  \"encoder_attention\": \"query_selector_0.85\",\n",
            "  \"n_decoder_layers\": 3,\n",
            "  \"decoder_attention\": \"full\",\n",
            "  \"batch_size\": 32,\n",
            "  \"embedding_size\": 24,\n",
            "  \"prediction_type\": \"multi\",\n",
            "  \"dropout\": 0,\n",
            "  \"fp16\": true,\n",
            "  \"deepspeed\": true,\n",
            "  \"iterations\": 5,\n",
            "  \"exps\": 2,\n",
            "  \"debug\": false\n",
            "}\n",
            "[2022-10-31 19:00:29,805] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-31 19:00:29,837] [INFO] [runner.py:507:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --deepspeed_config settings/ds_config_zero.json --data ETTh1 --seq_len 48 --pred_len 24 --dec_seq_len 48 --hidden_size 96 --n_encoder_layers 3 --n_decoder_layers 3 --encoder_attention query_selector_0.85 --decoder_attention full --n_heads 2 --batch_size 32 --embedding_size 24 --iterations 5 --exps 2 --dropout 0 --fp16 --deepspeed --features M --input_len 7 --output_len 7 --run_num 1\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-31 19:00:31,686] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Number of parameters: 123\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 7])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 7])\n",
            "torch.Size([24])\n",
            "torch.Size([168, 1152])\n",
            "torch.Size([168])\n",
            "[2022-10-31 19:00:33,841] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.4, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-31 19:00:33,843] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-31 19:00:33,852] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2022-10-31 19:00:35,743] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.22330641746520996 seconds\n",
            "[2022-10-31 19:00:36,771] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2022-10-31 19:00:36,775] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2022-10-31 19:00:36,775] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2022-10-31 19:00:36,775] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "[2022-10-31 19:00:36,775] [INFO] [stage_1_and_2.py:140:__init__] Reduce bucket size 500000000\n",
            "[2022-10-31 19:00:36,775] [INFO] [stage_1_and_2.py:141:__init__] Allgather bucket size 500000000\n",
            "[2022-10-31 19:00:36,775] [INFO] [stage_1_and_2.py:142:__init__] CPU Offload: False\n",
            "[2022-10-31 19:00:36,775] [INFO] [stage_1_and_2.py:143:__init__] Round robin gradient partitioning: False\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.2284848690032959 seconds\n",
            "Rank: 0 partition count [1] and sizes[(305688, False)] \n",
            "[2022-10-31 19:00:37,121] [INFO] [utils.py:827:see_memory_usage] Before initializing optimizer states\n",
            "[2022-10-31 19:00:37,122] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:00:37,122] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.19 GB, percent = 12.5%\n",
            "[2022-10-31 19:00:37,179] [INFO] [utils.py:827:see_memory_usage] After initializing optimizer states\n",
            "[2022-10-31 19:00:37,180] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:00:37,180] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.19 GB, percent = 12.5%\n",
            "[2022-10-31 19:00:37,180] [INFO] [stage_1_and_2.py:523:__init__] optimizer state initialized\n",
            "[2022-10-31 19:00:37,232] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-31 19:00:37,233] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:00:37,233] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.19 GB, percent = 12.5%\n",
            "[2022-10-31 19:00:37,237] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2022-10-31 19:00:37,237] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2022-10-31 19:00:37,237] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2022-10-31 19:00:37,237] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:37,237] [INFO] [config.py:1002:print] DeepSpeedEngine configuration:\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   amp_enabled .................. False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   amp_params ................... False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   bfloat16_enabled ............. False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fabf68fa990>\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   communication_data_type ...... None\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   curriculum_enabled ........... False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   curriculum_params ............ False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   dataloader_drop_last ......... False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   disable_allgather ............ False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   dump_state ................... False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-31 19:00:37,238] [INFO] [config.py:1006:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   elasticity_enabled ........... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   fp16_auto_cast ............... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   fp16_enabled ................. True\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   global_rank .................. 0\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   gradient_accumulation_steps .. 1\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   gradient_clipping ............ 0.0\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   load_universal_checkpoint .... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   loss_scale ................... 0\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   memory_breakdown ............. False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fabf68fa910>\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   optimizer_name ............... adam\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   pld_enabled .................. False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   pld_params ................... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   prescale_gradients ........... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   scheduler_name ............... None\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   scheduler_params ............. None\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   sparse_attention ............. None\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-31 19:00:37,239] [INFO] [config.py:1006:print]   steps_per_print .............. 10\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   train_batch_size ............. 5\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   train_micro_batch_size_per_gpu  5\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   world_size ................... 1\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=False allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=False prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   zero_enabled ................. True\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:1006:print]   zero_optimization_stage ...... 2\n",
            "[2022-10-31 19:00:37,240] [INFO] [config.py:997:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 5, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 5e-05, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": false, \n",
            "        \"cpu_offload\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 1000\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0003616809844970703 seconds\n",
            "train 8569\n",
            " Run   1, iteration:   1:   Loss at step 1: 1.0361328125, mean for epoch: 1.0361328125, mem_alloc: 23053824\n",
            "[2022-10-31 19:00:38,199] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 4294967296\n",
            " Run   1, iteration:   1:   Loss at step 2: 0.94775390625, mean for epoch: 0.991943359375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,260] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
            " Run   1, iteration:   1:   Loss at step 3: 1.21484375, mean for epoch: 1.0662434895833333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,305] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
            " Run   1, iteration:   1:   Loss at step 4: 0.99365234375, mean for epoch: 1.048095703125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,352] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
            " Run   1, iteration:   1:   Loss at step 5: 1.0947265625, mean for epoch: 1.057421875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,399] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
            " Run   1, iteration:   1:   Loss at step 6: 2.330078125, mean for epoch: 1.26953125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,451] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
            " Run   1, iteration:   1:   Loss at step 7: 0.998046875, mean for epoch: 1.2307477678571428, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,499] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
            " Run   1, iteration:   1:   Loss at step 8: 1.0732421875, mean for epoch: 1.2110595703125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,546] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
            " Run   1, iteration:   1:   Loss at step 9: 1.1162109375, mean for epoch: 1.2005208333333333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,593] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
            " Run   1, iteration:   1:   Loss at step 10: 1.1025390625, mean for epoch: 1.19072265625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,642] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
            "[2022-10-31 19:00:38,642] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=10, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:38,642] [INFO] [timer.py:207:stop] 0/10, RunningAvgSamplesPerSec=109.42885357189913, CurrSamplesPerSec=107.63125750592776, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 11: 1.091796875, mean for epoch: 1.1817294034090908, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,691] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
            " Run   1, iteration:   1:   Loss at step 12: 1.056640625, mean for epoch: 1.1713053385416667, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,738] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
            " Run   1, iteration:   1:   Loss at step 13: 1.0244140625, mean for epoch: 1.1600060096153846, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,784] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
            " Run   1, iteration:   1:   Loss at step 14: 1.001953125, mean for epoch: 1.1487165178571428, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,830] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
            " Run   1, iteration:   1:   Loss at step 15: 1.263671875, mean for epoch: 1.1563802083333334, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,878] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            " Run   1, iteration:   1:   Loss at step 16: 1.068359375, mean for epoch: 1.15087890625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,926] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            " Run   1, iteration:   1:   Loss at step 17: 1.1142578125, mean for epoch: 1.1487247242647058, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:38,973] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            " Run   1, iteration:   1:   Loss at step 18: 2.302734375, mean for epoch: 1.2128363715277777, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:39,020] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            " Run   1, iteration:   1:   Loss at step 19: 2.458984375, mean for epoch: 1.2784231085526316, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 20: 1.1708984375, mean for epoch: 1.273046875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:39,143] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:39,143] [INFO] [timer.py:207:stop] 0/20, RunningAvgSamplesPerSec=106.54428481553391, CurrSamplesPerSec=85.6494304746113, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 21: 0.935546875, mean for epoch: 1.2569754464285714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 22: 0.98974609375, mean for epoch: 1.2448286576704546, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 23: 1.5966796875, mean for epoch: 1.2601265285326086, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 24: 0.9765625, mean for epoch: 1.2483113606770833, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 25: 1.1982421875, mean for epoch: 1.24630859375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 26: 2.228515625, mean for epoch: 1.2840857872596154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 27: 0.93701171875, mean for epoch: 1.2712311921296295, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 28: 0.939453125, mean for epoch: 1.2593819754464286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 29: 0.94384765625, mean for epoch: 1.2485014816810345, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 30: 1.0146484375, mean for epoch: 1.2407063802083333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:39,744] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:39,744] [INFO] [timer.py:207:stop] 0/30, RunningAvgSamplesPerSec=98.35262747094825, CurrSamplesPerSec=85.0692227500071, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 31: 0.94921875, mean for epoch: 1.2313035534274193, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 32: 0.93310546875, mean for epoch: 1.22198486328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 33: 2.388671875, mean for epoch: 1.2573390151515151, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 34: 0.8232421875, mean for epoch: 1.2445714613970589, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 35: 0.91943359375, mean for epoch: 1.2352818080357142, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 36: 1.2109375, mean for epoch: 1.2346055772569444, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 37: 2.087890625, mean for epoch: 1.257667335304054, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 38: 0.93505859375, mean for epoch: 1.2491776315789473, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 39: 0.75390625, mean for epoch: 1.2364783653846154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 40: 1.1630859375, mean for epoch: 1.2346435546875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:40,370] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:40,370] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=93.9056995211847, CurrSamplesPerSec=86.16178506719474, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 41: 1.1533203125, mean for epoch: 1.2326600609756098, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 42: 1.671875, mean for epoch: 1.2431175595238095, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 43: 1.0576171875, mean for epoch: 1.238803597383721, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 44: 1.4404296875, mean for epoch: 1.2433860085227273, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 45: 3.30859375, mean for epoch: 1.2892795138888888, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 46: 0.7783203125, mean for epoch: 1.2781717051630435, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 47: 2.294921875, mean for epoch: 1.2998046875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 48: 0.703125, mean for epoch: 1.2873738606770833, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 49: 0.875, mean for epoch: 1.278958067602041, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 50: 0.80615234375, mean for epoch: 1.269501953125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:40,977] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:40,977] [INFO] [timer.py:207:stop] 0/50, RunningAvgSamplesPerSec=92.03807651290063, CurrSamplesPerSec=88.67450317124735, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 51: 0.8212890625, mean for epoch: 1.2607134650735294, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 52: 1.1826171875, mean for epoch: 1.2592116135817308, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 53: 0.72314453125, mean for epoch: 1.2490971403301887, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 54: 0.71533203125, mean for epoch: 1.2392126012731481, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 55: 0.64697265625, mean for epoch: 1.2284446022727273, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 56: 2.00390625, mean for epoch: 1.2422921316964286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 57: 1.0947265625, mean for epoch: 1.2397032620614035, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 58: 1.0078125, mean for epoch: 1.235705145474138, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 59: 0.70458984375, mean for epoch: 1.2267031912076272, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 60: 1.505859375, mean for epoch: 1.2313557942708333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:41,584] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:41,584] [INFO] [timer.py:207:stop] 0/60, RunningAvgSamplesPerSec=90.86888370095063, CurrSamplesPerSec=83.89581191418205, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 61: 0.74072265625, mean for epoch: 1.2233126280737705, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 62: 0.9091796875, mean for epoch: 1.2182459677419355, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 63: 0.73876953125, mean for epoch: 1.2106352306547619, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 64: 1.439453125, mean for epoch: 1.2142105102539062, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 65: 0.982421875, mean for epoch: 1.21064453125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 66: 0.66162109375, mean for epoch: 1.2023259943181819, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 67: 0.67431640625, mean for epoch: 1.1944452541977613, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 68: 0.9853515625, mean for epoch: 1.1913703469669117, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 69: 1.962890625, mean for epoch: 1.202551800271739, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 70: 0.93115234375, mean for epoch: 1.1986746651785714, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:42,192] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:42,193] [INFO] [timer.py:207:stop] 0/70, RunningAvgSamplesPerSec=90.05895947369002, CurrSamplesPerSec=83.32579733869461, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 71: 0.75439453125, mean for epoch: 1.1924171985035212, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 72: 0.8037109375, mean for epoch: 1.1870185004340277, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 73: 0.6533203125, mean for epoch: 1.1797075663527397, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 74: 0.67236328125, mean for epoch: 1.1728515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 75: 0.7197265625, mean for epoch: 1.1668098958333333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 76: 0.7177734375, mean for epoch: 1.160901521381579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 77: 0.62548828125, mean for epoch: 1.1539481026785714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 78: 0.6943359375, mean for epoch: 1.148055639022436, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 79: 1.9912109375, mean for epoch: 1.1587284909018987, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 80: 0.634765625, mean for epoch: 1.152178955078125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:42,792] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:42,792] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=89.63438358210607, CurrSamplesPerSec=86.33310554352569, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 81: 0.6923828125, mean for epoch: 1.1465024594907407, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 82: 0.751953125, mean for epoch: 1.1416908822408536, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 83: 1.2880859375, mean for epoch: 1.1434546780873494, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 84: 0.7353515625, mean for epoch: 1.1385963076636905, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 85: 1.5380859375, mean for epoch: 1.1432961856617647, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 86: 1.0146484375, mean for epoch: 1.141800281613372, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 87: 1.3955078125, mean for epoch: 1.1447164601293103, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 88: 0.7177734375, mean for epoch: 1.1398648348721592, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 89: 0.685546875, mean for epoch: 1.1347601386938202, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 90: 0.92529296875, mean for epoch: 1.1324327256944444, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:43,407] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:43,407] [INFO] [timer.py:207:stop] 0/90, RunningAvgSamplesPerSec=89.0433966317985, CurrSamplesPerSec=86.2965142356296, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 91: 0.65087890625, mean for epoch: 1.1271409254807692, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 92: 0.771484375, mean for epoch: 1.1232750934103262, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 93: 0.57373046875, mean for epoch: 1.1173660114247312, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 94: 1.33984375, mean for epoch: 1.1197327958776595, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 95: 0.63916015625, mean for epoch: 1.1146741365131578, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 96: 0.57421875, mean for epoch: 1.1090443929036458, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 97: 0.7265625, mean for epoch: 1.1051012806056701, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 98: 0.7607421875, mean for epoch: 1.1015874123086735, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 99: 0.68115234375, mean for epoch: 1.0973405934343434, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 100: 0.76806640625, mean for epoch: 1.0940478515625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:44,012] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:44,012] [INFO] [timer.py:207:stop] 0/100, RunningAvgSamplesPerSec=88.71599226129871, CurrSamplesPerSec=87.30712227939584, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 101: 0.97705078125, mean for epoch: 1.0928894647277227, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 102: 1.1943359375, mean for epoch: 1.0938840379901962, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 103: 0.8603515625, mean for epoch: 1.0916167324029127, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 104: 1.49609375, mean for epoch: 1.0955059344951923, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 105: 0.662109375, mean for epoch: 1.0913783482142858, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 106: 1.94921875, mean for epoch: 1.0994711821933962, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 107: 0.6181640625, mean for epoch: 1.094972984813084, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 108: 1.8984375, mean for epoch: 1.1024124710648149, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 109: 0.744140625, mean for epoch: 1.0991255733944953, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 110: 0.64453125, mean for epoch: 1.0949928977272727, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:44,624] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:44,625] [INFO] [timer.py:207:stop] 0/110, RunningAvgSamplesPerSec=88.35229850642168, CurrSamplesPerSec=85.69773001246348, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 111: 0.65283203125, mean for epoch: 1.0910094664977477, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 112: 0.83935546875, mean for epoch: 1.0887625558035714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 113: 0.8388671875, mean for epoch: 1.0865510923672566, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 114: 0.6669921875, mean for epoch: 1.0828707510964912, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 115: 1.013671875, mean for epoch: 1.0822690217391304, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 116: 0.91845703125, mean for epoch: 1.0808568494073276, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 117: 0.669921875, mean for epoch: 1.0773445846688035, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 118: 0.9521484375, mean for epoch: 1.0762836003707628, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 119: 1.05078125, mean for epoch: 1.0760692949054622, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 120: 0.72119140625, mean for epoch: 1.0731119791666666, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:45,239] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:45,240] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=88.03034262951834, CurrSamplesPerSec=81.79953740000079, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 121: 0.630859375, mean for epoch: 1.0694569989669422, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 122: 0.7060546875, mean for epoch: 1.0664782914959017, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 123: 0.7724609375, mean for epoch: 1.0640879065040652, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 124: 0.92578125, mean for epoch: 1.0629725302419355, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 125: 0.71826171875, mean for epoch: 1.06021484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 126: 0.83740234375, mean for epoch: 1.0584464905753967, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 127: 1.2568359375, mean for epoch: 1.0600086122047243, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 128: 0.939453125, mean for epoch: 1.0590667724609375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 129: 0.57275390625, mean for epoch: 1.0552969052810077, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 130: 0.5537109375, mean for epoch: 1.0514385516826923, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:45,848] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:45,848] [INFO] [timer.py:207:stop] 0/130, RunningAvgSamplesPerSec=87.85054158890624, CurrSamplesPerSec=88.17639045392623, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 131: 0.62451171875, mean for epoch: 1.0481795682251909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 132: 0.61376953125, mean for epoch: 1.0448885830965908, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 133: 0.8046875, mean for epoch: 1.0430825599154134, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 134: 1.2333984375, mean for epoch: 1.0445028276585822, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 135: 0.59130859375, mean for epoch: 1.0411458333333334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 136: 0.8212890625, mean for epoch: 1.039529239430147, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 137: 0.95458984375, mean for epoch: 1.0389092438412408, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 138: 0.58154296875, mean for epoch: 1.0355949954710144, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 139: 0.5859375, mean for epoch: 1.0323600494604317, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 140: 0.626953125, mean for epoch: 1.0294642857142857, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:46,456] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:46,456] [INFO] [timer.py:207:stop] 0/140, RunningAvgSamplesPerSec=87.65524538879102, CurrSamplesPerSec=81.99879571776003, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 141: 1.99609375, mean for epoch: 1.0363198138297873, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 142: 0.52734375, mean for epoch: 1.0327354753521127, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 143: 0.9423828125, mean for epoch: 1.032103638548951, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 144: 0.5625, mean for epoch: 1.0288425021701388, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 145: 0.53173828125, mean for epoch: 1.0254141971982758, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 146: 2.017578125, mean for epoch: 1.0322098405393836, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 147: 0.82421875, mean for epoch: 1.0307949351615646, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 148: 0.53955078125, mean for epoch: 1.0274757179054055, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 149: 0.6015625, mean for epoch: 1.024617239932886, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 150: 0.9443359375, mean for epoch: 1.02408203125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:47,064] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:47,065] [INFO] [timer.py:207:stop] 0/150, RunningAvgSamplesPerSec=87.51406546308256, CurrSamplesPerSec=86.04547729827758, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 151: 1.9248046875, mean for epoch: 1.0300470819536425, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 152: 1.076171875, mean for epoch: 1.0303505345394737, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 153: 0.5810546875, mean for epoch: 1.027413960375817, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 154: 0.6015625, mean for epoch: 1.0246486911525974, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 155: 0.61962890625, mean for epoch: 1.022035660282258, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 156: 0.5673828125, mean for epoch: 1.0191212189503205, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 157: 0.63671875, mean for epoch: 1.0166855344347134, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 158: 0.51318359375, mean for epoch: 1.0134988132911393, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 159: 0.82421875, mean for epoch: 1.0123083726415094, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 160: 0.5908203125, mean for epoch: 1.009674072265625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:47,669] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:47,670] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=87.44584539886691, CurrSamplesPerSec=83.28311028156149, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 161: 1.099609375, mean for epoch: 1.0102326766304348, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 162: 0.6103515625, mean for epoch: 1.007764274691358, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 163: 0.5029296875, mean for epoch: 1.0046671299846626, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 164: 0.6044921875, mean for epoch: 1.0022270388719512, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 165: 0.60791015625, mean for epoch: 0.9998372395833334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 166: 0.67431640625, mean for epoch: 0.9978762707078314, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 167: 1.236328125, mean for epoch: 0.9993041261227545, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 168: 0.58154296875, mean for epoch: 0.9968174525669643, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 169: 1.7841796875, mean for epoch: 1.0014764007026626, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 170: 0.54833984375, mean for epoch: 0.9988108915441176, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:48,275] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:48,275] [INFO] [timer.py:207:stop] 0/170, RunningAvgSamplesPerSec=87.38109494244931, CurrSamplesPerSec=86.06313301268898, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 171: 1.1591796875, mean for epoch: 0.9997487207602339, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 172: 2.001953125, mean for epoch: 1.0055754905523255, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 173: 0.85205078125, mean for epoch: 1.0046880644869942, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 174: 1.205078125, mean for epoch: 1.0058397315014367, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 175: 1.71484375, mean for epoch: 1.0098911830357142, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 176: 0.58447265625, mean for epoch: 1.0074740323153408, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 177: 0.6884765625, mean for epoch: 1.005671786723164, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 178: 0.50537109375, mean for epoch: 1.0028611086727528, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 179: 0.75927734375, mean for epoch: 1.0015003055167597, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 180: 0.7109375, mean for epoch: 0.9998860677083333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:48,889] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:48,889] [INFO] [timer.py:207:stop] 0/180, RunningAvgSamplesPerSec=87.24054155766363, CurrSamplesPerSec=88.66475567168091, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 181: 0.472412109375, mean for epoch: 0.9969718469440608, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 182: 0.52783203125, mean for epoch: 0.9943941556490384, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 183: 0.6279296875, mean for epoch: 0.9923916175717213, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 184: 1.2001953125, mean for epoch: 0.9935209854789402, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 185: 2.201171875, mean for epoch: 1.000048828125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 186: 0.52685546875, mean for epoch: 0.9975047778057796, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 187: 1.322265625, mean for epoch: 0.9992414668282086, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 188: 1.3271484375, mean for epoch: 1.0009856528424201, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 189: 0.62353515625, mean for epoch: 0.9989885602678571, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 190: 0.6201171875, mean for epoch: 0.9969945004111842, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:49,508] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:49,508] [INFO] [timer.py:207:stop] 0/190, RunningAvgSamplesPerSec=87.09126460411841, CurrSamplesPerSec=85.65327844079039, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 191: 2.595703125, mean for epoch: 1.0053647026341623, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 192: 0.6484375, mean for epoch: 1.0035057067871094, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 193: 0.69677734375, mean for epoch: 1.0019164406573835, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 194: 0.634765625, mean for epoch: 1.0000239106797681, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 195: 1.953125, mean for epoch: 1.004911608573718, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 196: 0.546875, mean for epoch: 1.002574687101403, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 197: 1.0986328125, mean for epoch: 1.0030622917988579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 198: 0.52587890625, mean for epoch: 1.0006522747001263, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 199: 0.720703125, mean for epoch: 0.999245495053392, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 200: 1.9580078125, mean for epoch: 1.004039306640625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:50,120] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:50,120] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=86.99989408809377, CurrSamplesPerSec=86.09563846558066, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 201: 0.58447265625, mean for epoch: 1.001951910370025, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 202: 0.56201171875, mean for epoch: 0.9997739886293316, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 203: 0.6083984375, mean for epoch: 0.9978460302493842, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 204: 0.4892578125, mean for epoch: 0.9953529507506127, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 205: 1.12109375, mean for epoch: 0.9959663205030488, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 206: 0.61181640625, mean for epoch: 0.9941015150940534, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 207: 0.587890625, mean for epoch: 0.9921391436443237, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 208: 0.583984375, mean for epoch: 0.9901768611027644, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 209: 1.0283203125, mean for epoch: 0.9903593656549043, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 210: 0.81201171875, mean for epoch: 0.9895100911458333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:50,729] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:50,729] [INFO] [timer.py:207:stop] 0/210, RunningAvgSamplesPerSec=86.9407672649849, CurrSamplesPerSec=88.26657351016233, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 211: 1.3017578125, mean for epoch: 0.9909899381664692, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 212: 1.0771484375, mean for epoch: 0.9913963461821934, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 213: 0.63427734375, mean for epoch: 0.9897197311473005, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 214: 0.57373046875, mean for epoch: 0.9877758560893691, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 215: 0.5439453125, mean for epoch: 0.9857115279796511, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 216: 0.55712890625, mean for epoch: 0.9837273491753472, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 217: 0.58740234375, mean for epoch: 0.9819009666618663, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 218: 0.552734375, mean for epoch: 0.9799323125716743, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 219: 0.6064453125, mean for epoch: 0.9782268924800228, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 220: 0.552734375, mean for epoch: 0.9762928355823863, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:51,334] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:51,335] [INFO] [timer.py:207:stop] 0/220, RunningAvgSamplesPerSec=86.90770461506104, CurrSamplesPerSec=87.50310849265227, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 221: 0.6220703125, mean for epoch: 0.9746900187358597, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 222: 0.59912109375, mean for epoch: 0.972998266821509, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 223: 0.65087890625, mean for epoch: 0.9715537853839686, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 224: 0.71337890625, mean for epoch: 0.9704012189592633, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 225: 0.63037109375, mean for epoch: 0.9688899739583333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 226: 1.8525390625, mean for epoch: 0.9727999256775443, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 227: 0.529296875, mean for epoch: 0.9708461677450441, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 228: 0.55615234375, mean for epoch: 0.9690273351836622, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 229: 0.6025390625, mean for epoch: 0.9674269497134279, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 230: 0.56494140625, mean for epoch: 0.9656770125679348, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:51,937] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:51,937] [INFO] [timer.py:207:stop] 0/230, RunningAvgSamplesPerSec=86.88238361833133, CurrSamplesPerSec=88.14044289779055, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 231: 0.58251953125, mean for epoch: 0.9640183221726191, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 232: 0.481201171875, mean for epoch: 0.9619372137661638, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 233: 0.62841796875, mean for epoch: 0.9605058006974249, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 234: 1.447265625, mean for epoch: 0.9625859708867521, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 235: 0.70703125, mean for epoch: 0.9614985039893617, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 236: 0.58056640625, mean for epoch: 0.959884384931144, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 237: 0.85302734375, mean for epoch: 0.9594335113396625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 238: 0.64599609375, mean for epoch: 0.9581165474002101, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 239: 1.396484375, mean for epoch: 0.9599507224110879, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 240: 0.736328125, mean for epoch: 0.9590189615885417, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:52,548] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:52,549] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=86.80328907762274, CurrSamplesPerSec=87.02850526822508, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 241: 0.6044921875, mean for epoch: 0.9575478961358921, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 242: 0.69482421875, mean for epoch: 0.9564622611053719, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 243: 0.75537109375, mean for epoch: 0.9556347254372428, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 244: 0.57568359375, mean for epoch: 0.9540775486680327, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 245: 0.5888671875, mean for epoch: 0.9525868941326531, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 246: 0.5849609375, mean for epoch: 0.9510924796747967, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 247: 0.55908203125, mean for epoch: 0.9495053928390689, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 248: 0.6640625, mean for epoch: 0.9483544134324596, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 249: 0.87060546875, mean for epoch: 0.9480421686746988, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 250: 0.556640625, mean for epoch: 0.9464765625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:53,157] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:53,157] [INFO] [timer.py:207:stop] 0/250, RunningAvgSamplesPerSec=86.7518967261946, CurrSamplesPerSec=87.29367593374985, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 251: 0.56396484375, mean for epoch: 0.9449526114292829, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 252: 0.49658203125, mean for epoch: 0.9431733630952381, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 253: 0.52099609375, mean for epoch: 0.941504678236166, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 254: 0.82763671875, mean for epoch: 0.9410563791830708, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 255: 0.471435546875, mean for epoch: 0.9392147288602941, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 256: 1.51171875, mean for epoch: 0.9414510726928711, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 257: 0.5185546875, mean for epoch: 0.9398055614664397, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 258: 1.275390625, mean for epoch: 0.9411062787669574, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 259: 0.5771484375, mean for epoch: 0.939701036136583, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 260: 1.0166015625, mean for epoch: 0.9399968073918269, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:53,764] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:53,765] [INFO] [timer.py:207:stop] 0/260, RunningAvgSamplesPerSec=86.70067284271742, CurrSamplesPerSec=88.05236573722242, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   1:   Loss at step 261: 1.7802734375, mean for epoch: 0.9432162580818966, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 262: 0.54296875, mean for epoch: 0.9416885958373091, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 263: 0.7802734375, mean for epoch: 0.9410748499881179, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 264: 0.6005859375, mean for epoch: 0.9397851192589962, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 265: 0.54931640625, mean for epoch: 0.9383116524174528, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 266: 0.57861328125, mean for epoch: 0.9369594029017857, mem_alloc: 1023816704\n",
            " Run   1, iteration:   1:   Loss at step 267: 1.083984375, mean for epoch: 0.9375100582279963, mem_alloc: 1023816704\n",
            "Loss after iteration 1 ; MSE: 0.9375, MAE: 0.5771484375\n",
            "Connected by ('127.0.0.1', 48086)\n",
            "\u001b[94mReceived training result: b'1;0.93750;0.57715' \u001b[0m\n",
            "Time per iteration 17.001768112182617, memory OrderedDict([('active.all.allocated', 352686), ('active.all.current', 7), ('active.all.freed', 352679), ('active.all.peak', 197), ('active.large_pool.allocated', 769), ('active.large_pool.current', 3), ('active.large_pool.freed', 766), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 351917), ('active.small_pool.current', 4), ('active.small_pool.freed', 351913), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 287205266944), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 287200133120), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 267786166784), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 267782497280), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 19419100160), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 19417635840), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 287205266944), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 287200744960), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 267786166784), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 267782497280), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 19419100160), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 19418247680), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 352686), ('allocation.all.current', 6), ('allocation.all.freed', 352680), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 769), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 766), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 351917), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 351914), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 149655), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 149649), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 251), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 249), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 149404), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 149400), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 23496072192), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 23476040192), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 711064064), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 693762048), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 22785008128), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 22782278144), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   1, iteration:   2:   Loss at step 1: 0.91552734375, mean for epoch: 0.91552734375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 2: 0.60107421875, mean for epoch: 0.75830078125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 3: 0.8095703125, mean for epoch: 0.775390625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:54,682] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:54,682] [INFO] [timer.py:207:stop] 0/270, RunningAvgSamplesPerSec=86.60337996445888, CurrSamplesPerSec=84.21823672564595, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 4: 1.5224609375, mean for epoch: 0.962158203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 5: 0.5458984375, mean for epoch: 0.87890625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 6: 0.51416015625, mean for epoch: 0.818115234375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 7: 0.87548828125, mean for epoch: 0.8263113839285714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 8: 0.4560546875, mean for epoch: 0.780029296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 9: 0.5966796875, mean for epoch: 0.7596571180555556, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 10: 0.82763671875, mean for epoch: 0.766455078125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 11: 0.441650390625, mean for epoch: 0.7369273792613636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 12: 0.56298828125, mean for epoch: 0.7224324544270834, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 13: 0.457275390625, mean for epoch: 0.7020357572115384, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:55,287] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:55,287] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=86.57261766481378, CurrSamplesPerSec=85.97809910748329, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 14: 1.150390625, mean for epoch: 0.7340611049107143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 15: 0.8935546875, mean for epoch: 0.7446940104166667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 16: 0.64111328125, mean for epoch: 0.73822021484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 17: 1.419921875, mean for epoch: 0.7783203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 18: 0.578125, mean for epoch: 0.7671983506944444, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 19: 0.69287109375, mean for epoch: 0.7632863898026315, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 20: 0.77880859375, mean for epoch: 0.7640625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 21: 0.59033203125, mean for epoch: 0.7557896205357143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 22: 0.6201171875, mean for epoch: 0.7496226917613636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 23: 1.505859375, mean for epoch: 0.7825025475543478, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:55,894] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:55,894] [INFO] [timer.py:207:stop] 0/290, RunningAvgSamplesPerSec=86.53764884866543, CurrSamplesPerSec=87.76089922247051, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 24: 0.5439453125, mean for epoch: 0.7725626627604166, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 25: 0.51171875, mean for epoch: 0.76212890625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 26: 0.7666015625, mean for epoch: 0.7623009314903846, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 27: 0.57958984375, mean for epoch: 0.7555338541666666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 28: 1.130859375, mean for epoch: 0.7689383370535714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 29: 0.6064453125, mean for epoch: 0.7633351293103449, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 30: 0.46630859375, mean for epoch: 0.7534342447916667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 31: 0.66162109375, mean for epoch: 0.7504725302419355, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 32: 0.64599609375, mean for epoch: 0.7472076416015625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 33: 0.429931640625, mean for epoch: 0.7375932173295454, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:56,506] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:56,506] [INFO] [timer.py:207:stop] 0/300, RunningAvgSamplesPerSec=86.49520615206276, CurrSamplesPerSec=82.42096492744966, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 34: 0.457763671875, mean for epoch: 0.7293629365808824, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 35: 0.62158203125, mean for epoch: 0.7262834821428571, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 36: 1.173828125, mean for epoch: 0.7387152777777778, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 37: 0.54931640625, mean for epoch: 0.7335963893581081, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 38: 0.52734375, mean for epoch: 0.7281686883223685, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 39: 0.49365234375, mean for epoch: 0.7221554487179487, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 40: 0.6484375, mean for epoch: 0.7203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 41: 0.8369140625, mean for epoch: 0.7231564405487805, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 42: 1.810546875, mean for epoch: 0.7490466889880952, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 43: 2.068359375, mean for epoch: 0.7797283793604651, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:57,111] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:57,111] [INFO] [timer.py:207:stop] 0/310, RunningAvgSamplesPerSec=86.48478724201776, CurrSamplesPerSec=84.22736930040524, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 44: 0.53173828125, mean for epoch: 0.7740922407670454, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 45: 0.49755859375, mean for epoch: 0.7679470486111111, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 46: 0.70458984375, mean for epoch: 0.7665697180706522, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 47: 0.8310546875, mean for epoch: 0.7679417386968085, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 48: 1.4384765625, mean for epoch: 0.7819112141927084, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 49: 0.8212890625, mean for epoch: 0.78271484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 50: 0.62548828125, mean for epoch: 0.7795703125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 51: 0.79052734375, mean for epoch: 0.77978515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 52: 0.58984375, mean for epoch: 0.7761324368990384, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 53: 0.5791015625, mean for epoch: 0.7724148732311321, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:57,716] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:57,717] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=86.46909346116432, CurrSamplesPerSec=87.1243165993652, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 54: 1.8193359375, mean for epoch: 0.7918023003472222, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 55: 0.61328125, mean for epoch: 0.7885564630681818, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 56: 0.75732421875, mean for epoch: 0.7879987444196429, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 57: 0.5556640625, mean for epoch: 0.783922697368421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 58: 0.60400390625, mean for epoch: 0.7808206492456896, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 59: 0.52978515625, mean for epoch: 0.776565810381356, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 60: 0.40625, mean for epoch: 0.7703938802083333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 61: 0.748046875, mean for epoch: 0.7700275358606558, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 62: 0.56298828125, mean for epoch: 0.7666881930443549, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 63: 0.55908203125, mean for epoch: 0.7633928571428571, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:58,320] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:58,321] [INFO] [timer.py:207:stop] 0/330, RunningAvgSamplesPerSec=86.46053413643014, CurrSamplesPerSec=87.11418317160707, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 64: 1.783203125, mean for epoch: 0.779327392578125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 65: 0.560546875, mean for epoch: 0.7759615384615385, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 66: 1.0830078125, mean for epoch: 0.7806137547348485, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 67: 0.68359375, mean for epoch: 0.7791656949626866, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 68: 0.59912109375, mean for epoch: 0.7765179802389706, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 69: 0.58251953125, mean for epoch: 0.7737064085144928, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 70: 0.63037109375, mean for epoch: 0.7716587611607143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 71: 0.76123046875, mean for epoch: 0.7715118838028169, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 72: 0.447509765625, mean for epoch: 0.7670118543836806, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 73: 0.5322265625, mean for epoch: 0.7637956175085616, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:58,926] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:58,927] [INFO] [timer.py:207:stop] 0/340, RunningAvgSamplesPerSec=86.43903490248086, CurrSamplesPerSec=86.97111955277607, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 74: 0.5927734375, mean for epoch: 0.7614845069679054, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 75: 0.58642578125, mean for epoch: 0.759150390625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 76: 0.509765625, mean for epoch: 0.7558690121299342, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 77: 0.5283203125, mean for epoch: 0.7529138342126623, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 78: 0.49755859375, mean for epoch: 0.7496400490785257, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 79: 0.7001953125, mean for epoch: 0.7490141663370253, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 80: 0.54638671875, mean for epoch: 0.7464813232421875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 81: 1.193359375, mean for epoch: 0.7519983362268519, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 82: 0.51708984375, mean for epoch: 0.7491335985137195, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 83: 1.7578125, mean for epoch: 0.7612863563629518, mem_alloc: 1023816704\n",
            "[2022-10-31 19:00:59,535] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:00:59,536] [INFO] [timer.py:207:stop] 0/350, RunningAvgSamplesPerSec=86.41811282619805, CurrSamplesPerSec=85.73942337568889, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 84: 0.81201171875, mean for epoch: 0.7618902297247023, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 85: 0.54638671875, mean for epoch: 0.7593548943014706, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 86: 2.54296875, mean for epoch: 0.7800945902979651, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 87: 0.55517578125, mean for epoch: 0.7775093166307471, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 88: 0.5927734375, mean for epoch: 0.7754100452769886, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 89: 0.6083984375, mean for epoch: 0.7735335103581461, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 90: 1.130859375, mean for epoch: 0.7775037977430556, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 91: 0.57666015625, mean for epoch: 0.7752967247596154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 92: 0.60009765625, mean for epoch: 0.773392387058424, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 93: 0.568359375, mean for epoch: 0.771187731014785, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:00,150] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:00,151] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=86.36674919500133, CurrSamplesPerSec=83.57118377951878, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 94: 0.50927734375, mean for epoch: 0.7684014502992021, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 95: 0.68896484375, mean for epoch: 0.767565275493421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 96: 0.49853515625, mean for epoch: 0.7647628784179688, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 97: 0.845703125, mean for epoch: 0.7655973139497423, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 98: 0.53125, mean for epoch: 0.7632060148278061, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 99: 0.6611328125, mean for epoch: 0.7621749723800505, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 100: 0.5654296875, mean for epoch: 0.76020751953125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 101: 0.52099609375, mean for epoch: 0.7578390895730198, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 102: 0.54150390625, mean for epoch: 0.7557181564031863, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 103: 0.53271484375, mean for epoch: 0.7535530756978155, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:00,767] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:00,767] [INFO] [timer.py:207:stop] 0/370, RunningAvgSamplesPerSec=86.31007017631367, CurrSamplesPerSec=86.13276709695702, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 104: 0.62060546875, mean for epoch: 0.7522747333233173, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 105: 0.75537109375, mean for epoch: 0.7523042224702381, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 106: 0.630859375, mean for epoch: 0.7511585163620284, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 107: 0.9658203125, mean for epoch: 0.7531647013726636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 108: 0.5439453125, mean for epoch: 0.7512274848090278, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 109: 1.0869140625, mean for epoch: 0.7543071781823395, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 110: 1.908203125, mean for epoch: 0.7647971413352272, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 111: 0.58447265625, mean for epoch: 0.7631725964245496, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 112: 0.56494140625, mean for epoch: 0.7614026750837054, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 113: 0.81982421875, mean for epoch: 0.7619196798949115, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:01,374] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:01,375] [INFO] [timer.py:207:stop] 0/380, RunningAvgSamplesPerSec=86.29764438569222, CurrSamplesPerSec=86.57831942070628, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 114: 0.56591796875, mean for epoch: 0.7602003666392544, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 115: 0.60498046875, mean for epoch: 0.7588506283967391, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 116: 0.44677734375, mean for epoch: 0.7561603414601293, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 117: 0.576171875, mean for epoch: 0.7546219784989316, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 118: 0.56982421875, mean for epoch: 0.753055895789195, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 119: 0.60107421875, mean for epoch: 0.7517787388392857, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 120: 0.49951171875, mean for epoch: 0.749676513671875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 121: 0.486572265625, mean for epoch: 0.7475020983987604, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 122: 1.18359375, mean for epoch: 0.7510766201331968, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 123: 0.82763671875, mean for epoch: 0.7516990599593496, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:01,976] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:01,976] [INFO] [timer.py:207:stop] 0/390, RunningAvgSamplesPerSec=86.29933228594831, CurrSamplesPerSec=86.70790196143287, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 124: 0.457763671875, mean for epoch: 0.74932861328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 125: 0.56494140625, mean for epoch: 0.747853515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 126: 0.56884765625, mean for epoch: 0.7464328342013888, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 127: 0.51025390625, mean for epoch: 0.7445731576033464, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 128: 0.55078125, mean for epoch: 0.7430591583251953, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 129: 0.49853515625, mean for epoch: 0.7411636234253876, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 130: 0.60888671875, mean for epoch: 0.7401461087740384, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 131: 0.5107421875, mean for epoch: 0.7383949338024809, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 132: 0.5966796875, mean for epoch: 0.7373213334517046, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 133: 0.7822265625, mean for epoch: 0.7376589667528195, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:02,583] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:02,583] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=86.28259244620007, CurrSamplesPerSec=77.41224848379703, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 134: 1.8017578125, mean for epoch: 0.745600002915112, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 135: 0.626953125, mean for epoch: 0.7447211371527778, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 136: 0.78369140625, mean for epoch: 0.7450076832490808, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 137: 0.515625, mean for epoch: 0.7433333570939781, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 138: 0.6044921875, mean for epoch: 0.7423272616621377, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 139: 0.85693359375, mean for epoch: 0.7431517676483813, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 140: 0.5244140625, mean for epoch: 0.74158935546875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 141: 0.6640625, mean for epoch: 0.7410395196143617, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 142: 1.31640625, mean for epoch: 0.7450913979973591, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 143: 0.53173828125, mean for epoch: 0.743599418159965, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:03,205] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:03,206] [INFO] [timer.py:207:stop] 0/410, RunningAvgSamplesPerSec=86.22292759663684, CurrSamplesPerSec=84.82354987319859, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 144: 1.005859375, mean for epoch: 0.7454206678602431, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 145: 0.55615234375, mean for epoch: 0.7441153690732759, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 146: 0.48291015625, mean for epoch: 0.7423262922731164, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 147: 0.7919921875, mean for epoch: 0.7426641555059523, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 148: 0.81787109375, mean for epoch: 0.7431723104940878, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 149: 0.7607421875, mean for epoch: 0.7432902291317114, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 150: 0.480712890625, mean for epoch: 0.7415397135416667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 151: 0.7666015625, mean for epoch: 0.7417056860513245, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 152: 0.7353515625, mean for epoch: 0.7416638826069079, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 153: 1.154296875, mean for epoch: 0.7443608302696079, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:03,822] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:03,822] [INFO] [timer.py:207:stop] 0/420, RunningAvgSamplesPerSec=86.17245541484085, CurrSamplesPerSec=87.39407830308586, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 154: 0.45703125, mean for epoch: 0.7424950537743507, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 155: 0.59912109375, mean for epoch: 0.741570060483871, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 156: 0.51171875, mean for epoch: 0.7400966546474359, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 157: 0.76416015625, mean for epoch: 0.7402499253582803, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 158: 1.810546875, mean for epoch: 0.7470239566851266, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 159: 0.50341796875, mean for epoch: 0.7454918435534591, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 160: 1.8515625, mean for epoch: 0.75240478515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 161: 0.54248046875, mean for epoch: 0.7511009074145962, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 162: 0.53515625, mean for epoch: 0.7497679157021605, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 163: 2.37890625, mean for epoch: 0.7597626294095092, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:04,434] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:04,434] [INFO] [timer.py:207:stop] 0/430, RunningAvgSamplesPerSec=86.14609461355761, CurrSamplesPerSec=82.0202826111613, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 164: 0.482177734375, mean for epoch: 0.7580700385861281, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 165: 0.425048828125, mean for epoch: 0.756051728219697, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 166: 0.66552734375, mean for epoch: 0.7555064006024096, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 167: 0.5302734375, mean for epoch: 0.7541577002245509, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 168: 0.751953125, mean for epoch: 0.7541445777529762, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 169: 0.55322265625, mean for epoch: 0.7529556906434911, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 170: 0.48486328125, mean for epoch: 0.7513786764705882, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 171: 0.80712890625, mean for epoch: 0.7517047012061403, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 172: 0.8193359375, mean for epoch: 0.752097906068314, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 173: 0.64306640625, mean for epoch: 0.7514676661849711, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:05,041] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:05,042] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=86.13494866299251, CurrSamplesPerSec=85.57359121883543, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 174: 0.7568359375, mean for epoch: 0.7514985183189655, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 175: 2.39453125, mean for epoch: 0.7608872767857143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 176: 0.81689453125, mean for epoch: 0.7612054998224432, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 177: 0.58203125, mean for epoch: 0.7601932159251412, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 178: 0.5498046875, mean for epoch: 0.7590112579002809, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 179: 0.91552734375, mean for epoch: 0.7598856494413407, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 180: 0.49951171875, mean for epoch: 0.7584391276041667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 181: 0.8544921875, mean for epoch: 0.758969807493094, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 182: 0.53369140625, mean for epoch: 0.7577320140796703, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 183: 0.59326171875, mean for epoch: 0.7568332692964481, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:05,657] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:05,657] [INFO] [timer.py:207:stop] 0/450, RunningAvgSamplesPerSec=86.10100056419223, CurrSamplesPerSec=83.37946636238216, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 184: 0.70166015625, mean for epoch: 0.7565334154211957, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 185: 1.1484375, mean for epoch: 0.7586518158783784, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 186: 0.6123046875, mean for epoch: 0.757865003360215, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 187: 0.56884765625, mean for epoch: 0.756854215407754, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 188: 1.7451171875, mean for epoch: 0.7621109333444149, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 189: 1.1875, mean for epoch: 0.7643616691468254, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 190: 0.46630859375, mean for epoch: 0.76279296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 191: 0.75439453125, mean for epoch: 0.7627489978730366, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 192: 0.74658203125, mean for epoch: 0.762664794921875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 193: 2.337890625, mean for epoch: 0.7708265867875648, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:06,260] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:06,261] [INFO] [timer.py:207:stop] 0/460, RunningAvgSamplesPerSec=86.10232682089593, CurrSamplesPerSec=83.46474994229132, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 194: 2.416015625, mean for epoch: 0.7793069426546392, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 195: 0.5400390625, mean for epoch: 0.7780799278846153, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 196: 0.68798828125, mean for epoch: 0.7776202766262755, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 197: 0.5234375, mean for epoch: 0.7763300087246193, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 198: 0.64306640625, mean for epoch: 0.7756569602272727, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 199: 0.79736328125, mean for epoch: 0.7757660372173367, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 200: 0.5537109375, mean for epoch: 0.77465576171875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 201: 1.0625, mean for epoch: 0.7760878226057214, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 202: 0.444580078125, mean for epoch: 0.7744466951577971, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 203: 1.830078125, mean for epoch: 0.7796468499846059, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:06,869] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:06,869] [INFO] [timer.py:207:stop] 0/470, RunningAvgSamplesPerSec=86.08951312780972, CurrSamplesPerSec=86.53473517421229, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 204: 0.560546875, mean for epoch: 0.7785728304993873, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 205: 0.50390625, mean for epoch: 0.7772329935213415, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 206: 1.2568359375, mean for epoch: 0.7795611631523058, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 207: 0.493408203125, mean for epoch: 0.7781787817028986, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 208: 0.61376953125, mean for epoch: 0.7773883526141827, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 209: 1.4072265625, mean for epoch: 0.7804019325657895, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 210: 0.83203125, mean for epoch: 0.7806477864583333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 211: 1.7998046875, mean for epoch: 0.7854779139514217, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 212: 0.75244140625, mean for epoch: 0.7853220813679245, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 213: 0.6259765625, mean for epoch: 0.7845739803403756, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:07,479] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:07,480] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=86.0686395315464, CurrSamplesPerSec=86.00207505464448, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 214: 0.6884765625, mean for epoch: 0.7841249269859814, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 215: 1.3466796875, mean for epoch: 0.786741460755814, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 216: 0.681640625, mean for epoch: 0.7862548828125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 217: 3.833984375, mean for epoch: 0.8002997191820277, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 218: 0.52783203125, mean for epoch: 0.7990498674025229, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 219: 0.53173828125, mean for epoch: 0.7978292665525114, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 220: 0.57373046875, mean for epoch: 0.796810635653409, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 221: 0.68310546875, mean for epoch: 0.7962961326357466, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 222: 0.6083984375, mean for epoch: 0.7954497466216216, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 223: 0.826171875, mean for epoch: 0.795587514013453, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:08,081] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:08,082] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=86.06675188149097, CurrSamplesPerSec=86.30432724953188, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 224: 0.52783203125, mean for epoch: 0.7943921770368304, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 225: 0.708984375, mean for epoch: 0.7940125868055555, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 226: 1.1650390625, mean for epoch: 0.795654296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 227: 0.5419921875, mean for epoch: 0.7945368426486784, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 228: 0.55859375, mean for epoch: 0.7935020045230263, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 229: 0.486328125, mean for epoch: 0.7921606338700873, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 230: 1.5712890625, mean for epoch: 0.795548148777174, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 231: 0.56689453125, mean for epoch: 0.7945583062770563, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 232: 0.51904296875, mean for epoch: 0.7933707401670259, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 233: 0.62890625, mean for epoch: 0.7926648839860515, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:08,692] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:08,693] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=86.04464787060728, CurrSamplesPerSec=82.04884232270987, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 234: 0.46142578125, mean for epoch: 0.7912493322649573, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 235: 1.1796875, mean for epoch: 0.7929022606382978, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 236: 0.66552734375, mean for epoch: 0.792362536414195, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 237: 0.61328125, mean for epoch: 0.7916069191719409, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 238: 0.7138671875, mean for epoch: 0.7912802816439075, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 239: 0.6328125, mean for epoch: 0.7906172365324268, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 240: 0.716796875, mean for epoch: 0.7903096516927083, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 241: 0.5361328125, mean for epoch: 0.7892549760114108, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 242: 0.52099609375, mean for epoch: 0.7881464682334711, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 243: 0.5849609375, mean for epoch: 0.7873103137860082, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:09,291] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:09,292] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=86.05428826242517, CurrSamplesPerSec=86.36403694811533, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 244: 0.57421875, mean for epoch: 0.786436987704918, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 245: 0.78466796875, mean for epoch: 0.7864297672193877, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 246: 0.5615234375, mean for epoch: 0.7855155138465447, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 247: 0.477783203125, mean for epoch: 0.7842696340460527, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 248: 1.0693359375, mean for epoch: 0.7854190949470766, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 249: 0.5673828125, mean for epoch: 0.7845434472264057, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 250: 0.51025390625, mean for epoch: 0.7834462890625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 251: 0.5244140625, mean for epoch: 0.7824142881598606, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 252: 0.484375, mean for epoch: 0.7812315925719246, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 253: 0.53271484375, mean for epoch: 0.7802493129323123, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:09,897] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:09,897] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=86.04784915058457, CurrSamplesPerSec=86.7204512279338, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 254: 0.64990234375, mean for epoch: 0.7797361358882874, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 255: 0.53955078125, mean for epoch: 0.7787942325367647, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 256: 0.53173828125, mean for epoch: 0.7778291702270508, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 257: 0.54345703125, mean for epoch: 0.776917216378891, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 258: 0.473388671875, mean for epoch: 0.7757407491521318, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 259: 1.2138671875, mean for epoch: 0.7774323570222008, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 260: 0.57763671875, mean for epoch: 0.7766639122596154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 261: 1.79296875, mean for epoch: 0.7805578005268199, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 262: 0.54931640625, mean for epoch: 0.7796751997853053, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 263: 0.5654296875, mean for epoch: 0.7788605780655894, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:10,523] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:10,523] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=85.98992247197548, CurrSamplesPerSec=82.40541942379328, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   2:   Loss at step 264: 3.095703125, mean for epoch: 0.7876364968039773, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 265: 0.55322265625, mean for epoch: 0.7867519162735849, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 266: 0.78076171875, mean for epoch: 0.7867293967340225, mem_alloc: 1023816704\n",
            " Run   1, iteration:   2:   Loss at step 267: 1.7802734375, mean for epoch: 0.7904505354634831, mem_alloc: 1023816704\n",
            "Loss after iteration 2 ; MSE: 0.79052734375, MAE: 0.489990234375\n",
            "Connected by ('127.0.0.1', 36160)\n",
            "\u001b[94mReceived training result: b'2;0.79053;0.48999' \u001b[0m\n",
            "Time per iteration 16.798553347587585, memory OrderedDict([('active.all.allocated', 714204), ('active.all.current', 7), ('active.all.freed', 714197), ('active.all.peak', 197), ('active.large_pool.allocated', 1570), ('active.large_pool.current', 3), ('active.large_pool.freed', 1567), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 712634), ('active.small_pool.current', 4), ('active.small_pool.freed', 712630), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 574516610560), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 574511476736), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 535617327104), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 535613657600), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 38899283456), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 38897819136), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 574516610560), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 574512088576), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 535617327104), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 535613657600), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 38899283456), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 38898430976), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 714204), ('allocation.all.current', 6), ('allocation.all.freed', 714198), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 1570), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 1567), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 712634), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 712631), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 303360), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 303354), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 518), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 516), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 302842), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 302838), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 47080025600), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 47059993600), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 1451042816), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 1433740800), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 45628982784), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 45626252800), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   1, iteration:   3:   Loss at step 1: 0.80810546875, mean for epoch: 0.80810546875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 2: 0.74169921875, mean for epoch: 0.77490234375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 3: 0.492919921875, mean for epoch: 0.680908203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 4: 0.50830078125, mean for epoch: 0.63775634765625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 5: 0.460205078125, mean for epoch: 0.60224609375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 6: 0.53515625, mean for epoch: 0.591064453125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:11,451] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:11,452] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=85.90070770104518, CurrSamplesPerSec=77.31464447795199, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 7: 0.50927734375, mean for epoch: 0.5793805803571429, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 8: 1.146484375, mean for epoch: 0.6502685546875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 9: 0.7158203125, mean for epoch: 0.6575520833333334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 10: 0.74365234375, mean for epoch: 0.666162109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 11: 2.03515625, mean for epoch: 0.7906161221590909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 12: 0.50634765625, mean for epoch: 0.7669270833333334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 13: 0.51171875, mean for epoch: 0.7472956730769231, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 14: 0.50732421875, mean for epoch: 0.7301548549107143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 15: 0.7646484375, mean for epoch: 0.7324544270833333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 16: 1.08984375, mean for epoch: 0.754791259765625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:12,061] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:12,062] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=85.8865854553515, CurrSamplesPerSec=84.46551342207543, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 17: 0.60888671875, mean for epoch: 0.7462086397058824, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 18: 0.82958984375, mean for epoch: 0.7508409288194444, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 19: 0.57275390625, mean for epoch: 0.741467927631579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 20: 0.49658203125, mean for epoch: 0.7292236328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 21: 0.53125, mean for epoch: 0.7197963169642857, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 22: 0.47998046875, mean for epoch: 0.7088955965909091, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 23: 0.474853515625, mean for epoch: 0.6987198539402174, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 24: 1.857421875, mean for epoch: 0.7469991048177084, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 25: 0.4853515625, mean for epoch: 0.736533203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 26: 0.497802734375, mean for epoch: 0.7273512620192307, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:12,683] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:12,683] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=85.84787439487785, CurrSamplesPerSec=84.387340804378, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 27: 0.5400390625, mean for epoch: 0.7204137731481481, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 28: 0.50341796875, mean for epoch: 0.7126639229910714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 29: 1.37890625, mean for epoch: 0.7356377963362069, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 30: 0.54052734375, mean for epoch: 0.7291341145833333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 31: 0.83251953125, mean for epoch: 0.7324691280241935, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 32: 0.74365234375, mean for epoch: 0.732818603515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 33: 0.54052734375, mean for epoch: 0.7269915956439394, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 34: 0.642578125, mean for epoch: 0.7245088465073529, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 35: 0.51708984375, mean for epoch: 0.7185825892857143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 36: 0.58349609375, mean for epoch: 0.7148301866319444, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:13,303] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:13,303] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=85.810495171071, CurrSamplesPerSec=85.51845629373481, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 37: 2.00390625, mean for epoch: 0.7496700802364865, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 38: 0.5107421875, mean for epoch: 0.7433825041118421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 39: 0.59375, mean for epoch: 0.7395457732371795, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 40: 1.1435546875, mean for epoch: 0.74964599609375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 41: 1.935546875, mean for epoch: 0.7785704077743902, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 42: 0.6962890625, mean for epoch: 0.776611328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 43: 0.474365234375, mean for epoch: 0.7695823492005814, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 44: 0.454345703125, mean for epoch: 0.7624178799715909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 45: 0.7685546875, mean for epoch: 0.7625542534722223, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 46: 0.615234375, mean for epoch: 0.7593516474184783, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:13,927] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:13,927] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=85.76796993164191, CurrSamplesPerSec=80.46966011035478, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 47: 0.529296875, mean for epoch: 0.7544568650265957, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 48: 0.69677734375, mean for epoch: 0.7532552083333334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 49: 0.7626953125, mean for epoch: 0.7534478635204082, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 50: 1.3779296875, mean for epoch: 0.7659375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 51: 0.49462890625, mean for epoch: 0.7606177236519608, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 52: 1.8359375, mean for epoch: 0.7812969501201923, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 53: 0.724609375, mean for epoch: 0.7802273732311321, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 54: 0.478759765625, mean for epoch: 0.7746446397569444, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 55: 1.84375, mean for epoch: 0.7940829190340909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 56: 0.4931640625, mean for epoch: 0.7887093680245536, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:14,542] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:14,542] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=85.74900036601295, CurrSamplesPerSec=85.29064636432776, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 57: 0.884765625, mean for epoch: 0.7903945655153509, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 58: 0.76220703125, mean for epoch: 0.7899085735452587, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 59: 0.78759765625, mean for epoch: 0.7898694054555084, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 60: 1.8056640625, mean for epoch: 0.80679931640625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 61: 0.73193359375, mean for epoch: 0.805572009477459, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 62: 0.6064453125, mean for epoch: 0.8023602885584677, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 63: 0.8115234375, mean for epoch: 0.8025057353670635, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 64: 0.53857421875, mean for epoch: 0.7983818054199219, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 65: 0.7490234375, mean for epoch: 0.7976224459134615, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 66: 0.57080078125, mean for epoch: 0.7941857540246212, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:15,156] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:15,156] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=85.7386859692426, CurrSamplesPerSec=80.95142880303247, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 67: 0.53125, mean for epoch: 0.7902613397854478, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 68: 0.65234375, mean for epoch: 0.7882331399356618, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 69: 0.5556640625, mean for epoch: 0.7848625735960145, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 70: 0.705078125, mean for epoch: 0.7837227957589286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 71: 0.61865234375, mean for epoch: 0.7813978598151409, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 72: 0.51806640625, mean for epoch: 0.777740478515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 73: 1.8037109375, mean for epoch: 0.791794868364726, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 74: 0.5341796875, mean for epoch: 0.7883135821368243, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 75: 0.60107421875, mean for epoch: 0.7858170572916666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 76: 2.005859375, mean for epoch: 0.8018702456825658, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:15,771] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:15,771] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=85.71823624380497, CurrSamplesPerSec=82.53417029063932, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 77: 0.4853515625, mean for epoch: 0.7977596134334416, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 78: 0.5029296875, mean for epoch: 0.7939797425881411, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 79: 0.5078125, mean for epoch: 0.7903573724287974, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 80: 0.452880859375, mean for epoch: 0.786138916015625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 81: 0.54296875, mean for epoch: 0.7831368152006173, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 82: 1.0712890625, mean for epoch: 0.7866508669969512, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 83: 0.55908203125, mean for epoch: 0.7839090737951807, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 84: 1.2158203125, mean for epoch: 0.7890508742559523, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 85: 1.8798828125, mean for epoch: 0.8018841911764706, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 86: 1.71484375, mean for epoch: 0.8125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:16,389] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:16,390] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=85.69720472465077, CurrSamplesPerSec=85.07577970337195, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 87: 0.5, mean for epoch: 0.8089080459770115, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 88: 0.5205078125, mean for epoch: 0.8056307705965909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 89: 0.5712890625, mean for epoch: 0.8029977176966292, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 90: 0.80126953125, mean for epoch: 0.802978515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 91: 0.54541015625, mean for epoch: 0.8001480940934066, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 92: 0.4921875, mean for epoch: 0.7968006963315217, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 93: 0.56689453125, mean for epoch: 0.7943285870295699, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 94: 0.460693359375, mean for epoch: 0.7907792760970744, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 95: 0.8154296875, mean for epoch: 0.7910387541118421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 96: 0.5556640625, mean for epoch: 0.7885869344075521, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:17,017] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:17,017] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=85.650904336264, CurrSamplesPerSec=82.36593431625913, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 97: 0.80078125, mean for epoch: 0.7887126490012887, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 98: 0.58203125, mean for epoch: 0.7866036551339286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 99: 0.705078125, mean for epoch: 0.7857801649305556, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 100: 0.77392578125, mean for epoch: 0.78566162109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 101: 0.52392578125, mean for epoch: 0.783070177134901, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 102: 0.73876953125, mean for epoch: 0.7826358570772058, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 103: 1.1181640625, mean for epoch: 0.7858934124696602, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 104: 0.489990234375, mean for epoch: 0.7830481896033654, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 105: 0.96923828125, mean for epoch: 0.7848214285714286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 106: 0.74755859375, mean for epoch: 0.7844698923938679, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:17,639] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:17,639] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=85.61730813403443, CurrSamplesPerSec=83.81567483314016, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 107: 1.705078125, mean for epoch: 0.7930737076518691, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 108: 1.7021484375, mean for epoch: 0.8014910662615741, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 109: 0.56396484375, mean for epoch: 0.7993119266055045, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 110: 0.478515625, mean for epoch: 0.7963955965909091, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 111: 1.185546875, mean for epoch: 0.799901463963964, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 112: 1.0830078125, mean for epoch: 0.80242919921875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 113: 0.63232421875, mean for epoch: 0.8009238454092921, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 114: 0.73193359375, mean for epoch: 0.8003186677631579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 115: 0.441162109375, mean for epoch: 0.7971955672554348, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 116: 0.556640625, mean for epoch: 0.7951218177532328, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:18,254] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:18,255] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=85.59902858037515, CurrSamplesPerSec=87.08922156931958, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 117: 1.796875, mean for epoch: 0.8036838107638888, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 118: 0.83642578125, mean for epoch: 0.8039612850900424, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 119: 0.5859375, mean for epoch: 0.8021291524422269, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 120: 0.65234375, mean for epoch: 0.8008809407552083, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 121: 0.5419921875, mean for epoch: 0.7987413642820248, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 122: 0.5400390625, mean for epoch: 0.7966208536116803, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 123: 0.53369140625, mean for epoch: 0.794483215828252, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 124: 0.74462890625, mean for epoch: 0.7940811649445565, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 125: 0.587890625, mean for epoch: 0.792431640625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 126: 0.90283203125, mean for epoch: 0.7933078342013888, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:18,866] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:18,866] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=85.5925986965037, CurrSamplesPerSec=84.05789433602283, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 127: 1.0205078125, mean for epoch: 0.7950968104084646, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 128: 0.54150390625, mean for epoch: 0.7931156158447266, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 129: 0.4638671875, mean for epoch: 0.7905633024467055, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 130: 1.13671875, mean for epoch: 0.7932260366586539, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 131: 0.587890625, mean for epoch: 0.7916585907681297, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 132: 0.476806640625, mean for epoch: 0.7892733487215909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 133: 0.73681640625, mean for epoch: 0.7888789356203008, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 134: 0.483154296875, mean for epoch: 0.7865974084654851, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 135: 0.5732421875, mean for epoch: 0.7850169994212963, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 136: 0.724609375, mean for epoch: 0.7845728257123161, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:19,469] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:19,469] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=85.59978827381536, CurrSamplesPerSec=86.65809927976099, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 137: 1.0966796875, mean for epoch: 0.7868509779881386, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 138: 0.389892578125, mean for epoch: 0.7839744678442029, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 139: 0.529296875, mean for epoch: 0.7821422549460432, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 140: 0.48974609375, mean for epoch: 0.7800537109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 141: 0.492919921875, mean for epoch: 0.7780173010859929, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 142: 0.79443359375, mean for epoch: 0.7781329087808099, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 143: 0.55615234375, mean for epoch: 0.7765805971372378, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 144: 0.56689453125, mean for epoch: 0.7751244439019097, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 145: 0.66064453125, mean for epoch: 0.7743349272629311, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 146: 1.53125, mean for epoch: 0.7795192770761986, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:20,080] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:20,081] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=85.59053084108717, CurrSamplesPerSec=81.96194146223263, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 147: 0.6689453125, mean for epoch: 0.7787670732355442, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 148: 1.400390625, mean for epoch: 0.7829672323690878, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 149: 0.474853515625, mean for epoch: 0.7808993550755033, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 150: 1.3349609375, mean for epoch: 0.7845930989583333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 151: 0.5009765625, mean for epoch: 0.78271484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 152: 0.52734375, mean for epoch: 0.7810347707648027, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 153: 0.54052734375, mean for epoch: 0.7794628267973857, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 154: 0.5478515625, mean for epoch: 0.7779588575487013, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 155: 1.6728515625, mean for epoch: 0.7837323588709677, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 156: 0.58544921875, mean for epoch: 0.7824613131009616, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:20,695] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:20,696] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=85.57679841704694, CurrSamplesPerSec=86.70682647901533, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 157: 0.4755859375, mean for epoch: 0.7805066928742038, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 158: 0.5029296875, mean for epoch: 0.7787498763844937, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 159: 0.53564453125, mean for epoch: 0.7772209119496856, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 160: 0.438232421875, mean for epoch: 0.7751022338867187, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 161: 0.49609375, mean for epoch: 0.7733692619371118, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 162: 2.365234375, mean for epoch: 0.7831955897955247, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 163: 0.587890625, mean for epoch: 0.781997399827454, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 164: 0.6796875, mean for epoch: 0.7813735589748476, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 165: 1.15234375, mean for epoch: 0.7836218631628787, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 166: 0.9453125, mean for epoch: 0.7845959031438253, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:21,308] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:21,309] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=85.56497513957021, CurrSamplesPerSec=88.83489429117265, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 167: 1.1142578125, mean for epoch: 0.7865699265531437, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 168: 0.4267578125, mean for epoch: 0.7844281877790179, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 169: 0.75390625, mean for epoch: 0.7842475845968935, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 170: 1.173828125, mean for epoch: 0.7865392348345588, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 171: 0.4619140625, mean for epoch: 0.7846408420138888, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 172: 0.493408203125, mean for epoch: 0.782947628997093, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 173: 0.75634765625, mean for epoch: 0.7827938719291907, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 174: 0.5634765625, mean for epoch: 0.7815334276221264, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 175: 0.5810546875, mean for epoch: 0.7803878348214286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 176: 0.62353515625, mean for epoch: 0.7794966264204546, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:21,928] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:21,928] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=85.54151072918023, CurrSamplesPerSec=83.65519167098807, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 177: 1.0693359375, mean for epoch: 0.7811341366525424, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 178: 1.4140625, mean for epoch: 0.7846899139747191, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 179: 0.62744140625, mean for epoch: 0.7838114306913407, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 180: 0.494140625, mean for epoch: 0.7822021484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 181: 0.61279296875, mean for epoch: 0.7812661861187845, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 182: 0.77587890625, mean for epoch: 0.781236585679945, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 183: 0.74658203125, mean for epoch: 0.7810472165300546, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 184: 0.59814453125, mean for epoch: 0.7800531801970109, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 185: 0.490234375, mean for epoch: 0.7784865920608108, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 186: 0.462890625, mean for epoch: 0.7767898395497311, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:22,563] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:22,563] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=85.49235271171364, CurrSamplesPerSec=78.94447184066193, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 187: 0.61474609375, mean for epoch: 0.7759232954545454, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 188: 0.541015625, mean for epoch: 0.774673786569149, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 189: 0.59521484375, mean for epoch: 0.7737242683531746, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 190: 0.5400390625, mean for epoch: 0.7724943462171052, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 191: 0.4921875, mean for epoch: 0.7710267711060209, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 192: 1.7958984375, mean for epoch: 0.7763646443684896, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 193: 0.463623046875, mean for epoch: 0.7747442215835493, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 194: 1.666015625, mean for epoch: 0.7793384040753866, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 195: 0.476806640625, mean for epoch: 0.7777869591346154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 196: 0.494140625, mean for epoch: 0.7763397839604592, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:23,187] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:23,188] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=85.46396598531966, CurrSamplesPerSec=79.18322962604965, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 197: 1.9609375, mean for epoch: 0.7823529703362944, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 198: 0.497314453125, mean for epoch: 0.7809133818655303, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 199: 0.50537109375, mean for epoch: 0.7795287472518844, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 200: 0.498291015625, mean for epoch: 0.77812255859375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 201: 0.5419921875, mean for epoch: 0.7769477806281094, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 202: 0.74169921875, mean for epoch: 0.7767732827970297, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 203: 0.52880859375, mean for epoch: 0.7755517818657636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 204: 0.59130859375, mean for epoch: 0.7746486289828431, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 205: 0.615234375, mean for epoch: 0.7738709984756098, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 206: 0.49853515625, mean for epoch: 0.772534416717233, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:23,829] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:23,830] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=85.4005242959398, CurrSamplesPerSec=81.80017552413457, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 207: 0.7568359375, mean for epoch: 0.7724585786533816, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 208: 0.78125, mean for epoch: 0.7725008451021634, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 209: 0.50634765625, mean for epoch: 0.771227384868421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 210: 0.81591796875, mean for epoch: 0.771440197172619, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 211: 0.5927734375, mean for epoch: 0.770593435278436, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 212: 0.51416015625, mean for epoch: 0.7693838443396226, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 213: 0.46923828125, mean for epoch: 0.7679747102406104, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 214: 0.525390625, mean for epoch: 0.7668411397488317, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 215: 0.71875, mean for epoch: 0.7666174600290697, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 216: 0.552734375, mean for epoch: 0.7656272605613426, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:24,479] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:24,479] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=85.33415219145839, CurrSamplesPerSec=78.09633044605152, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 217: 0.55078125, mean for epoch: 0.764637186779954, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 218: 1.7900390625, mean for epoch: 0.769340865108945, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 219: 0.57763671875, mean for epoch: 0.7684655037100456, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 220: 0.462890625, mean for epoch: 0.7670765269886364, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 221: 0.5322265625, mean for epoch: 0.7660138574660633, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 222: 1.0791015625, mean for epoch: 0.7674241624436937, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 223: 0.58447265625, mean for epoch: 0.7666037521020179, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 224: 0.5419921875, mean for epoch: 0.7656010219029018, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 225: 0.50244140625, mean for epoch: 0.7644314236111112, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 226: 0.53125, mean for epoch: 0.7633996474004425, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:25,091] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:25,091] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=85.32817570020056, CurrSamplesPerSec=82.49488623847436, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 227: 0.44482421875, mean for epoch: 0.7619962314151982, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 228: 0.50146484375, mean for epoch: 0.7608535498903509, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 229: 0.8466796875, mean for epoch: 0.7612283365174672, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 230: 0.50341796875, mean for epoch: 0.760107421875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 231: 0.708984375, mean for epoch: 0.7598861099837663, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 232: 0.6279296875, mean for epoch: 0.7593173323006466, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 233: 1.7060546875, mean for epoch: 0.7633805827521459, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 234: 0.5361328125, mean for epoch: 0.7624094384348291, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 235: 0.5771484375, mean for epoch: 0.76162109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 236: 0.58984375, mean for epoch: 0.7608932236493644, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:25,689] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:25,690] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=85.34505957195431, CurrSamplesPerSec=87.2686113769714, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 237: 0.50146484375, mean for epoch: 0.7597985891350211, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 238: 0.47412109375, mean for epoch: 0.7585982635241597, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 239: 0.64501953125, mean for epoch: 0.7581230387029289, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 240: 1.107421875, mean for epoch: 0.7595784505208333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 241: 0.47412109375, mean for epoch: 0.7583939801607884, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 242: 0.60400390625, mean for epoch: 0.7577560046487604, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 243: 0.58837890625, mean for epoch: 0.7570589795524691, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 244: 0.73974609375, mean for epoch: 0.756988025102459, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 245: 1.97265625, mean for epoch: 0.7619499362244898, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 246: 0.76953125, mean for epoch: 0.7619807545731707, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:26,310] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:26,311] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=85.32514449484083, CurrSamplesPerSec=81.3454974244399, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 247: 0.49267578125, mean for epoch: 0.7608904510374493, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 248: 0.64501953125, mean for epoch: 0.7604232295866935, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 249: 0.395751953125, mean for epoch: 0.7589586863077309, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 250: 0.56689453125, mean for epoch: 0.7581904296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 251: 0.61669921875, mean for epoch: 0.7576267196837649, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 252: 1.8388671875, mean for epoch: 0.7619173564608135, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 253: 0.488525390625, mean for epoch: 0.7608367558053359, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 254: 0.8251953125, mean for epoch: 0.7610901359498031, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 255: 0.638671875, mean for epoch: 0.7606100643382353, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 256: 1.78515625, mean for epoch: 0.7646121978759766, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:26,938] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:26,939] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=85.29472674182277, CurrSamplesPerSec=80.66217422074526, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 257: 0.5029296875, mean for epoch: 0.7635939779912452, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 258: 1.1337890625, mean for epoch: 0.7650288426598837, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 259: 0.56787109375, mean for epoch: 0.7642676158301158, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 260: 1.0244140625, mean for epoch: 0.7652681790865384, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 261: 0.6640625, mean for epoch: 0.7648804178639846, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 262: 0.7294921875, mean for epoch: 0.7647453482824428, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 263: 0.615234375, mean for epoch: 0.7641768654942965, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 264: 0.91455078125, mean for epoch: 0.7647464636600378, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 265: 0.50732421875, mean for epoch: 0.7637750589622642, mem_alloc: 1023816704\n",
            " Run   1, iteration:   3:   Loss at step 266: 0.966796875, mean for epoch: 0.7645382988721805, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:27,540] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:27,541] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=85.31073941463157, CurrSamplesPerSec=87.31657354129021, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   3:   Loss at step 267: 0.488037109375, mean for epoch: 0.7635027138927902, mem_alloc: 1023816704\n",
            "Loss after iteration 3 ; MSE: 0.763671875, MAE: 0.474365234375\n",
            "Connected by ('127.0.0.1', 36496)\n",
            "\u001b[94mReceived training result: b'3;0.76367;0.47437' \u001b[0m\n",
            "Time per iteration 16.80721131960551, memory OrderedDict([('active.all.allocated', 1075722), ('active.all.current', 7), ('active.all.freed', 1075715), ('active.all.peak', 197), ('active.large_pool.allocated', 2371), ('active.large_pool.current', 3), ('active.large_pool.freed', 2368), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1073351), ('active.small_pool.current', 4), ('active.small_pool.freed', 1073347), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 861827954176), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 861822820352), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 803448487424), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 803444817920), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 58379466752), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 58378002432), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 861827954176), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 861823432192), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 803448487424), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 803444817920), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 58379466752), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 58378614272), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1075722), ('allocation.all.current', 6), ('allocation.all.freed', 1075716), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 2371), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 2368), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1073351), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1073348), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 457065), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 457059), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 785), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 783), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 456280), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 456276), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 70663979008), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 70643947008), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 2191021568), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 2173719552), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 68472957440), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 68470227456), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   1, iteration:   4:   Loss at step 1: 0.533203125, mean for epoch: 0.533203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 2: 0.61376953125, mean for epoch: 0.573486328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 3: 0.9677734375, mean for epoch: 0.7049153645833334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 4: 0.52978515625, mean for epoch: 0.6611328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 5: 0.485107421875, mean for epoch: 0.625927734375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 6: 0.47607421875, mean for epoch: 0.6009521484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 7: 1.95703125, mean for epoch: 0.794677734375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 8: 0.499267578125, mean for epoch: 0.75775146484375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 9: 1.0693359375, mean for epoch: 0.7923719618055556, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:28,458] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:28,458] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=85.28379742254921, CurrSamplesPerSec=84.37376033473477, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 10: 0.5478515625, mean for epoch: 0.767919921875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 11: 0.56396484375, mean for epoch: 0.7493785511363636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 12: 2.3359375, mean for epoch: 0.881591796875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 13: 0.69677734375, mean for epoch: 0.8673753004807693, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 14: 0.52294921875, mean for epoch: 0.8427734375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 15: 0.54443359375, mean for epoch: 0.8228841145833333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 16: 1.322265625, mean for epoch: 0.854095458984375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 17: 0.6767578125, mean for epoch: 0.8436638327205882, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 18: 0.62109375, mean for epoch: 0.831298828125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 19: 0.49658203125, mean for epoch: 0.8136821546052632, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:29,073] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:29,073] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=85.28009470007484, CurrSamplesPerSec=85.70088187457603, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 20: 0.607421875, mean for epoch: 0.803369140625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 21: 1.783203125, mean for epoch: 0.8500279017857143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 22: 0.61083984375, mean for epoch: 0.8391557173295454, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 23: 0.7236328125, mean for epoch: 0.8341329823369565, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 24: 1.6826171875, mean for epoch: 0.8694864908854166, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 25: 0.4658203125, mean for epoch: 0.85333984375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 26: 0.447998046875, mean for epoch: 0.8377497746394231, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 27: 1.99609375, mean for epoch: 0.8806514033564815, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 28: 0.44384765625, mean for epoch: 0.86505126953125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 29: 0.4892578125, mean for epoch: 0.8520928744612069, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:29,693] [INFO] [logging.py:68:log_dist] [Rank 0] step=830, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:29,693] [INFO] [timer.py:207:stop] 0/830, RunningAvgSamplesPerSec=85.26666092932705, CurrSamplesPerSec=80.93455851989641, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 30: 1.1357421875, mean for epoch: 0.8615478515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 31: 0.6025390625, mean for epoch: 0.8531927293346774, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 32: 1.2060546875, mean for epoch: 0.8642196655273438, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 33: 0.7626953125, mean for epoch: 0.8611431699810606, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 34: 0.53515625, mean for epoch: 0.8515553193933824, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 35: 0.44189453125, mean for epoch: 0.8398507254464286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 36: 0.658203125, mean for epoch: 0.8348049587673612, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 37: 0.471923828125, mean for epoch: 0.8249973606418919, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 38: 0.442626953125, mean for epoch: 0.8149349814967105, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 39: 0.72607421875, mean for epoch: 0.8126565004006411, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:30,302] [INFO] [logging.py:68:log_dist] [Rank 0] step=840, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:30,302] [INFO] [timer.py:207:stop] 0/840, RunningAvgSamplesPerSec=85.26677249033256, CurrSamplesPerSec=84.71835310086287, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 40: 0.4677734375, mean for epoch: 0.804034423828125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 41: 0.488037109375, mean for epoch: 0.7963271722560976, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 42: 0.70556640625, mean for epoch: 0.7941662016369048, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 43: 0.5673828125, mean for epoch: 0.7888921693313954, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 44: 1.59765625, mean for epoch: 0.8072731711647727, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 45: 0.5361328125, mean for epoch: 0.8012478298611111, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 46: 0.75732421875, mean for epoch: 0.80029296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 47: 0.95068359375, mean for epoch: 0.8034927692819149, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 48: 0.8388671875, mean for epoch: 0.804229736328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 49: 0.53271484375, mean for epoch: 0.7986886160714286, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:30,911] [INFO] [logging.py:68:log_dist] [Rank 0] step=850, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:30,911] [INFO] [timer.py:207:stop] 0/850, RunningAvgSamplesPerSec=85.2707486497281, CurrSamplesPerSec=85.91258608046603, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 50: 0.509765625, mean for epoch: 0.79291015625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 51: 1.7548828125, mean for epoch: 0.8117723651960784, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 52: 0.65869140625, mean for epoch: 0.8088285006009616, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 53: 1.7109375, mean for epoch: 0.8258494251179245, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 54: 1.1162109375, mean for epoch: 0.8312264901620371, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 55: 0.6962890625, mean for epoch: 0.8287730823863636, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 56: 0.4755859375, mean for epoch: 0.8224661690848214, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 57: 0.55908203125, mean for epoch: 0.8178453947368421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 58: 0.74365234375, mean for epoch: 0.8165662042025862, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 59: 0.6982421875, mean for epoch: 0.8145607123940678, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:31,528] [INFO] [logging.py:68:log_dist] [Rank 0] step=860, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:31,528] [INFO] [timer.py:207:stop] 0/860, RunningAvgSamplesPerSec=85.25740582437798, CurrSamplesPerSec=81.07912083663567, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 60: 0.52099609375, mean for epoch: 0.80966796875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 61: 1.0888671875, mean for epoch: 0.8142450051229508, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 62: 0.54541015625, mean for epoch: 0.8099089591733871, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 63: 1.3681640625, mean for epoch: 0.8187701512896826, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 64: 0.49755859375, mean for epoch: 0.813751220703125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 65: 0.442138671875, mean for epoch: 0.8080341045673077, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 66: 1.3310546875, mean for epoch: 0.8159586588541666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 67: 0.654296875, mean for epoch: 0.813545796408582, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 68: 1.3349609375, mean for epoch: 0.8212136661305147, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 69: 0.48828125, mean for epoch: 0.8163885586503623, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:32,139] [INFO] [logging.py:68:log_dist] [Rank 0] step=870, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:32,139] [INFO] [timer.py:207:stop] 0/870, RunningAvgSamplesPerSec=85.25538680444653, CurrSamplesPerSec=83.59250312901091, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 70: 1.6708984375, mean for epoch: 0.8285958426339286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 71: 0.425048828125, mean for epoch: 0.8229120818661971, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 72: 0.98779296875, mean for epoch: 0.8252020941840278, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 73: 0.744140625, mean for epoch: 0.824091663099315, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 74: 0.499755859375, mean for epoch: 0.8197087468327703, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 75: 0.69580078125, mean for epoch: 0.818056640625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 76: 0.45947265625, mean for epoch: 0.8133384303042763, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 77: 0.51904296875, mean for epoch: 0.809516411323052, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 78: 1.73046875, mean for epoch: 0.8213234925881411, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 79: 0.54150390625, mean for epoch: 0.8177814725079114, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:32,750] [INFO] [logging.py:68:log_dist] [Rank 0] step=880, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:32,750] [INFO] [timer.py:207:stop] 0/880, RunningAvgSamplesPerSec=85.25102108765863, CurrSamplesPerSec=87.2664325305015, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 80: 1.1591796875, mean for epoch: 0.8220489501953125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 81: 0.8173828125, mean for epoch: 0.8219913435570988, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 82: 0.71533203125, mean for epoch: 0.8206906202362805, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 83: 0.59326171875, mean for epoch: 0.8179505129894579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 84: 1.16796875, mean for epoch: 0.8221173967633929, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 85: 0.65380859375, mean for epoch: 0.8201372931985295, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 86: 0.45068359375, mean for epoch: 0.8158413199491279, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 87: 0.49951171875, mean for epoch: 0.8122053475215517, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 88: 0.57177734375, mean for epoch: 0.8094732111150568, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 89: 0.48388671875, mean for epoch: 0.8058149359199438, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:33,354] [INFO] [logging.py:68:log_dist] [Rank 0] step=890, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:33,354] [INFO] [timer.py:207:stop] 0/890, RunningAvgSamplesPerSec=85.25926417256031, CurrSamplesPerSec=86.53759181315507, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 90: 0.50048828125, mean for epoch: 0.8024224175347222, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 91: 1.08203125, mean for epoch: 0.8054950420673077, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 92: 0.57080078125, mean for epoch: 0.8029440174932065, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 93: 0.480712890625, mean for epoch: 0.7994791666666666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 94: 0.5166015625, mean for epoch: 0.7964698304521277, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 95: 0.5048828125, mean for epoch: 0.7934004934210527, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 96: 0.5419921875, mean for epoch: 0.7907816569010416, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 97: 0.77880859375, mean for epoch: 0.7906582232603093, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 98: 0.53076171875, mean for epoch: 0.7880062181122449, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 99: 0.5283203125, mean for epoch: 0.7853831281565656, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:33,970] [INFO] [logging.py:68:log_dist] [Rank 0] step=900, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:33,971] [INFO] [timer.py:207:stop] 0/900, RunningAvgSamplesPerSec=85.24834166474629, CurrSamplesPerSec=83.23286844841682, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 100: 0.73828125, mean for epoch: 0.784912109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 101: 0.55615234375, mean for epoch: 0.782647161200495, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 102: 1.677734375, mean for epoch: 0.7914225260416666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 103: 0.51416015625, mean for epoch: 0.7887306583737864, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 104: 0.6162109375, mean for epoch: 0.7870718149038461, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 105: 0.54736328125, mean for epoch: 0.7847888764880953, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 106: 0.5517578125, mean for epoch: 0.7825904702240566, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 107: 0.783203125, mean for epoch: 0.7825961959696262, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 108: 0.5625, mean for epoch: 0.7805582682291666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 109: 0.533203125, mean for epoch: 0.7782889549885321, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:34,581] [INFO] [logging.py:68:log_dist] [Rank 0] step=910, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:34,582] [INFO] [timer.py:207:stop] 0/910, RunningAvgSamplesPerSec=85.2516957427787, CurrSamplesPerSec=88.21941780245668, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 110: 0.51416015625, mean for epoch: 0.7758877840909091, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 111: 0.5869140625, mean for epoch: 0.7741853181306306, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 112: 1.720703125, mean for epoch: 0.7826363699776786, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 113: 0.85595703125, mean for epoch: 0.7832852253871682, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 114: 0.5419921875, mean for epoch: 0.7811686197916666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 115: 0.72265625, mean for epoch: 0.780659816576087, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 116: 1.7919921875, mean for epoch: 0.7893781990840517, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 117: 0.52734375, mean for epoch: 0.7871385884081197, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 118: 0.51904296875, mean for epoch: 0.784866591631356, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 119: 0.404296875, mean for epoch: 0.7816685267857143, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:35,203] [INFO] [logging.py:68:log_dist] [Rank 0] step=920, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:35,203] [INFO] [timer.py:207:stop] 0/920, RunningAvgSamplesPerSec=85.23313340851189, CurrSamplesPerSec=84.17800933637857, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 120: 0.490966796875, mean for epoch: 0.7792460123697916, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 121: 0.55029296875, mean for epoch: 0.7773538384555785, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 122: 0.470458984375, mean for epoch: 0.7748383068647541, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 123: 0.70751953125, mean for epoch: 0.774290999745935, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 124: 0.552734375, mean for epoch: 0.7725042527721774, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 125: 0.478759765625, mean for epoch: 0.770154296875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 126: 0.7666015625, mean for epoch: 0.7701261005704365, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 127: 0.47216796875, mean for epoch: 0.7677799735482284, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 128: 0.5283203125, mean for epoch: 0.7659091949462891, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 129: 1.103515625, mean for epoch: 0.7685262990552325, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:35,812] [INFO] [logging.py:68:log_dist] [Rank 0] step=930, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:35,813] [INFO] [timer.py:207:stop] 0/930, RunningAvgSamplesPerSec=85.23235816143676, CurrSamplesPerSec=87.31548290664124, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 130: 0.607421875, mean for epoch: 0.7672870342548077, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 131: 0.8095703125, mean for epoch: 0.7676098073711832, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 132: 2.126953125, mean for epoch: 0.7779078628077651, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 133: 0.99560546875, mean for epoch: 0.7795446869125939, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 134: 0.5673828125, mean for epoch: 0.7779613893423507, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 135: 0.7978515625, mean for epoch: 0.7781087239583333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 136: 0.642578125, mean for epoch: 0.7771121754365808, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 137: 0.52685546875, mean for epoch: 0.7752854841468978, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 138: 0.55615234375, mean for epoch: 0.773697562839674, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 139: 0.476318359375, mean for epoch: 0.7715581441097122, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:36,421] [INFO] [logging.py:68:log_dist] [Rank 0] step=940, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:36,421] [INFO] [timer.py:207:stop] 0/940, RunningAvgSamplesPerSec=85.23463181273264, CurrSamplesPerSec=86.16886558713436, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 140: 2.484375, mean for epoch: 0.7837925502232143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 141: 0.54638671875, mean for epoch: 0.7821088209219859, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 142: 0.466796875, mean for epoch: 0.7798883142605634, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 143: 0.487548828125, mean for epoch: 0.7778439821896853, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 144: 0.541015625, mean for epoch: 0.7761993408203125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 145: 0.7373046875, mean for epoch: 0.7759311018318965, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 146: 0.60009765625, mean for epoch: 0.7747267631635274, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 147: 0.56005859375, mean for epoch: 0.7732664354804422, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 148: 0.58203125, mean for epoch: 0.7719743058488175, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 149: 0.4462890625, mean for epoch: 0.7697884988464765, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:37,027] [INFO] [logging.py:68:log_dist] [Rank 0] step=950, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:37,027] [INFO] [timer.py:207:stop] 0/950, RunningAvgSamplesPerSec=85.23725046448854, CurrSamplesPerSec=82.73539611088975, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 150: 0.499755859375, mean for epoch: 0.76798828125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 151: 0.52587890625, mean for epoch: 0.7663849079056292, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 152: 0.458251953125, mean for epoch: 0.7643577174136513, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 153: 1.0048828125, mean for epoch: 0.7659297768586601, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 154: 1.302734375, mean for epoch: 0.769415521002435, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 155: 0.7900390625, mean for epoch: 0.769548576108871, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 156: 0.7802734375, mean for epoch: 0.7696173252203525, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 157: 0.51318359375, mean for epoch: 0.7679839893511147, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 158: 1.0712890625, mean for epoch: 0.7699036417128164, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 159: 1.0361328125, mean for epoch: 0.7715780390133647, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:37,631] [INFO] [logging.py:68:log_dist] [Rank 0] step=960, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:37,632] [INFO] [timer.py:207:stop] 0/960, RunningAvgSamplesPerSec=85.2428985119802, CurrSamplesPerSec=86.92281548166754, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 160: 0.52294921875, mean for epoch: 0.7700241088867188, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 161: 1.033203125, mean for epoch: 0.7716587611607143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 162: 0.55810546875, mean for epoch: 0.7703405309606481, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 163: 0.74951171875, mean for epoch: 0.7702127468366564, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 164: 0.49853515625, mean for epoch: 0.7685561761623476, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 165: 0.441162109375, mean for epoch: 0.7665719696969697, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 166: 0.47509765625, mean for epoch: 0.7648161003388554, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 167: 0.4619140625, mean for epoch: 0.7630023156811377, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 168: 0.460693359375, mean for epoch: 0.7612028576078869, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 169: 0.53466796875, mean for epoch: 0.7598624144785503, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:38,234] [INFO] [logging.py:68:log_dist] [Rank 0] step=970, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:38,234] [INFO] [timer.py:207:stop] 0/970, RunningAvgSamplesPerSec=85.25624401888184, CurrSamplesPerSec=87.83220532064598, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 170: 0.449462890625, mean for epoch: 0.7580365349264706, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 171: 0.498779296875, mean for epoch: 0.7565204107273392, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 172: 0.572265625, mean for epoch: 0.7554491619731105, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 173: 0.5830078125, mean for epoch: 0.7544523911669075, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 174: 0.46533203125, mean for epoch: 0.7527907799030172, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 175: 0.50244140625, mean for epoch: 0.7513602120535714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 176: 0.58935546875, mean for epoch: 0.7504397305575284, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 177: 1.767578125, mean for epoch: 0.7561862751588984, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 178: 0.560546875, mean for epoch: 0.7550871774051966, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 179: 0.5732421875, mean for epoch: 0.7540712836068436, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:38,826] [INFO] [logging.py:68:log_dist] [Rank 0] step=980, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:38,826] [INFO] [timer.py:207:stop] 0/980, RunningAvgSamplesPerSec=85.28226402293815, CurrSamplesPerSec=88.61605030085863, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 180: 0.73974609375, mean for epoch: 0.75399169921875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 181: 0.59765625, mean for epoch: 0.7531279674551105, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 182: 0.48193359375, mean for epoch: 0.7516378884787088, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 183: 0.4892578125, mean for epoch: 0.7502041175717213, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 184: 0.658203125, mean for epoch: 0.7497041121773098, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 185: 1.7294921875, mean for epoch: 0.7550002639358108, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 186: 0.70458984375, mean for epoch: 0.754729240171371, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 187: 0.583984375, mean for epoch: 0.7538161660260695, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 188: 0.44970703125, mean for epoch: 0.7521985642453457, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 189: 0.75537109375, mean for epoch: 0.7522153501157407, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:39,425] [INFO] [logging.py:68:log_dist] [Rank 0] step=990, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:39,425] [INFO] [timer.py:207:stop] 0/990, RunningAvgSamplesPerSec=85.29448603529764, CurrSamplesPerSec=85.14624441737718, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 190: 1.7646484375, mean for epoch: 0.7575439453125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 191: 0.4462890625, mean for epoch: 0.7559143385962042, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 192: 0.460693359375, mean for epoch: 0.7543767293294271, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 193: 0.80126953125, mean for epoch: 0.7546196972150259, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 194: 1.1982421875, mean for epoch: 0.7569064110824743, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 195: 1.6669921875, mean for epoch: 0.7615735176282051, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 196: 0.5146484375, mean for epoch: 0.7603136957908163, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 197: 1.0986328125, mean for epoch: 0.762031051713198, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 198: 0.6669921875, mean for epoch: 0.7615510574494949, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 199: 0.798828125, mean for epoch: 0.761738379396985, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:40,034] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:40,034] [INFO] [timer.py:207:stop] 0/1000, RunningAvgSamplesPerSec=85.2941972879092, CurrSamplesPerSec=84.32694124884898, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 200: 0.476806640625, mean for epoch: 0.760313720703125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 201: 0.5146484375, mean for epoch: 0.759091505363806, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 202: 0.466796875, mean for epoch: 0.757644502243193, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 203: 0.99267578125, mean for epoch: 0.7588022917949507, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 204: 0.456298828125, mean for epoch: 0.7573194316789216, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 205: 0.5009765625, mean for epoch: 0.7560689786585366, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 206: 0.5009765625, mean for epoch: 0.7548306659587378, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 207: 2.037109375, mean for epoch: 0.7610252490942029, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 208: 1.732421875, mean for epoch: 0.7656954251802884, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 209: 0.466552734375, mean for epoch: 0.7642641204395934, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:40,659] [INFO] [logging.py:68:log_dist] [Rank 0] step=1010, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:40,660] [INFO] [timer.py:207:stop] 0/1010, RunningAvgSamplesPerSec=85.27378359409455, CurrSamplesPerSec=84.25951818459411, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 210: 0.449951171875, mean for epoch: 0.7627673921130952, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 211: 0.5361328125, mean for epoch: 0.7616932945793838, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 212: 0.5146484375, mean for epoch: 0.7605279886497641, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 213: 0.55322265625, mean for epoch: 0.7595547241784038, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 214: 0.52490234375, mean for epoch: 0.7584582177278038, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 215: 0.7705078125, mean for epoch: 0.7585142623546511, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 216: 1.55078125, mean for epoch: 0.7621821650752315, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 217: 0.51318359375, mean for epoch: 0.7610347062211982, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 218: 0.54736328125, mean for epoch: 0.7600545620699541, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:41,217] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
            " Run   1, iteration:   4:   Loss at step 219: 0.460205078125, mean for epoch: 0.758685386344178, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:41,267] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            "[2022-10-31 19:01:41,267] [INFO] [logging.py:68:log_dist] [Rank 0] step=1020, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:41,268] [INFO] [timer.py:207:stop] 0/1020, RunningAvgSamplesPerSec=85.28050165002475, CurrSamplesPerSec=106.5431120323518, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 220: 0.470703125, mean for epoch: 0.7573763760653409, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 221: 0.97021484375, mean for epoch: 0.7583394460548643, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 222: 0.52490234375, mean for epoch: 0.7572879275760135, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 223: 0.609375, mean for epoch: 0.756624640905269, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 224: 0.58203125, mean for epoch: 0.755845206124442, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 225: 0.5849609375, mean for epoch: 0.7550857204861111, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 226: 0.481689453125, mean for epoch: 0.753876002488938, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 227: 0.4814453125, mean for epoch: 0.7526758672907489, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 228: 1.6513671875, mean for epoch: 0.7566174958881579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 229: 0.464111328125, mean for epoch: 0.7553401763782751, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:41,897] [INFO] [logging.py:68:log_dist] [Rank 0] step=1030, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:41,898] [INFO] [timer.py:207:stop] 0/1030, RunningAvgSamplesPerSec=85.25763651748741, CurrSamplesPerSec=84.32524588054588, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 230: 0.5693359375, mean for epoch: 0.7545314622961956, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 231: 1.02734375, mean for epoch: 0.755712467870671, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 232: 0.451416015625, mean for epoch: 0.754400845231681, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 233: 1.07421875, mean for epoch: 0.7557734542650214, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 234: 0.4990234375, mean for epoch: 0.7546762319711539, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 235: 0.4404296875, mean for epoch: 0.7533390126329788, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 236: 1.5966796875, mean for epoch: 0.756912490068856, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 237: 0.541015625, mean for epoch: 0.7560015328322784, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 238: 0.58154296875, mean for epoch: 0.7552685136554622, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 239: 0.48388671875, mean for epoch: 0.7541330249738494, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:42,524] [INFO] [logging.py:68:log_dist] [Rank 0] step=1040, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:42,524] [INFO] [timer.py:207:stop] 0/1040, RunningAvgSamplesPerSec=85.2397052424219, CurrSamplesPerSec=82.1394663867521, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 240: 0.55712890625, mean for epoch: 0.7533121744791667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 241: 0.7138671875, mean for epoch: 0.7531485023340249, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 242: 0.79248046875, mean for epoch: 0.7533110311208677, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 243: 0.58837890625, mean for epoch: 0.7526322980967078, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 244: 0.49755859375, mean for epoch: 0.7515869140625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 245: 0.51318359375, mean for epoch: 0.7506138392857142, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 246: 0.60595703125, mean for epoch: 0.750025803480691, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 247: 0.6748046875, mean for epoch: 0.7497212645495951, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 248: 0.47314453125, mean for epoch: 0.7486060357862904, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 249: 0.50537109375, mean for epoch: 0.7476291886295181, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:43,150] [INFO] [logging.py:68:log_dist] [Rank 0] step=1050, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:43,151] [INFO] [timer.py:207:stop] 0/1050, RunningAvgSamplesPerSec=85.21961375512232, CurrSamplesPerSec=81.29567462378763, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 250: 0.97998046875, mean for epoch: 0.74855859375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 251: 0.56787109375, mean for epoch: 0.7478387232320717, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 252: 0.44384765625, mean for epoch: 0.7466324094742064, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 253: 1.3251953125, mean for epoch: 0.748919219367589, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 254: 0.443603515625, mean for epoch: 0.7477171890378937, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 255: 0.53857421875, mean for epoch: 0.7468970205269608, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 256: 0.410888671875, mean for epoch: 0.7455844879150391, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 257: 0.490966796875, mean for epoch: 0.7445937575997081, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 258: 1.6884765625, mean for epoch: 0.7482522180838178, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 259: 1.880859375, mean for epoch: 0.7526252186896718, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:43,775] [INFO] [logging.py:68:log_dist] [Rank 0] step=1060, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:43,775] [INFO] [timer.py:207:stop] 0/1060, RunningAvgSamplesPerSec=85.20101840167462, CurrSamplesPerSec=84.44918718011702, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   4:   Loss at step 260: 0.634765625, mean for epoch: 0.7521719125600962, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 261: 0.6591796875, mean for epoch: 0.7518156205100575, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 262: 0.78515625, mean for epoch: 0.7519428748210878, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 263: 0.489501953125, mean for epoch: 0.7509450005941065, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 264: 0.70458984375, mean for epoch: 0.7507694128787878, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 265: 0.6259765625, mean for epoch: 0.7502984964622641, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 266: 0.76025390625, mean for epoch: 0.7503359228148496, mem_alloc: 1023816704\n",
            " Run   1, iteration:   4:   Loss at step 267: 0.53125, mean for epoch: 0.7495153762874532, mem_alloc: 1023816704\n",
            "Loss after iteration 4 ; MSE: 0.74951171875, MAE: 0.46630859375\n",
            "Connected by ('127.0.0.1', 44602)\n",
            "\u001b[94mReceived training result: b'4;0.74951;0.46631' \u001b[0m\n",
            "Time per iteration 16.773401618003845, memory OrderedDict([('active.all.allocated', 1436244), ('active.all.current', 7), ('active.all.freed', 1436237), ('active.all.peak', 197), ('active.large_pool.allocated', 3168), ('active.large_pool.current', 3), ('active.large_pool.freed', 3165), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1433076), ('active.small_pool.current', 4), ('active.small_pool.freed', 1433072), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 1149126733312), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 1149121599488), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 1071274104832), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 1071270435328), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 77852628480), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 77851164160), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 1149126733312), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 1149122211328), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 1071274104832), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 1071270435328), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 77852628480), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 77851776000), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1436244), ('allocation.all.current', 6), ('allocation.all.freed', 1436238), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 3168), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 3165), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1433076), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1433073), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 610340), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 610334), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 1050), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 1048), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 609290), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 609286), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 94235367936), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 94215335936), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 2925457408), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 2908155392), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 91309910528), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 91307180544), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   1, iteration:   5:   Loss at step 1: 0.7890625, mean for epoch: 0.7890625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 2: 0.4697265625, mean for epoch: 0.62939453125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:44,697] [INFO] [logging.py:68:log_dist] [Rank 0] step=1070, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:44,697] [INFO] [timer.py:207:stop] 0/1070, RunningAvgSamplesPerSec=85.17732874577561, CurrSamplesPerSec=85.79659865893721, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 3: 0.58935546875, mean for epoch: 0.6160481770833334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 4: 0.52978515625, mean for epoch: 0.594482421875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 5: 0.480712890625, mean for epoch: 0.571728515625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 6: 0.509765625, mean for epoch: 0.5614013671875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 7: 0.7783203125, mean for epoch: 0.5923897879464286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 8: 0.59130859375, mean for epoch: 0.592254638671875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 9: 0.73388671875, mean for epoch: 0.6079915364583334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 10: 0.61328125, mean for epoch: 0.6085205078125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 11: 0.45947265625, mean for epoch: 0.594970703125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 12: 1.1337890625, mean for epoch: 0.6398722330729166, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:45,307] [INFO] [logging.py:68:log_dist] [Rank 0] step=1080, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:45,308] [INFO] [timer.py:207:stop] 0/1080, RunningAvgSamplesPerSec=85.17348304298295, CurrSamplesPerSec=83.69291674814528, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 13: 0.646484375, mean for epoch: 0.640380859375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 14: 0.5458984375, mean for epoch: 0.6336321149553571, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 15: 0.428955078125, mean for epoch: 0.6199869791666667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 16: 0.48681640625, mean for epoch: 0.611663818359375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 17: 0.43359375, mean for epoch: 0.6011891084558824, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 18: 0.54248046875, mean for epoch: 0.5979275173611112, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 19: 0.6103515625, mean for epoch: 0.5985814144736842, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 20: 0.82421875, mean for epoch: 0.60986328125, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 21: 0.86279296875, mean for epoch: 0.6219075520833334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 22: 0.474853515625, mean for epoch: 0.6152232776988636, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:45,919] [INFO] [logging.py:68:log_dist] [Rank 0] step=1090, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:45,920] [INFO] [timer.py:207:stop] 0/1090, RunningAvgSamplesPerSec=85.17472441707844, CurrSamplesPerSec=87.09428508540601, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 23: 0.6953125, mean for epoch: 0.6187054177989131, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 24: 0.463623046875, mean for epoch: 0.61224365234375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 25: 0.475830078125, mean for epoch: 0.606787109375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 26: 0.53759765625, mean for epoch: 0.6041259765625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 27: 0.4130859375, mean for epoch: 0.5970504195601852, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 28: 0.54931640625, mean for epoch: 0.5953456333705357, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 29: 0.54931640625, mean for epoch: 0.5937584186422413, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 30: 0.4755859375, mean for epoch: 0.5898193359375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 31: 0.451171875, mean for epoch: 0.5853468371975806, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 32: 3.48046875, mean for epoch: 0.6758193969726562, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:46,531] [INFO] [logging.py:68:log_dist] [Rank 0] step=1100, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:46,531] [INFO] [timer.py:207:stop] 0/1100, RunningAvgSamplesPerSec=85.17520659669488, CurrSamplesPerSec=83.98518251536814, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 33: 0.51904296875, mean for epoch: 0.6710685961174242, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 34: 0.490478515625, mean for epoch: 0.6657571231617647, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 35: 1.0244140625, mean for epoch: 0.6760044642857143, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 36: 0.54541015625, mean for epoch: 0.6723768446180556, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 37: 0.533203125, mean for epoch: 0.6686153927364865, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 38: 0.587890625, mean for epoch: 0.666491056743421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 39: 0.7783203125, mean for epoch: 0.6693584735576923, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 40: 0.78857421875, mean for epoch: 0.6723388671875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 41: 0.73291015625, mean for epoch: 0.6738162157012195, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 42: 0.46337890625, mean for epoch: 0.6688058035714286, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:47,133] [INFO] [logging.py:68:log_dist] [Rank 0] step=1110, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:47,133] [INFO] [timer.py:207:stop] 0/1110, RunningAvgSamplesPerSec=85.18655142549945, CurrSamplesPerSec=86.95561314398259, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 43: 0.5380859375, mean for epoch: 0.6657658066860465, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 44: 0.68408203125, mean for epoch: 0.6661820845170454, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 45: 0.53271484375, mean for epoch: 0.6632161458333333, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 46: 0.476318359375, mean for epoch: 0.6591531504755435, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 47: 0.53857421875, mean for epoch: 0.6565876412898937, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 48: 0.450927734375, mean for epoch: 0.6523030598958334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 49: 0.442626953125, mean for epoch: 0.6480239556760204, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 50: 0.67724609375, mean for epoch: 0.6486083984375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 51: 0.5146484375, mean for epoch: 0.6459817325367647, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 52: 0.44970703125, mean for epoch: 0.6422072190504807, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:47,745] [INFO] [logging.py:68:log_dist] [Rank 0] step=1120, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:47,745] [INFO] [timer.py:207:stop] 0/1120, RunningAvgSamplesPerSec=85.18713751272725, CurrSamplesPerSec=82.89236631264403, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 53: 0.5517578125, mean for epoch: 0.6405006264740566, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 54: 0.58935546875, mean for epoch: 0.6395534939236112, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 55: 0.50146484375, mean for epoch: 0.6370427911931819, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 56: 0.468017578125, mean for epoch: 0.6340244838169643, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 57: 0.398193359375, mean for epoch: 0.6298870956688597, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 58: 0.434326171875, mean for epoch: 0.6265153556034483, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 59: 0.498046875, mean for epoch: 0.6243379237288136, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 60: 0.466552734375, mean for epoch: 0.6217081705729167, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 61: 1.1279296875, mean for epoch: 0.6300068839651639, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 62: 0.4541015625, mean for epoch: 0.6271697013608871, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:48,352] [INFO] [logging.py:68:log_dist] [Rank 0] step=1130, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:48,353] [INFO] [timer.py:207:stop] 0/1130, RunningAvgSamplesPerSec=85.19041289033143, CurrSamplesPerSec=85.11928824813904, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 63: 4.22265625, mean for epoch: 0.6842409164186508, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 64: 1.912109375, mean for epoch: 0.7034263610839844, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 65: 0.51513671875, mean for epoch: 0.7005295973557693, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 66: 0.81982421875, mean for epoch: 0.7023370916193182, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 67: 0.447509765625, mean for epoch: 0.6985336986940298, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 68: 0.57568359375, mean for epoch: 0.6967270795036765, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 69: 0.416748046875, mean for epoch: 0.6926694123641305, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 70: 0.56787109375, mean for epoch: 0.6908865792410714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 71: 0.83740234375, mean for epoch: 0.6929501815580986, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 72: 0.494873046875, mean for epoch: 0.6901991102430556, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:48,965] [INFO] [logging.py:68:log_dist] [Rank 0] step=1140, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:48,965] [INFO] [timer.py:207:stop] 0/1140, RunningAvgSamplesPerSec=85.18873280292054, CurrSamplesPerSec=84.50056813145191, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 73: 0.73583984375, mean for epoch: 0.690824325770548, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 74: 1.6767578125, mean for epoch: 0.7041477512668919, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 75: 0.62353515625, mean for epoch: 0.7030729166666667, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 76: 0.437744140625, mean for epoch: 0.6995817485608553, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 77: 0.51025390625, mean for epoch: 0.697122945413961, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 78: 0.80810546875, mean for epoch: 0.6985457982772436, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 79: 0.61328125, mean for epoch: 0.6974665001977848, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 80: 1.3056640625, mean for epoch: 0.7050689697265625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 81: 0.54443359375, mean for epoch: 0.7030858169367284, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 82: 0.61376953125, mean for epoch: 0.7019965939405488, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:49,585] [INFO] [logging.py:68:log_dist] [Rank 0] step=1150, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:49,585] [INFO] [timer.py:207:stop] 0/1150, RunningAvgSamplesPerSec=85.1796634822153, CurrSamplesPerSec=86.50724966484479, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 83: 0.467041015625, mean for epoch: 0.6991658038403614, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 84: 1.7138671875, mean for epoch: 0.7112455822172619, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 85: 0.509765625, mean for epoch: 0.7088752297794118, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 86: 0.4912109375, mean for epoch: 0.7063442496366279, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 87: 0.482421875, mean for epoch: 0.7037704292385057, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 88: 0.607421875, mean for epoch: 0.7026755593039773, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 89: 0.419677734375, mean for epoch: 0.6994958084620787, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 90: 0.45068359375, mean for epoch: 0.6967312282986111, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 91: 0.78662109375, mean for epoch: 0.6977190290178571, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 92: 0.7216796875, mean for epoch: 0.6979794709578805, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:50,216] [INFO] [logging.py:68:log_dist] [Rank 0] step=1160, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:50,216] [INFO] [timer.py:207:stop] 0/1160, RunningAvgSamplesPerSec=85.15610909454568, CurrSamplesPerSec=82.64377871830642, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 93: 1.0498046875, mean for epoch: 0.7017625378024194, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 94: 0.47705078125, mean for epoch: 0.6993719872007979, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 95: 0.4736328125, mean for epoch: 0.6969957853618421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 96: 1.5361328125, mean for epoch: 0.7057367960611979, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 97: 0.4482421875, mean for epoch: 0.7030822124677835, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 98: 0.61767578125, mean for epoch: 0.7022107182716837, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 99: 0.6181640625, mean for epoch: 0.7013617621527778, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 100: 0.5791015625, mean for epoch: 0.70013916015625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 101: 0.63427734375, mean for epoch: 0.6994870629641089, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 102: 0.489013671875, mean for epoch: 0.6974235983455882, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:50,826] [INFO] [logging.py:68:log_dist] [Rank 0] step=1170, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:50,827] [INFO] [timer.py:207:stop] 0/1170, RunningAvgSamplesPerSec=85.15729201530355, CurrSamplesPerSec=87.24900567472666, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 103: 0.74169921875, mean for epoch: 0.6978534587378641, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 104: 0.53515625, mean for epoch: 0.6962890625, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 105: 0.6328125, mean for epoch: 0.6956845238095238, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 106: 1.09375, mean for epoch: 0.699439858490566, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 107: 1.705078125, mean for epoch: 0.7088383469626168, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 108: 1.58984375, mean for epoch: 0.7169958043981481, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 109: 0.52978515625, mean for epoch: 0.715278275516055, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 110: 0.486328125, mean for epoch: 0.7131969105113637, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 111: 0.50537109375, mean for epoch: 0.7113246058558559, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 112: 0.56982421875, mean for epoch: 0.7100612095424107, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:51,442] [INFO] [logging.py:68:log_dist] [Rank 0] step=1180, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:51,442] [INFO] [timer.py:207:stop] 0/1180, RunningAvgSamplesPerSec=85.15602730496968, CurrSamplesPerSec=82.52897355879911, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 113: 1.220703125, mean for epoch: 0.7145801645464602, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 114: 0.470947265625, mean for epoch: 0.7124430338541666, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 115: 0.52783203125, mean for epoch: 0.7108377207880435, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 116: 0.55517578125, mean for epoch: 0.7094958075161638, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 117: 0.72607421875, mean for epoch: 0.7096375033386753, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 118: 0.45751953125, mean for epoch: 0.7075009103548728, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 119: 2.611328125, mean for epoch: 0.7234994583771008, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 120: 0.947265625, mean for epoch: 0.7253641764322917, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 121: 0.51708984375, mean for epoch: 0.7236429009555785, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 122: 0.73193359375, mean for epoch: 0.7237108574538934, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:52,060] [INFO] [logging.py:68:log_dist] [Rank 0] step=1190, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:52,060] [INFO] [timer.py:207:stop] 0/1190, RunningAvgSamplesPerSec=85.1483602903021, CurrSamplesPerSec=84.58202086769943, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 123: 0.479736328125, mean for epoch: 0.7217273246951219, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 124: 0.5556640625, mean for epoch: 0.7203881048387096, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 125: 0.73583984375, mean for epoch: 0.72051171875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 126: 1.7958984375, mean for epoch: 0.7290465339781746, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 127: 0.515625, mean for epoch: 0.7273660494586615, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 128: 0.67431640625, mean for epoch: 0.7269515991210938, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 129: 0.52001953125, mean for epoch: 0.7253474745639535, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 130: 0.51904296875, mean for epoch: 0.7237605168269231, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 131: 0.60791015625, mean for epoch: 0.7228761629293893, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 132: 0.7939453125, mean for epoch: 0.7234145655776515, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:52,676] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:52,677] [INFO] [timer.py:207:stop] 0/1200, RunningAvgSamplesPerSec=85.14125656795352, CurrSamplesPerSec=86.77068464017808, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 133: 0.44189453125, mean for epoch: 0.7212978735902256, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 134: 0.56982421875, mean for epoch: 0.7201674731809702, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 135: 0.75439453125, mean for epoch: 0.7204210069444444, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 136: 0.7646484375, mean for epoch: 0.7207462086397058, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 137: 1.66015625, mean for epoch: 0.7276032162408759, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 138: 0.6845703125, mean for epoch: 0.7272913836050725, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 139: 1.94921875, mean for epoch: 0.7360822279676259, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 140: 0.52001953125, mean for epoch: 0.7345389229910714, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 141: 0.50439453125, mean for epoch: 0.7329066932624113, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 142: 0.49658203125, mean for epoch: 0.7312424350792254, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:53,285] [INFO] [logging.py:68:log_dist] [Rank 0] step=1210, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:53,286] [INFO] [timer.py:207:stop] 0/1210, RunningAvgSamplesPerSec=85.14198374688434, CurrSamplesPerSec=84.34457712123101, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 143: 2.130859375, mean for epoch: 0.7410299661276224, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 144: 0.7158203125, mean for epoch: 0.7408548990885416, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 145: 0.50830078125, mean for epoch: 0.7392510775862069, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 146: 0.76904296875, mean for epoch: 0.739455131635274, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 147: 0.415283203125, mean for epoch: 0.7372498804209183, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 148: 1.4970703125, mean for epoch: 0.7423838022592906, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 149: 0.468994140625, mean for epoch: 0.7405489723154363, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 150: 0.689453125, mean for epoch: 0.7402083333333334, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 151: 0.8349609375, mean for epoch: 0.7408358340231788, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 152: 0.935546875, mean for epoch: 0.7421168277138158, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:53,912] [INFO] [logging.py:68:log_dist] [Rank 0] step=1220, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:53,912] [INFO] [timer.py:207:stop] 0/1220, RunningAvgSamplesPerSec=85.12948176987351, CurrSamplesPerSec=84.96685843934851, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 153: 0.450927734375, mean for epoch: 0.7402136310253268, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 154: 1.052734375, mean for epoch: 0.7422429865056818, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 155: 0.484375, mean for epoch: 0.7405793220766129, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 156: 0.50048828125, mean for epoch: 0.7390402769431089, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 157: 0.46337890625, mean for epoch: 0.7372844720342356, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 158: 0.67822265625, mean for epoch: 0.736910663073576, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 159: 0.6142578125, mean for epoch: 0.7361392614976415, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 160: 0.51318359375, mean for epoch: 0.7347457885742188, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 161: 1.9697265625, mean for epoch: 0.7424164766110248, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 162: 0.431884765625, mean for epoch: 0.7404996141975309, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:54,540] [INFO] [logging.py:68:log_dist] [Rank 0] step=1230, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:54,541] [INFO] [timer.py:207:stop] 0/1230, RunningAvgSamplesPerSec=85.10846910022616, CurrSamplesPerSec=83.50529585091981, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 163: 1.0888671875, mean for epoch: 0.7426368385736196, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 164: 1.2255859375, mean for epoch: 0.745581650152439, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 165: 0.49658203125, mean for epoch: 0.7440725615530303, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 166: 0.513671875, mean for epoch: 0.7426846056099398, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 167: 0.440673828125, mean for epoch: 0.7408761578405688, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 168: 0.4345703125, mean for epoch: 0.7390529087611607, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 169: 0.5556640625, mean for epoch: 0.7379677676590237, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 170: 0.451416015625, mean for epoch: 0.7362821691176471, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 171: 0.74853515625, mean for epoch: 0.7363538240131579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 172: 0.52392578125, mean for epoch: 0.735118777252907, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:55,194] [INFO] [logging.py:68:log_dist] [Rank 0] step=1240, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:55,196] [INFO] [timer.py:207:stop] 0/1240, RunningAvgSamplesPerSec=85.0588825914141, CurrSamplesPerSec=62.62211472423781, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 173: 0.54736328125, mean for epoch: 0.7340334853684971, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 174: 0.47119140625, mean for epoch: 0.7325228987068966, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 175: 0.48193359375, mean for epoch: 0.7310909598214286, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 176: 0.5439453125, mean for epoch: 0.7300276322798296, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 177: 0.80859375, mean for epoch: 0.73047150865113, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 178: 0.7548828125, mean for epoch: 0.7306086508075843, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 179: 0.54296875, mean for epoch: 0.7295603832053073, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 180: 0.53369140625, mean for epoch: 0.7284722222222222, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 181: 0.541015625, mean for epoch: 0.7274365504143646, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 182: 0.5908203125, mean for epoch: 0.7266859117445055, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:55,864] [INFO] [logging.py:68:log_dist] [Rank 0] step=1250, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:55,865] [INFO] [timer.py:207:stop] 0/1250, RunningAvgSamplesPerSec=84.9980536883242, CurrSamplesPerSec=74.53413323476728, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 183: 0.478759765625, mean for epoch: 0.7253311240607924, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 184: 0.5986328125, mean for epoch: 0.7246425462805707, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 185: 0.49462890625, mean for epoch: 0.7233992293074324, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 186: 0.5048828125, mean for epoch: 0.7222244098622311, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 187: 0.521484375, mean for epoch: 0.7211509337399733, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 188: 0.546875, mean for epoch: 0.7202239340924202, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 189: 0.556640625, mean for epoch: 0.7193584139384921, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 190: 0.85400390625, mean for epoch: 0.7200670744243421, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 191: 0.85302734375, mean for epoch: 0.7207632014888743, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 192: 0.475830078125, mean for epoch: 0.7194875081380209, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:56,497] [INFO] [logging.py:68:log_dist] [Rank 0] step=1260, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:56,498] [INFO] [timer.py:207:stop] 0/1260, RunningAvgSamplesPerSec=84.97496432351885, CurrSamplesPerSec=82.65876269155578, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 193: 0.8193359375, mean for epoch: 0.7200048575129534, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 194: 0.4755859375, mean for epoch: 0.7187449661726805, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 195: 0.489501953125, mean for epoch: 0.7175693609775641, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 196: 0.97509765625, mean for epoch: 0.7188832808514031, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 197: 0.455322265625, mean for epoch: 0.717545407677665, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 198: 0.478759765625, mean for epoch: 0.71633941958649, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 199: 0.54736328125, mean for epoch: 0.7154902932631909, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 200: 0.60546875, mean for epoch: 0.714940185546875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 201: 0.474365234375, mean for epoch: 0.7137432952425373, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 202: 0.48193359375, mean for epoch: 0.7125957224628713, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:57,147] [INFO] [logging.py:68:log_dist] [Rank 0] step=1270, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:57,147] [INFO] [timer.py:207:stop] 0/1270, RunningAvgSamplesPerSec=84.9361184385273, CurrSamplesPerSec=86.18055098954567, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 203: 0.5888671875, mean for epoch: 0.7119862222906403, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 204: 0.79541015625, mean for epoch: 0.7123951631433824, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 205: 0.759765625, mean for epoch: 0.7126262385670732, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 206: 0.5224609375, mean for epoch: 0.7117031060376213, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 207: 0.4873046875, mean for epoch: 0.7106190557065217, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 208: 0.4716796875, mean for epoch: 0.7094703087439904, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 209: 0.447509765625, mean for epoch: 0.7082169090161483, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 210: 1.3525390625, mean for epoch: 0.7112851097470239, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 211: 1.0517578125, mean for epoch: 0.7128987244520142, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 212: 0.490478515625, mean for epoch: 0.7118495725235849, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:57,757] [INFO] [logging.py:68:log_dist] [Rank 0] step=1280, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:57,758] [INFO] [timer.py:207:stop] 0/1280, RunningAvgSamplesPerSec=84.93782023288051, CurrSamplesPerSec=83.53390107307591, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 213: 1.87890625, mean for epoch: 0.7173287118544601, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 214: 0.767578125, mean for epoch: 0.7175635221962616, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 215: 0.5263671875, mean for epoch: 0.7166742369186047, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 216: 0.499267578125, mean for epoch: 0.715667724609375, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 217: 0.453125, mean for epoch: 0.7144578503024194, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 218: 1.845703125, mean for epoch: 0.7196470488102065, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 219: 0.537109375, mean for epoch: 0.7188135434503424, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 220: 1.6923828125, mean for epoch: 0.7232388583096591, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 221: 1.9541015625, mean for epoch: 0.7288083728082579, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 222: 0.74951171875, mean for epoch: 0.7289016311233109, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:58,362] [INFO] [logging.py:68:log_dist] [Rank 0] step=1290, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:58,362] [INFO] [timer.py:207:stop] 0/1290, RunningAvgSamplesPerSec=84.94542329406244, CurrSamplesPerSec=86.52366747944335, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 223: 0.712890625, mean for epoch: 0.728829832889574, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 224: 1.7099609375, mean for epoch: 0.7332098824637276, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 225: 0.484375, mean for epoch: 0.7321039496527778, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 226: 0.5966796875, mean for epoch: 0.7315047272538717, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 227: 1.0654296875, mean for epoch: 0.7329757623210352, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 228: 0.560546875, mean for epoch: 0.7322194952713815, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 229: 1.8203125, mean for epoch: 0.7369709931086245, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 230: 0.7060546875, mean for epoch: 0.736836574388587, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 231: 0.51123046875, mean for epoch: 0.7358599245806277, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 232: 0.828125, mean for epoch: 0.7362576188712284, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:58,997] [INFO] [logging.py:68:log_dist] [Rank 0] step=1300, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:58,997] [INFO] [timer.py:207:stop] 0/1300, RunningAvgSamplesPerSec=84.92193022630985, CurrSamplesPerSec=86.04583034157349, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 233: 1.7099609375, mean for epoch: 0.740436603071352, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 234: 0.54296875, mean for epoch: 0.7395927233573718, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 235: 0.6728515625, mean for epoch: 0.7393087184175532, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 236: 1.3173828125, mean for epoch: 0.7417581849179026, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 237: 0.5341796875, mean for epoch: 0.7408823262790084, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 238: 0.54541015625, mean for epoch: 0.7400610146402311, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 239: 0.61865234375, mean for epoch: 0.7395530285695606, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 240: 0.447021484375, mean for epoch: 0.7383341471354167, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 241: 0.9951171875, mean for epoch: 0.7393996369294605, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 242: 0.48291015625, mean for epoch: 0.7383397630423554, mem_alloc: 1023816704\n",
            "[2022-10-31 19:01:59,606] [INFO] [logging.py:68:log_dist] [Rank 0] step=1310, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:01:59,606] [INFO] [timer.py:207:stop] 0/1310, RunningAvgSamplesPerSec=84.92587817031142, CurrSamplesPerSec=86.5186700936083, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 243: 0.50927734375, mean for epoch: 0.7373971193415638, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 244: 1.35546875, mean for epoch: 0.739930199795082, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 245: 0.4638671875, mean for epoch: 0.7388034119897959, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 246: 0.54345703125, mean for epoch: 0.7380093210111789, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 247: 0.48046875, mean for epoch: 0.7369666466346154, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 248: 0.66796875, mean for epoch: 0.7366884293094758, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 249: 0.71240234375, mean for epoch: 0.7365908948293173, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 250: 0.51806640625, mean for epoch: 0.735716796875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 251: 0.8369140625, mean for epoch: 0.7361199732320717, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 252: 0.56494140625, mean for epoch: 0.7354406932043651, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:00,309] [INFO] [logging.py:68:log_dist] [Rank 0] step=1320, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:00,309] [INFO] [timer.py:207:stop] 0/1320, RunningAvgSamplesPerSec=84.8380936937182, CurrSamplesPerSec=59.60832466417677, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 253: 0.452392578125, mean for epoch: 0.7343219259510869, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 254: 0.96923828125, mean for epoch: 0.7352467934916339, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 255: 0.487548828125, mean for epoch: 0.7342754289215686, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 256: 0.490234375, mean for epoch: 0.7333221435546875, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 257: 1.0556640625, mean for epoch: 0.7345763922665369, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 258: 1.2470703125, mean for epoch: 0.7365628028100775, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 259: 0.5791015625, mean for epoch: 0.7359548443532818, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 260: 0.66748046875, mean for epoch: 0.7356914813701924, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 261: 0.53369140625, mean for epoch: 0.7349175347222222, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 262: 0.517578125, mean for epoch: 0.7340879949904581, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:00,933] [INFO] [logging.py:68:log_dist] [Rank 0] step=1330, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:00,934] [INFO] [timer.py:207:stop] 0/1330, RunningAvgSamplesPerSec=84.82762524846491, CurrSamplesPerSec=82.72495256578662, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   1, iteration:   5:   Loss at step 263: 1.7294921875, mean for epoch: 0.7378728018060836, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 264: 1.3740234375, mean for epoch: 0.7402824633049242, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 265: 0.49365234375, mean for epoch: 0.7393517836084905, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 266: 0.485107421875, mean for epoch: 0.738395977737312, mem_alloc: 1023816704\n",
            " Run   1, iteration:   5:   Loss at step 267: 0.496826171875, mean for epoch: 0.7374912219101124, mem_alloc: 1023816704\n",
            "Loss after iteration 5 ; MSE: 0.7373046875, MAE: 0.459716796875\n",
            "Connected by ('127.0.0.1', 49030)\n",
            "\u001b[94mReceived training result: b'5;0.73730;0.45972' \u001b[0m\n",
            "Time per iteration 16.825168228149415, memory OrderedDict([('active.all.allocated', 1797762), ('active.all.current', 7), ('active.all.freed', 1797755), ('active.all.peak', 197), ('active.large_pool.allocated', 3969), ('active.large_pool.current', 3), ('active.large_pool.freed', 3966), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1793793), ('active.small_pool.current', 4), ('active.small_pool.freed', 1793789), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 1436438076928), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 1436432943104), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 1339105265152), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 1339101595648), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 97332811776), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 97331347456), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 1436438076928), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 1436433554944), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 1339105265152), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 1339101595648), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 97332811776), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 97331959296), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1797762), ('allocation.all.current', 6), ('allocation.all.freed', 1797756), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 3969), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 3966), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1793793), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1793790), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 764045), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 764039), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 1317), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 1315), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 762728), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 762724), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 117819321344), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 117799289344), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 3665436160), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 3648134144), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 114153885184), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 114151155200), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            "1023816704\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.407958984375, mean for epoch: 0.407958984375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 2: 0.449951171875, mean for epoch: 0.428955078125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 3: 0.374755859375, mean for epoch: 0.410888671875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 4: 0.5615234375, mean for epoch: 0.44854736328125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 5: 0.546875, mean for epoch: 0.468212890625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 6: 0.67822265625, mean for epoch: 0.5032145182291666, mem_alloc: 1023816704\n",
            "Validation set Loss at step 7: 0.438720703125, mean for epoch: 0.49400111607142855, mem_alloc: 1023816704\n",
            "Validation set Loss at step 8: 0.56103515625, mean for epoch: 0.50238037109375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 9: 0.4423828125, mean for epoch: 0.4957139756944444, mem_alloc: 1023816704\n",
            "Validation set Loss at step 10: 0.556640625, mean for epoch: 0.501806640625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 11: 0.6513671875, mean for epoch: 0.5154030539772727, mem_alloc: 1023816704\n",
            "Validation set Loss at step 12: 0.440185546875, mean for epoch: 0.5091349283854166, mem_alloc: 1023816704\n",
            "Validation set Loss at step 13: 0.443359375, mean for epoch: 0.5040752704326923, mem_alloc: 1023816704\n",
            "Validation set Loss at step 14: 0.51416015625, mean for epoch: 0.5047956194196429, mem_alloc: 1023816704\n",
            "Validation set Loss at step 15: 0.257080078125, mean for epoch: 0.48828125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 16: 0.3662109375, mean for epoch: 0.48065185546875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 17: 0.44384765625, mean for epoch: 0.47848690257352944, mem_alloc: 1023816704\n",
            "Validation set Loss at step 18: 0.3466796875, mean for epoch: 0.4711642795138889, mem_alloc: 1023816704\n",
            "Validation set Loss at step 19: 0.263427734375, mean for epoch: 0.4602307771381579, mem_alloc: 1023816704\n",
            "Validation set Loss at step 20: 0.291748046875, mean for epoch: 0.451806640625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 21: 0.361328125, mean for epoch: 0.4474981398809524, mem_alloc: 1023816704\n",
            "Validation set Loss at step 22: 0.298828125, mean for epoch: 0.4407404119318182, mem_alloc: 1023816704\n",
            "Validation set Loss at step 23: 0.468994140625, mean for epoch: 0.44196883491847827, mem_alloc: 1023816704\n",
            "Validation set Loss at step 24: 0.395263671875, mean for epoch: 0.4400227864583333, mem_alloc: 1023816704\n",
            "Validation set Loss at step 25: 0.29931640625, mean for epoch: 0.43439453125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 26: 0.318603515625, mean for epoch: 0.42994103064903844, mem_alloc: 1023816704\n",
            "Validation set Loss at step 27: 0.480224609375, mean for epoch: 0.4318033854166667, mem_alloc: 1023816704\n",
            "Validation set Loss at step 28: 0.80126953125, mean for epoch: 0.4449986049107143, mem_alloc: 1023816704\n",
            "Validation set Loss at step 29: 0.6083984375, mean for epoch: 0.4506330818965517, mem_alloc: 1023816704\n",
            "Validation set Loss at step 30: 0.58056640625, mean for epoch: 0.4549641927083333, mem_alloc: 1023816704\n",
            "Validation set Loss at step 31: 0.63916015625, mean for epoch: 0.46090599798387094, mem_alloc: 1023816704\n",
            "Validation set Loss at step 32: 0.288818359375, mean for epoch: 0.45552825927734375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 33: 0.3046875, mean for epoch: 0.4509573271780303, mem_alloc: 1023816704\n",
            "Validation set Loss at step 34: 0.368896484375, mean for epoch: 0.4485437729779412, mem_alloc: 1023816704\n",
            "Validation set Loss at step 35: 0.345703125, mean for epoch: 0.44560546875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 36: 0.33349609375, mean for epoch: 0.4424913194444444, mem_alloc: 1023816704\n",
            "Validation set Loss at step 37: 0.287109375, mean for epoch: 0.43829180743243246, mem_alloc: 1023816704\n",
            "Validation set Loss at step 38: 0.3623046875, mean for epoch: 0.4362921463815789, mem_alloc: 1023816704\n",
            "Validation set Loss at step 39: 0.291259765625, mean for epoch: 0.43257336738782054, mem_alloc: 1023816704\n",
            "Validation set Loss at step 40: 0.33935546875, mean for epoch: 0.430242919921875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 41: 0.289794921875, mean for epoch: 0.42681735899390244, mem_alloc: 1023816704\n",
            "Validation set Loss at step 42: 0.3671875, mean for epoch: 0.42539760044642855, mem_alloc: 1023816704\n",
            "Validation set Loss at step 43: 0.70751953125, mean for epoch: 0.43195857558139533, mem_alloc: 1023816704\n",
            "Validation set Loss at step 44: 0.74755859375, mean for epoch: 0.43913130326704547, mem_alloc: 1023816704\n",
            "Validation set Loss at step 45: 0.76123046875, mean for epoch: 0.4462890625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 46: 0.50927734375, mean for epoch: 0.44765837296195654, mem_alloc: 1023816704\n",
            "Validation set Loss at step 47: 0.370361328125, mean for epoch: 0.44601375498670215, mem_alloc: 1023816704\n",
            "Validation set Loss at step 48: 1.0888671875, mean for epoch: 0.4594065348307292, mem_alloc: 1023816704\n",
            "Validation set Loss at step 49: 22.453125, mean for epoch: 0.9082579320790817, mem_alloc: 1023816704\n",
            "Validation set Loss at step 50: 39.75, mean for epoch: 1.6850927734375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 51: 21.5, mean for epoch: 2.073620366115196, mem_alloc: 1023816704\n",
            "Validation set Loss at step 52: 55.71875, mean for epoch: 3.1052574744591346, mem_alloc: 1023816704\n",
            "Validation set Loss at step 53: 6.4609375, mean for epoch: 3.16857219192217, mem_alloc: 1023816704\n",
            "Validation set Loss at step 54: 0.87353515625, mean for epoch: 3.126071506076389, mem_alloc: 1023816704\n",
            "Validation set Loss at step 55: 0.4560546875, mean for epoch: 3.0775257457386362, mem_alloc: 1023816704\n",
            "Validation set Loss at step 56: 0.28125, mean for epoch: 3.027592250279018, mem_alloc: 1023816704\n",
            "Validation set Loss at step 57: 0.2724609375, mean for epoch: 2.979256613212719, mem_alloc: 1023816704\n",
            "Validation set Loss at step 58: 0.309326171875, mean for epoch: 2.9332233297413794, mem_alloc: 1023816704\n",
            "Validation set Loss at step 59: 0.3134765625, mean for epoch: 2.888820842161017, mem_alloc: 1023816704\n",
            "Validation set Loss at step 60: 0.308349609375, mean for epoch: 2.84581298828125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 61: 0.36083984375, mean for epoch: 2.8050757236168034, mem_alloc: 1023816704\n",
            "Validation set Loss at step 62: 0.58984375, mean for epoch: 2.769346175655242, mem_alloc: 1023816704\n",
            "Validation set Loss at step 63: 0.473876953125, mean for epoch: 2.73291015625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 64: 0.434326171875, mean for epoch: 2.6969947814941406, mem_alloc: 1023816704\n",
            "Validation set Loss at step 65: 0.6396484375, mean for epoch: 2.665343299278846, mem_alloc: 1023816704\n",
            "Validation set Loss at step 66: 0.89111328125, mean for epoch: 2.638461026278409, mem_alloc: 1023816704\n",
            "Validation set Loss at step 67: 0.541015625, mean for epoch: 2.607155871035448, mem_alloc: 1023816704\n",
            "Validation set Loss at step 68: 0.383056640625, mean for epoch: 2.5744485294117645, mem_alloc: 1023816704\n",
            "Validation set Loss at step 69: 0.35791015625, mean for epoch: 2.5423247848731885, mem_alloc: 1023816704\n",
            "Validation set Loss at step 70: 0.61279296875, mean for epoch: 2.5147600446428573, mem_alloc: 1023816704\n",
            "Validation set Loss at step 71: 0.501953125, mean for epoch: 2.4864106514084505, mem_alloc: 1023816704\n",
            "Validation set Loss at step 72: 0.76904296875, mean for epoch: 2.462558322482639, mem_alloc: 1023816704\n",
            "Validation set Loss at step 73: 0.5, mean for epoch: 2.435673961900685, mem_alloc: 1023816704\n",
            "Validation set Loss at step 74: 0.377197265625, mean for epoch: 2.407856709248311, mem_alloc: 1023816704\n",
            "Validation set Loss at step 75: 0.6259765625, mean for epoch: 2.3840983072916666, mem_alloc: 1023816704\n",
            "Validation set Loss at step 76: 0.49169921875, mean for epoch: 2.3591983192845394, mem_alloc: 1023816704\n",
            "Validation set Loss at step 77: 0.50439453125, mean for epoch: 2.3351099584009742, mem_alloc: 1023816704\n",
            "Validation set Loss at step 78: 0.40185546875, mean for epoch: 2.31032464443109, mem_alloc: 1023816704\n",
            "Validation set Loss at step 79: 0.322021484375, mean for epoch: 2.28515625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 80: 0.4140625, mean for epoch: 2.261767578125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 81: 0.39306640625, mean for epoch: 2.238697193287037, mem_alloc: 1023816704\n",
            "Validation set Loss at step 82: 0.382080078125, mean for epoch: 2.2160555211509148, mem_alloc: 1023816704\n",
            "Validation set Loss at step 83: 0.345458984375, mean for epoch: 2.1935182134789155, mem_alloc: 1023816704\n",
            "Validation set Loss at step 84: 0.436767578125, mean for epoch: 2.172604515438988, mem_alloc: 1023816704\n",
            "Validation set Loss at step 85: 0.385986328125, mean for epoch: 2.1515854779411763, mem_alloc: 1023816704\n",
            "Validation set Loss at step 86: 0.5283203125, mean for epoch: 2.1327103015988373, mem_alloc: 1023816704\n",
            "Validation set Loss at step 87: 0.59619140625, mean for epoch: 2.1150491648706895, mem_alloc: 1023816704\n",
            "Validation set Loss at step 88: 0.62646484375, mean for epoch: 2.0981334339488638, mem_alloc: 1023816704\n",
            "Validation set Loss at step 89: 0.5703125, mean for epoch: 2.0809669066011236, mem_alloc: 1023816704\n",
            "Loss for validation set  ; MSE: 2.080078125, MAE: 0.52294921875\n",
            "prediction[0.0834, 0.03656, 0.1926, 0.4473, 0.3193, 0.1666, -0.157, -0.2289, -0.4133, -0.2085, -0.2013, -0.314, 0.03387, 0.3066, 0.6353, 0.86, 0.9175, 0.8223, 0.6387, 0.4983, 0.3484, 0.001381, 0.02757, -0.07355]Connected by ('127.0.0.1', 45030)\n",
            "\n",
            "\u001b[94mReceived result: b'2.08008;0.52295' \u001b[0m\n",
            "truth[0.0924, 0.127, 0.1855, 0.2688, 0.318, 0.09155, -0.03864, -0.1779, -0.02875, -0.0996, -0.1186, -0.0922, -0.1392, 1.113, 0.719, 1.474, 1.246, 1.088, 1.033, 0.848, 0.2876, 0.2177, 0.1254, 0.113]\n",
            "Iteration  1| MSE 2.0801 | MAE 0.5230\n",
            "Mean        | MSE 2.0801 | MAE 0.5230\n",
            "[2022-10-31 19:02:03,787] [INFO] [launch.py:318:main] Process 1043 exits successfully.\n",
            "[2022-10-31 19:02:05,044] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-10-31 19:02:05,044] [INFO] [runner.py:507:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --deepspeed_config settings/ds_config_zero.json --data ETTh1 --seq_len 48 --pred_len 24 --dec_seq_len 48 --hidden_size 96 --n_encoder_layers 3 --n_decoder_layers 3 --encoder_attention query_selector_0.85 --decoder_attention full --n_heads 2 --batch_size 32 --embedding_size 24 --iterations 5 --exps 2 --dropout 0 --fp16 --deepspeed --features M --input_len 7 --output_len 7 --run_num 2\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.8.4-1+cuda11.2\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.8.4-1\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.8.4-1+cuda11.2\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:129:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.8.4-1\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-10-31 19:02:06,889] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-10-31 19:02:06,890] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-10-31 19:02:06,890] [INFO] [launch.py:156:main] dist_world_size=1\n",
            "[2022-10-31 19:02:06,890] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Number of parameters: 123\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([96, 24])\n",
            "torch.Size([24, 48])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 7])\n",
            "torch.Size([24])\n",
            "torch.Size([24, 7])\n",
            "torch.Size([24])\n",
            "torch.Size([168, 1152])\n",
            "torch.Size([168])\n",
            "[2022-10-31 19:02:09,052] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.4, git-hash=unknown, git-branch=unknown\n",
            "[2022-10-31 19:02:09,054] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2022-10-31 19:02:09,063] [WARNING] [config_utils.py:64:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2022-10-31 19:02:10,938] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.2 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.23618626594543457 seconds\n",
            "[2022-10-31 19:02:11,985] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2022-10-31 19:02:11,988] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2022-10-31 19:02:11,988] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2022-10-31 19:02:11,989] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "[2022-10-31 19:02:11,989] [INFO] [stage_1_and_2.py:140:__init__] Reduce bucket size 500000000\n",
            "[2022-10-31 19:02:11,989] [INFO] [stage_1_and_2.py:141:__init__] Allgather bucket size 500000000\n",
            "[2022-10-31 19:02:11,989] [INFO] [stage_1_and_2.py:142:__init__] CPU Offload: False\n",
            "[2022-10-31 19:02:11,989] [INFO] [stage_1_and_2.py:143:__init__] Round robin gradient partitioning: False\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py37_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.23904633522033691 seconds\n",
            "Rank: 0 partition count [1] and sizes[(305688, False)] \n",
            "[2022-10-31 19:02:12,344] [INFO] [utils.py:827:see_memory_usage] Before initializing optimizer states\n",
            "[2022-10-31 19:02:12,345] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:02:12,345] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.22 GB, percent = 12.6%\n",
            "[2022-10-31 19:02:12,399] [INFO] [utils.py:827:see_memory_usage] After initializing optimizer states\n",
            "[2022-10-31 19:02:12,399] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:02:12,400] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.22 GB, percent = 12.6%\n",
            "[2022-10-31 19:02:12,400] [INFO] [stage_1_and_2.py:523:__init__] optimizer state initialized\n",
            "[2022-10-31 19:02:12,453] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2022-10-31 19:02:12,454] [INFO] [utils.py:832:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2022-10-31 19:02:12,454] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 3.22 GB, percent = 12.6%\n",
            "[2022-10-31 19:02:12,457] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2022-10-31 19:02:12,458] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2022-10-31 19:02:12,458] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2022-10-31 19:02:12,458] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:12,458] [INFO] [config.py:1002:print] DeepSpeedEngine configuration:\n",
            "[2022-10-31 19:02:12,458] [INFO] [config.py:1006:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   amp_enabled .................. False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   amp_params ................... False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   bfloat16_enabled ............. False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   checkpoint_tag_validation_enabled  True\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   checkpoint_tag_validation_fail  False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6012912110>\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   communication_data_type ...... None\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   curriculum_enabled ........... False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   curriculum_params ............ False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   dataloader_drop_last ......... False\n",
            "[2022-10-31 19:02:12,459] [INFO] [config.py:1006:print]   disable_allgather ............ False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   dump_state ................... False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_enabled ........... False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_layer_num ......... 0\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_max_iter .......... 100\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_stability ......... 1e-06\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_tol ............... 0.01\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   eigenvalue_verbose ........... False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   elasticity_enabled ........... False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   fp16_auto_cast ............... False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   fp16_enabled ................. True\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   fp16_master_weights_and_gradients  False\n",
            "[2022-10-31 19:02:12,460] [INFO] [config.py:1006:print]   global_rank .................. 0\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   gradient_accumulation_steps .. 1\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   gradient_clipping ............ 0.0\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   gradient_predivide_factor .... 1.0\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   load_universal_checkpoint .... False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   loss_scale ................... 0\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   memory_breakdown ............. False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f6012912cd0>\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   optimizer_legacy_fusion ...... False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   optimizer_name ............... adam\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   pld_enabled .................. False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   pld_params ................... False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   prescale_gradients ........... False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   scheduler_name ............... None\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   scheduler_params ............. None\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   sparse_attention ............. None\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   sparse_gradients_enabled ..... False\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   steps_per_print .............. 10\n",
            "[2022-10-31 19:02:12,461] [INFO] [config.py:1006:print]   train_batch_size ............. 5\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   train_micro_batch_size_per_gpu  5\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   wall_clock_breakdown ......... False\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   world_size ................... 1\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   zero_allow_untested_optimizer  False\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=False allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=False prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   zero_enabled ................. True\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:1006:print]   zero_optimization_stage ...... 2\n",
            "[2022-10-31 19:02:12,462] [INFO] [config.py:997:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 5, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 5e-05, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": false, \n",
            "        \"cpu_offload\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 1000\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.00045609474182128906 seconds\n",
            "train 8569\n",
            " Run   2, iteration:   1:   Loss at step 1: 1.162109375, mean for epoch: 1.162109375, mem_alloc: 23053824\n",
            "[2022-10-31 19:02:13,442] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 4294967296\n",
            " Run   2, iteration:   1:   Loss at step 2: 1.0986328125, mean for epoch: 1.13037109375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,503] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
            " Run   2, iteration:   1:   Loss at step 3: 1.1005859375, mean for epoch: 1.1204427083333333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,566] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
            " Run   2, iteration:   1:   Loss at step 4: 1.5029296875, mean for epoch: 1.216064453125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,645] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
            " Run   2, iteration:   1:   Loss at step 5: 1.0126953125, mean for epoch: 1.175390625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,692] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
            " Run   2, iteration:   1:   Loss at step 6: 1.0498046875, mean for epoch: 1.1544596354166667, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,739] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
            " Run   2, iteration:   1:   Loss at step 7: 1.0283203125, mean for epoch: 1.1364397321428572, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,785] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
            " Run   2, iteration:   1:   Loss at step 8: 1.138671875, mean for epoch: 1.13671875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,831] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
            " Run   2, iteration:   1:   Loss at step 9: 1.087890625, mean for epoch: 1.1312934027777777, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,878] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
            " Run   2, iteration:   1:   Loss at step 10: 1.826171875, mean for epoch: 1.20078125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,925] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
            "[2022-10-31 19:02:13,925] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=10, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:13,926] [INFO] [timer.py:207:stop] 0/10, RunningAvgSamplesPerSec=99.06519607003737, CurrSamplesPerSec=110.45141174797625, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 11: 1.0654296875, mean for epoch: 1.1884765625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:13,971] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
            " Run   2, iteration:   1:   Loss at step 12: 1.6640625, mean for epoch: 1.2281087239583333, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,017] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
            " Run   2, iteration:   1:   Loss at step 13: 1.0068359375, mean for epoch: 1.2110877403846154, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,063] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
            " Run   2, iteration:   1:   Loss at step 14: 1.03125, mean for epoch: 1.1982421875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,108] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
            " Run   2, iteration:   1:   Loss at step 15: 1.04296875, mean for epoch: 1.187890625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,156] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            " Run   2, iteration:   1:   Loss at step 16: 1.083984375, mean for epoch: 1.181396484375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,201] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            " Run   2, iteration:   1:   Loss at step 17: 1.615234375, mean for epoch: 1.2069163602941178, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,247] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            " Run   2, iteration:   1:   Loss at step 18: 1.388671875, mean for epoch: 1.2170138888888888, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,292] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            " Run   2, iteration:   1:   Loss at step 19: 1.1015625, mean for epoch: 1.2109375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 20: 1.0166015625, mean for epoch: 1.201220703125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:14,415] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:14,416] [INFO] [timer.py:207:stop] 0/20, RunningAvgSamplesPerSec=103.38462751941711, CurrSamplesPerSec=84.42844835221463, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 21: 1.2431640625, mean for epoch: 1.203218005952381, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 22: 1.3212890625, mean for epoch: 1.2085848721590908, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 23: 1.15625, mean for epoch: 1.2063094429347827, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 24: 1.1806640625, mean for epoch: 1.2052408854166667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 25: 1.021484375, mean for epoch: 1.197890625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 26: 1.1171875, mean for epoch: 1.1947866586538463, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 27: 0.9130859375, mean for epoch: 1.1843532986111112, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 28: 1.1318359375, mean for epoch: 1.1824776785714286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 29: 2.69140625, mean for epoch: 1.234509698275862, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 30: 0.962890625, mean for epoch: 1.2254557291666666, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:15,020] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:15,020] [INFO] [timer.py:207:stop] 0/30, RunningAvgSamplesPerSec=96.4215257490493, CurrSamplesPerSec=88.27474733869033, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 31: 1.6982421875, mean for epoch: 1.2407069052419355, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 32: 0.96630859375, mean for epoch: 1.2321319580078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 33: 2.302734375, mean for epoch: 1.2645744554924243, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 34: 1.0, mean for epoch: 1.2567928538602942, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 35: 0.90625, mean for epoch: 1.24677734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 36: 0.830078125, mean for epoch: 1.2352023654513888, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 37: 2.1640625, mean for epoch: 1.260306693412162, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 38: 0.82568359375, mean for epoch: 1.2488692434210527, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 39: 2.775390625, mean for epoch: 1.2880108173076923, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 40: 1.234375, mean for epoch: 1.286669921875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:15,624] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:15,625] [INFO] [timer.py:207:stop] 0/40, RunningAvgSamplesPerSec=93.43706973622115, CurrSamplesPerSec=86.50796335331219, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 41: 0.82373046875, mean for epoch: 1.2753787157012195, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 42: 0.7021484375, mean for epoch: 1.2617303757440477, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 43: 0.75146484375, mean for epoch: 1.2498637354651163, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 44: 0.80029296875, mean for epoch: 1.2396462180397727, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 45: 0.81591796875, mean for epoch: 1.2302300347222221, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 46: 0.93017578125, mean for epoch: 1.2237071161684783, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 47: 0.86279296875, mean for epoch: 1.2160280917553192, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 48: 0.6865234375, mean for epoch: 1.2049967447916667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 49: 0.75927734375, mean for epoch: 1.1959004304846939, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 50: 0.77880859375, mean for epoch: 1.18755859375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:16,226] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:16,226] [INFO] [timer.py:207:stop] 0/50, RunningAvgSamplesPerSec=91.85794915273262, CurrSamplesPerSec=87.53963417179399, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 51: 0.7333984375, mean for epoch: 1.1786534926470589, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 52: 0.7939453125, mean for epoch: 1.1712552584134615, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 53: 2.1171875, mean for epoch: 1.1891030365566038, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 54: 0.6787109375, mean for epoch: 1.1796513310185186, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 55: 0.67236328125, mean for epoch: 1.1704279119318182, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 56: 0.8681640625, mean for epoch: 1.1650303431919642, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 57: 0.76171875, mean for epoch: 1.1579547012061404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 58: 0.7431640625, mean for epoch: 1.1508031384698276, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 59: 1.9228515625, mean for epoch: 1.1638887049788136, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 60: 0.6328125, mean for epoch: 1.1550374348958334, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:16,833] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:16,833] [INFO] [timer.py:207:stop] 0/60, RunningAvgSamplesPerSec=90.67368709505772, CurrSamplesPerSec=89.71005689352782, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 61: 0.70947265625, mean for epoch: 1.147733094262295, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 62: 0.75146484375, mean for epoch: 1.1413416708669355, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 63: 0.70166015625, mean for epoch: 1.1343625992063493, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 64: 0.6416015625, mean for epoch: 1.1266632080078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 65: 0.74951171875, mean for epoch: 1.1208608774038462, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 66: 0.6826171875, mean for epoch: 1.1142208214962122, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 67: 0.74169921875, mean for epoch: 1.1086607975746268, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 68: 0.787109375, mean for epoch: 1.1039321001838236, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 69: 0.724609375, mean for epoch: 1.0984346693840579, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 70: 0.74853515625, mean for epoch: 1.0934361049107142, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:17,425] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:17,425] [INFO] [timer.py:207:stop] 0/70, RunningAvgSamplesPerSec=90.22463671012821, CurrSamplesPerSec=87.44290771418207, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 71: 0.84228515625, mean for epoch: 1.0898987676056338, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 72: 0.9921875, mean for epoch: 1.0885416666666667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 73: 0.6611328125, mean for epoch: 1.0826867508561644, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 74: 1.0361328125, mean for epoch: 1.0820576435810811, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 75: 0.70068359375, mean for epoch: 1.07697265625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 76: 0.9267578125, mean for epoch: 1.0749961451480263, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 77: 0.9814453125, mean for epoch: 1.0737811992694806, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 78: 0.646484375, mean for epoch: 1.0683030348557692, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 79: 2.30078125, mean for epoch: 1.083904024920886, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 80: 0.65576171875, mean for epoch: 1.07855224609375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:18,031] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:18,032] [INFO] [timer.py:207:stop] 0/80, RunningAvgSamplesPerSec=89.5969333982287, CurrSamplesPerSec=87.95450351456995, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 81: 2.044921875, mean for epoch: 1.0904827353395061, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 82: 0.65673828125, mean for epoch: 1.0851931688262195, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 83: 1.30078125, mean for epoch: 1.0877906155873494, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 84: 0.77490234375, mean for epoch: 1.0840657552083333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 85: 0.70849609375, mean for epoch: 1.0796472886029411, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 86: 0.7314453125, mean for epoch: 1.0755984284156976, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 87: 0.89990234375, mean for epoch: 1.0735789331896552, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 88: 0.751953125, mean for epoch: 1.0699240944602273, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 89: 0.65771484375, mean for epoch: 1.0652925298455056, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 90: 0.654296875, mean for epoch: 1.0607259114583334, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:18,639] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:18,639] [INFO] [timer.py:207:stop] 0/90, RunningAvgSamplesPerSec=89.11334313977767, CurrSamplesPerSec=86.49476202260166, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 91: 1.00390625, mean for epoch: 1.0601015195741759, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 92: 1.36328125, mean for epoch: 1.0633969514266304, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 93: 0.72412109375, mean for epoch: 1.0597488239247312, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 94: 0.61962890625, mean for epoch: 1.0550666971409575, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 95: 0.6611328125, mean for epoch: 1.0509200246710526, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 96: 0.6328125, mean for epoch: 1.0465647379557292, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 97: 1.4716796875, mean for epoch: 1.0509473663015463, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 98: 0.6337890625, mean for epoch: 1.0466906489158163, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 99: 0.91552734375, mean for epoch: 1.0453657670454546, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 100: 0.69140625, mean for epoch: 1.041826171875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:19,246] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:19,246] [INFO] [timer.py:207:stop] 0/100, RunningAvgSamplesPerSec=88.79756003066078, CurrSamplesPerSec=86.57188619738776, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 101: 0.5869140625, mean for epoch: 1.0373220915841583, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 102: 1.5634765625, mean for epoch: 1.04248046875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 103: 0.85498046875, mean for epoch: 1.0406600804004855, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 104: 2.27734375, mean for epoch: 1.05255126953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 105: 0.98974609375, mean for epoch: 1.051953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 106: 0.56982421875, mean for epoch: 1.0474047390919812, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 107: 0.5322265625, mean for epoch: 1.0425899897780373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 108: 0.6767578125, mean for epoch: 1.0392026548032407, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 109: 0.65771484375, mean for epoch: 1.0357027666284404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 110: 0.5546875, mean for epoch: 1.0313299005681817, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:19,856] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:19,857] [INFO] [timer.py:207:stop] 0/110, RunningAvgSamplesPerSec=88.46722413951026, CurrSamplesPerSec=88.31601111766192, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 111: 0.5927734375, mean for epoch: 1.0273789414414414, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 112: 0.6015625, mean for epoch: 1.0235770089285714, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 113: 0.6953125, mean for epoch: 1.0206720132743363, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 114: 0.556640625, mean for epoch: 1.0166015625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 115: 0.57275390625, mean for epoch: 1.0127420176630435, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 116: 0.54248046875, mean for epoch: 1.0086880387931034, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 117: 0.6171875, mean for epoch: 1.0053418803418803, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 118: 0.61083984375, mean for epoch: 1.001998642743644, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 119: 0.92626953125, mean for epoch: 1.0013622636554622, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 120: 0.64013671875, mean for epoch: 0.99835205078125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:20,457] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:20,457] [INFO] [timer.py:207:stop] 0/120, RunningAvgSamplesPerSec=88.27936389069714, CurrSamplesPerSec=85.34861384688014, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 121: 1.0224609375, mean for epoch: 0.9985512977789256, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 122: 0.6494140625, mean for epoch: 0.9956895171618853, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 123: 0.52001953125, mean for epoch: 0.991822281504065, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 124: 0.5634765625, mean for epoch: 0.9883678805443549, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 125: 0.8125, mean for epoch: 0.9869609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 126: 1.8193359375, mean for epoch: 0.9935670882936508, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 127: 0.63720703125, mean for epoch: 0.9907611035925197, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 128: 0.63818359375, mean for epoch: 0.988006591796875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 129: 0.572265625, mean for epoch: 0.9847837936046512, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 130: 0.54736328125, mean for epoch: 0.9814190204326924, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:21,059] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:21,060] [INFO] [timer.py:207:stop] 0/130, RunningAvgSamplesPerSec=88.14855575157226, CurrSamplesPerSec=87.15871544762751, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 131: 0.841796875, mean for epoch: 0.9803532025286259, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 132: 1.046875, mean for epoch: 0.9808571555397727, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 133: 1.80078125, mean for epoch: 0.9870219983552632, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 134: 0.693359375, mean for epoch: 0.9848304862406716, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 135: 0.970703125, mean for epoch: 0.9847258391203704, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 136: 0.5087890625, mean for epoch: 0.9812263039981618, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 137: 1.333984375, mean for epoch: 0.9838011804288321, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 138: 0.5654296875, mean for epoch: 0.9807695029438406, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 139: 0.64892578125, mean for epoch: 0.9783821380395683, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 140: 0.68115234375, mean for epoch: 0.9762590680803571, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:21,666] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:21,666] [INFO] [timer.py:207:stop] 0/140, RunningAvgSamplesPerSec=87.96200740753551, CurrSamplesPerSec=85.43136248462184, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 141: 0.72705078125, mean for epoch: 0.9744916334219859, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 142: 0.8623046875, mean for epoch: 0.9737015845070423, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 143: 0.744140625, mean for epoch: 0.9720962631118881, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 144: 0.576171875, mean for epoch: 0.9693467881944444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 145: 0.50927734375, mean for epoch: 0.9661738954741379, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 146: 0.70263671875, mean for epoch: 0.9643688463184932, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 147: 0.669921875, mean for epoch: 0.9623658056972789, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 148: 0.6025390625, mean for epoch: 0.959934543918919, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 149: 0.583984375, mean for epoch: 0.9574113884228188, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 150: 0.70361328125, mean for epoch: 0.9557194010416666, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:22,283] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:22,283] [INFO] [timer.py:207:stop] 0/150, RunningAvgSamplesPerSec=87.71367233813658, CurrSamplesPerSec=84.31066852670047, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 151: 0.5087890625, mean for epoch: 0.9527595974751656, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 152: 1.1611328125, mean for epoch: 0.9541304738898027, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 153: 2.0390625, mean for epoch: 0.9612215328839869, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 154: 0.8388671875, mean for epoch: 0.9604270241477273, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 155: 1.984375, mean for epoch: 0.9670331401209677, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 156: 3.501953125, mean for epoch: 0.9832826272035257, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 157: 1.2490234375, mean for epoch: 0.9849752438296179, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 158: 0.59765625, mean for epoch: 0.9825238577927216, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 159: 0.65576171875, mean for epoch: 0.98046875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 160: 1.291015625, mean for epoch: 0.98240966796875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:22,889] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:22,889] [INFO] [timer.py:207:stop] 0/160, RunningAvgSamplesPerSec=87.58949929498849, CurrSamplesPerSec=88.45607464021191, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 161: 0.67578125, mean for epoch: 0.9805051436335404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 162: 2.052734375, mean for epoch: 0.9871238425925926, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 163: 0.77490234375, mean for epoch: 0.9858218702070553, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 164: 1.46484375, mean for epoch: 0.9887427353277439, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 165: 1.3466796875, mean for epoch: 0.990912050189394, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 166: 0.6640625, mean for epoch: 0.9889430769954819, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 167: 0.61279296875, mean for epoch: 0.9866906811377245, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 168: 0.791015625, mean for epoch: 0.9855259486607143, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 169: 0.55322265625, mean for epoch: 0.9829679410133136, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 170: 0.51318359375, mean for epoch: 0.9802045036764706, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:23,488] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:23,488] [INFO] [timer.py:207:stop] 0/170, RunningAvgSamplesPerSec=87.53781151356718, CurrSamplesPerSec=89.76496723409538, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 171: 0.91650390625, mean for epoch: 0.9798319855628655, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 172: 0.68994140625, mean for epoch: 0.9781465752180233, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 173: 1.8359375, mean for epoch: 0.9831049042630058, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 174: 0.712890625, mean for epoch: 0.9815519486350575, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 175: 0.6650390625, mean for epoch: 0.9797433035714286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 176: 0.513671875, mean for epoch: 0.9770951704545454, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 177: 1.4404296875, mean for epoch: 0.9797128795903954, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 178: 0.642578125, mean for epoch: 0.9778188641151685, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 179: 0.7060546875, mean for epoch: 0.9763006284916201, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 180: 0.5224609375, mean for epoch: 0.973779296875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:24,087] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:24,088] [INFO] [timer.py:207:stop] 0/180, RunningAvgSamplesPerSec=87.48098629956185, CurrSamplesPerSec=88.218304497251, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 181: 0.92626953125, mean for epoch: 0.9735168119820442, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 182: 0.5732421875, mean for epoch: 0.9713175008585165, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 183: 0.60302734375, mean for epoch: 0.9693049863387978, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 184: 0.6923828125, mean for epoch: 0.9677999745244565, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 185: 0.59521484375, mean for epoch: 0.9657860008445946, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 186: 1.33203125, mean for epoch: 0.9677550613239247, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 187: 1.900390625, mean for epoch: 0.9727424172794118, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 188: 0.546875, mean for epoch: 0.9704771650598404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 189: 2.1171875, mean for epoch: 0.9765444155092593, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 190: 0.544921875, mean for epoch: 0.9742727179276316, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:24,697] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:24,697] [INFO] [timer.py:207:stop] 0/190, RunningAvgSamplesPerSec=87.36895219236884, CurrSamplesPerSec=84.50227055690092, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 191: 1.0126953125, mean for epoch: 0.9744738833442408, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 192: 0.86572265625, mean for epoch: 0.973907470703125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 193: 0.499755859375, mean for epoch: 0.9714507266029793, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 194: 0.95751953125, mean for epoch: 0.9713789163176546, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 195: 0.63134765625, mean for epoch: 0.9696351662660256, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 196: 0.759765625, mean for epoch: 0.9685644033003826, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 197: 0.68603515625, mean for epoch: 0.9671302446859137, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 198: 0.81005859375, mean for epoch: 0.9663369535195707, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 199: 0.62841796875, mean for epoch: 0.9646388681689698, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 200: 0.595703125, mean for epoch: 0.962794189453125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:25,457] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:25,457] [INFO] [timer.py:207:stop] 0/200, RunningAvgSamplesPerSec=86.2265185543462, CurrSamplesPerSec=82.36399340193229, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 201: 0.7119140625, mean for epoch: 0.9615460296175373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 202: 0.54248046875, mean for epoch: 0.9594714476330446, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 203: 0.8828125, mean for epoch: 0.9590938173491379, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 204: 0.7763671875, mean for epoch: 0.9581980985753676, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 205: 0.56982421875, mean for epoch: 0.9563035918445122, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 206: 0.5673828125, mean for epoch: 0.9544156268962378, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 207: 0.53466796875, mean for epoch: 0.9523878604317633, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 208: 0.890625, mean for epoch: 0.9520909236027644, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 209: 1.8515625, mean for epoch: 0.9563946153558612, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 210: 0.5517578125, mean for epoch: 0.9544677734375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:26,062] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:26,063] [INFO] [timer.py:207:stop] 0/210, RunningAvgSamplesPerSec=86.21925426549069, CurrSamplesPerSec=85.05507697798544, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 211: 1.8974609375, mean for epoch: 0.9589369353524881, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 212: 0.552734375, mean for epoch: 0.9570208855395047, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 213: 0.84619140625, mean for epoch: 0.9565005593456573, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 214: 0.56787109375, mean for epoch: 0.9546845338054907, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 215: 0.481201171875, mean for epoch: 0.9524822856104651, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 216: 0.54638671875, mean for epoch: 0.9506022135416666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 217: 1.4267578125, mean for epoch: 0.9527964789746544, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 218: 0.53466796875, mean for epoch: 0.9508784582855505, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 219: 0.80859375, mean for epoch: 0.9502287564212328, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 220: 0.5107421875, mean for epoch: 0.9482310901988636, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:26,671] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:26,671] [INFO] [timer.py:207:stop] 0/220, RunningAvgSamplesPerSec=86.1763484928507, CurrSamplesPerSec=87.79653779331422, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 221: 0.6005859375, mean for epoch: 0.946658035209276, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 222: 1.146484375, mean for epoch: 0.9475581538569819, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 223: 1.2607421875, mean for epoch: 0.9489625665639013, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 224: 0.5146484375, mean for epoch: 0.9470236642020089, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 225: 0.479248046875, mean for epoch: 0.9449446614583333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 226: 0.54150390625, mean for epoch: 0.9431595253733407, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 227: 0.5869140625, mean for epoch: 0.941590162100771, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 228: 0.7978515625, mean for epoch: 0.9409597296463815, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 229: 0.6044921875, mean for epoch: 0.9394904390693232, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 230: 0.5419921875, mean for epoch: 0.9377621858016304, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:27,272] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:27,273] [INFO] [timer.py:207:stop] 0/230, RunningAvgSamplesPerSec=86.1820747982961, CurrSamplesPerSec=86.06843113998548, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 231: 1.18359375, mean for epoch: 0.9388263917072511, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 232: 0.60595703125, mean for epoch: 0.9373916099811422, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 233: 0.64111328125, mean for epoch: 0.9361200291711373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 234: 0.87890625, mean for epoch: 0.9358755258413461, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 235: 0.62255859375, mean for epoch: 0.934542262300532, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 236: 0.5, mean for epoch: 0.932700981528072, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 237: 1.1650390625, mean for epoch: 0.9336813109836498, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 238: 0.6318359375, mean for epoch: 0.9324130531118697, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 239: 0.5400390625, mean for epoch: 0.9307713209335774, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 240: 1.0595703125, mean for epoch: 0.9313079833984375, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:27,880] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:27,881] [INFO] [timer.py:207:stop] 0/240, RunningAvgSamplesPerSec=86.15555041318822, CurrSamplesPerSec=77.71950369854282, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 241: 0.5078125, mean for epoch: 0.9295507407287344, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 242: 0.65234375, mean for epoch: 0.9284052572959711, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 243: 1.8564453125, mean for epoch: 0.9322243521733539, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 244: 0.77490234375, mean for epoch: 0.93157958984375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 245: 1.18359375, mean for epoch: 0.9326082190688776, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 246: 0.8427734375, mean for epoch: 0.9322430370299797, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 247: 1.3916015625, mean for epoch: 0.934102788145243, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 248: 0.7236328125, mean for epoch: 0.9332541188886089, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 249: 0.51318359375, mean for epoch: 0.9315670886671686, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 250: 0.51171875, mean for epoch: 0.9298876953125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:28,491] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:28,491] [INFO] [timer.py:207:stop] 0/250, RunningAvgSamplesPerSec=86.12383704708864, CurrSamplesPerSec=82.58779978734297, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 251: 0.47314453125, mean for epoch: 0.9280680014317729, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 252: 0.454833984375, mean for epoch: 0.9261900886656746, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 253: 1.798828125, mean for epoch: 0.9296392508646245, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 254: 0.65478515625, mean for epoch: 0.9285571481299213, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 255: 0.66015625, mean for epoch: 0.9275045955882353, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 256: 0.8583984375, mean for epoch: 0.9272346496582031, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 257: 0.58154296875, mean for epoch: 0.9258895458414397, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 258: 0.8212890625, mean for epoch: 0.9254841176114341, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 259: 1.8857421875, mean for epoch: 0.929191677726834, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 260: 2.421875, mean for epoch: 0.9349327674278847, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:29,099] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:29,100] [INFO] [timer.py:207:stop] 0/260, RunningAvgSamplesPerSec=86.09004111107494, CurrSamplesPerSec=81.98244756748305, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   1:   Loss at step 261: 1.2177734375, mean for epoch: 0.9360164481561303, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 262: 1.8994140625, mean for epoch: 0.9396935382872137, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 263: 0.7666015625, mean for epoch: 0.9390353938925855, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 264: 0.5390625, mean for epoch: 0.9375203450520834, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 265: 0.65283203125, mean for epoch: 0.9364460495283019, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 266: 0.62109375, mean for epoch: 0.9352605145676691, mem_alloc: 1023816704\n",
            " Run   2, iteration:   1:   Loss at step 267: 0.7978515625, mean for epoch: 0.9347458742977528, mem_alloc: 1023816704\n",
            "Loss after iteration 1 ; MSE: 0.9345703125, MAE: 0.57470703125\n",
            "Connected by ('127.0.0.1', 45104)\n",
            "\u001b[94mReceived training result: b'1;0.93457;0.57471' \u001b[0m\n",
            "Time per iteration 17.113162755966187, memory OrderedDict([('active.all.allocated', 352686), ('active.all.current', 7), ('active.all.freed', 352679), ('active.all.peak', 197), ('active.large_pool.allocated', 769), ('active.large_pool.current', 3), ('active.large_pool.freed', 766), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 351917), ('active.small_pool.current', 4), ('active.small_pool.freed', 351913), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 287205266944), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 287200133120), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 267786166784), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 267782497280), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 19419100160), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 19417635840), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 287205266944), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 287200744960), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 267786166784), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 267782497280), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 19419100160), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 19418247680), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 352686), ('allocation.all.current', 6), ('allocation.all.freed', 352680), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 769), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 766), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 351917), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 351914), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 149655), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 149649), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 251), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 249), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 149404), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 149400), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 23496072192), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 23476040192), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 711064064), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 693762048), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 22785008128), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 22782278144), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   2, iteration:   2:   Loss at step 1: 0.53369140625, mean for epoch: 0.53369140625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 2: 0.484619140625, mean for epoch: 0.5091552734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 3: 0.71630859375, mean for epoch: 0.5782063802083334, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:30,024] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:30,024] [INFO] [timer.py:207:stop] 0/270, RunningAvgSamplesPerSec=85.96252269809055, CurrSamplesPerSec=83.93106705193983, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 4: 0.55322265625, mean for epoch: 0.57196044921875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 5: 0.86474609375, mean for epoch: 0.630517578125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 6: 0.464599609375, mean for epoch: 0.6028645833333334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 7: 0.83154296875, mean for epoch: 0.6355329241071429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 8: 0.8779296875, mean for epoch: 0.66583251953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 9: 0.759765625, mean for epoch: 0.67626953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 10: 0.56689453125, mean for epoch: 0.66533203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 11: 0.6103515625, mean for epoch: 0.6603338068181818, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 12: 1.099609375, mean for epoch: 0.6969401041666666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 13: 1.2275390625, mean for epoch: 0.7377554086538461, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:30,643] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:30,644] [INFO] [timer.py:207:stop] 0/280, RunningAvgSamplesPerSec=85.88908387742855, CurrSamplesPerSec=84.11824635995347, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 14: 0.56005859375, mean for epoch: 0.7250627790178571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 15: 0.7880859375, mean for epoch: 0.7292643229166667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 16: 0.6875, mean for epoch: 0.726654052734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 17: 0.56005859375, mean for epoch: 0.7168543198529411, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 18: 0.498046875, mean for epoch: 0.7046983506944444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 19: 0.5830078125, mean for epoch: 0.6982935855263158, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 20: 0.5390625, mean for epoch: 0.69033203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 21: 0.57373046875, mean for epoch: 0.6847795758928571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 22: 0.58935546875, mean for epoch: 0.6804421164772727, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 23: 0.58935546875, mean for epoch: 0.6764818274456522, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:31,330] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:31,331] [INFO] [timer.py:207:stop] 0/290, RunningAvgSamplesPerSec=85.50105600879003, CurrSamplesPerSec=86.04794866218883, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 24: 0.5205078125, mean for epoch: 0.66998291015625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 25: 1.2666015625, mean for epoch: 0.69384765625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 26: 0.58984375, mean for epoch: 0.6898475060096154, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 27: 1.2275390625, mean for epoch: 0.7097620081018519, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 28: 3.310546875, mean for epoch: 0.8026471819196429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 29: 0.57763671875, mean for epoch: 0.7948882004310345, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 30: 0.486328125, mean for epoch: 0.7846028645833333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 31: 0.56689453125, mean for epoch: 0.7775800151209677, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 32: 0.62158203125, mean for epoch: 0.772705078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 33: 0.59326171875, mean for epoch: 0.7672674005681818, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:31,943] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:31,943] [INFO] [timer.py:207:stop] 0/300, RunningAvgSamplesPerSec=85.473505415531, CurrSamplesPerSec=82.96352559537938, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 34: 0.5107421875, mean for epoch: 0.7597225413602942, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 35: 0.62353515625, mean for epoch: 0.7558314732142857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 36: 2.0, mean for epoch: 0.7903917100694444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 37: 0.5732421875, mean for epoch: 0.7845228040540541, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 38: 1.361328125, mean for epoch: 0.7997018914473685, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 39: 0.5341796875, mean for epoch: 0.7928936298076923, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 40: 0.78173828125, mean for epoch: 0.79261474609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 41: 0.662109375, mean for epoch: 0.7894316882621951, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 42: 0.8115234375, mean for epoch: 0.7899576822916666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 43: 0.82421875, mean for epoch: 0.7907544513081395, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:32,564] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:32,564] [INFO] [timer.py:207:stop] 0/310, RunningAvgSamplesPerSec=85.42250357121296, CurrSamplesPerSec=85.99361142889947, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 44: 0.74267578125, mean for epoch: 0.7896617542613636, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 45: 0.440185546875, mean for epoch: 0.7818956163194445, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 46: 0.80810546875, mean for epoch: 0.7824653957201086, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 47: 0.56591796875, mean for epoch: 0.7778580036569149, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 48: 0.6357421875, mean for epoch: 0.7748972574869791, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 49: 0.521484375, mean for epoch: 0.7697255660076531, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 50: 0.5927734375, mean for epoch: 0.7661865234375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 51: 0.81982421875, mean for epoch: 0.7672382429534313, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 52: 0.441650390625, mean for epoch: 0.7609769381009616, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 53: 0.4853515625, mean for epoch: 0.7557764593160378, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:33,176] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:33,176] [INFO] [timer.py:207:stop] 0/320, RunningAvgSamplesPerSec=85.40752754710712, CurrSamplesPerSec=87.69630924403482, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 54: 0.57958984375, mean for epoch: 0.7525137442129629, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 55: 0.7421875, mean for epoch: 0.7523259943181818, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 56: 0.80712890625, mean for epoch: 0.7533046177455357, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 57: 0.53466796875, mean for epoch: 0.7494688870614035, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 58: 0.8759765625, mean for epoch: 0.7516500538793104, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 59: 1.2294921875, mean for epoch: 0.7597490730932204, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 60: 0.65625, mean for epoch: 0.7580240885416667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 61: 0.80517578125, mean for epoch: 0.7587970671106558, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 62: 0.6572265625, mean for epoch: 0.7571588331653226, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 63: 0.94677734375, mean for epoch: 0.7601686507936508, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:33,790] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:33,790] [INFO] [timer.py:207:stop] 0/330, RunningAvgSamplesPerSec=85.38511884829357, CurrSamplesPerSec=84.12701978466328, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 64: 0.5908203125, mean for epoch: 0.7575225830078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 65: 0.685546875, mean for epoch: 0.7564152644230769, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 66: 1.8291015625, mean for epoch: 0.7726680871212122, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 67: 0.5126953125, mean for epoch: 0.7687878964552238, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 68: 0.89306640625, mean for epoch: 0.7706155215992647, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 69: 0.5654296875, mean for epoch: 0.7676418138586957, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 70: 0.77880859375, mean for epoch: 0.7678013392857143, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 71: 1.9208984375, mean for epoch: 0.7840421434859155, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 72: 1.279296875, mean for epoch: 0.7909206814236112, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 73: 3.041015625, mean for epoch: 0.8217438998287672, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:34,408] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:34,408] [INFO] [timer.py:207:stop] 0/340, RunningAvgSamplesPerSec=85.34081262129844, CurrSamplesPerSec=81.6568480482819, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 74: 0.49853515625, mean for epoch: 0.8173762141047297, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 75: 1.1669921875, mean for epoch: 0.8220377604166667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 76: 0.53271484375, mean for epoch: 0.8182308799342105, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 77: 0.6103515625, mean for epoch: 0.815531148538961, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 78: 0.490966796875, mean for epoch: 0.8113700671073718, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 79: 1.7607421875, mean for epoch: 0.8233874357199367, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 80: 0.67431640625, mean for epoch: 0.8215240478515625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 81: 0.7900390625, mean for epoch: 0.8211353443287037, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 82: 0.775390625, mean for epoch: 0.8205774818978658, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 83: 0.494873046875, mean for epoch: 0.8166533320783133, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:35,021] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:35,021] [INFO] [timer.py:207:stop] 0/350, RunningAvgSamplesPerSec=85.32793177552635, CurrSamplesPerSec=87.09139157554641, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 84: 1.970703125, mean for epoch: 0.8303920200892857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 85: 0.525390625, mean for epoch: 0.8268037683823529, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 86: 0.61181640625, mean for epoch: 0.8243039153343024, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 87: 0.53271484375, mean for epoch: 0.8209523168103449, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 88: 0.53271484375, mean for epoch: 0.8176768909801136, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 89: 1.7744140625, mean for epoch: 0.8284267468398876, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 90: 0.58251953125, mean for epoch: 0.8256944444444444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 91: 0.572265625, mean for epoch: 0.8229095123626373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 92: 0.498291015625, mean for epoch: 0.819381050441576, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 93: 0.62744140625, mean for epoch: 0.8173171832997311, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:35,628] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:35,629] [INFO] [timer.py:207:stop] 0/360, RunningAvgSamplesPerSec=85.33279504529501, CurrSamplesPerSec=83.57817799227645, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 94: 1.1962890625, mean for epoch: 0.8213487990359043, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 95: 0.56787109375, mean for epoch: 0.8186806126644737, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 96: 0.4921875, mean for epoch: 0.8152796427408854, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 97: 0.4990234375, mean for epoch: 0.8120192694909794, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 98: 0.5556640625, mean for epoch: 0.8094034000318877, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 99: 0.77783203125, mean for epoch: 0.8090844973169192, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 100: 0.459716796875, mean for epoch: 0.8055908203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 101: 0.591796875, mean for epoch: 0.8034740485767327, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 102: 0.5869140625, mean for epoch: 0.8013509114583334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 103: 0.60888671875, mean for epoch: 0.7994823270631068, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:36,249] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:36,249] [INFO] [timer.py:207:stop] 0/370, RunningAvgSamplesPerSec=85.28331360651714, CurrSamplesPerSec=83.58484023579021, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 104: 0.7978515625, mean for epoch: 0.7994666466346154, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 105: 0.4931640625, mean for epoch: 0.7965494791666666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 106: 0.76025390625, mean for epoch: 0.7962070681014151, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 107: 0.62255859375, mean for epoch: 0.7945841851635514, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 108: 0.5126953125, mean for epoch: 0.7919741030092593, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 109: 0.53857421875, mean for epoch: 0.7896493334288991, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 110: 0.7841796875, mean for epoch: 0.789599609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 111: 0.578125, mean for epoch: 0.787694432713964, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 112: 0.92236328125, mean for epoch: 0.7888968331473214, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 113: 1.2216796875, mean for epoch: 0.7927267699115044, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:36,855] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:36,856] [INFO] [timer.py:207:stop] 0/380, RunningAvgSamplesPerSec=85.2951495524472, CurrSamplesPerSec=83.77382307707671, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 114: 0.52099609375, mean for epoch: 0.7903431674890351, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 115: 0.482666015625, mean for epoch: 0.7876677139945653, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 116: 0.50537109375, mean for epoch: 0.7852341224407328, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 117: 1.8193359375, mean for epoch: 0.7940725994925214, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 118: 0.72509765625, mean for epoch: 0.7934880660752118, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 119: 0.49755859375, mean for epoch: 0.7910012637867647, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 120: 0.564453125, mean for epoch: 0.7891133626302084, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 121: 0.81298828125, mean for epoch: 0.7893106760072314, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 122: 0.83544921875, mean for epoch: 0.7896888607838115, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 123: 0.48095703125, mean for epoch: 0.7871788459095529, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:37,462] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:37,462] [INFO] [timer.py:207:stop] 0/390, RunningAvgSamplesPerSec=85.30024193256214, CurrSamplesPerSec=82.5107901497834, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 124: 0.5712890625, mean for epoch: 0.7854377992691532, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 125: 0.55029296875, mean for epoch: 0.783556640625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 126: 1.1181640625, mean for epoch: 0.7862122550843254, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 127: 0.5498046875, mean for epoch: 0.7843507781742126, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 128: 0.56005859375, mean for epoch: 0.7825984954833984, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 129: 0.498046875, mean for epoch: 0.7803926689680233, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 130: 0.90673828125, mean for epoch: 0.7813645582932692, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 131: 0.615234375, mean for epoch: 0.7800963889551527, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 132: 0.464599609375, mean for epoch: 0.7777062618371212, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 133: 0.5947265625, mean for epoch: 0.7763304746240601, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:38,065] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:38,066] [INFO] [timer.py:207:stop] 0/400, RunningAvgSamplesPerSec=85.31996649950355, CurrSamplesPerSec=85.46583040928523, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 134: 0.461181640625, mean for epoch: 0.773978617653918, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 135: 0.51220703125, mean for epoch: 0.7720395688657408, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 136: 0.72900390625, mean for epoch: 0.7717231301700368, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 137: 0.943359375, mean for epoch: 0.772975949475365, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 138: 0.466552734375, mean for epoch: 0.7707554913949275, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 139: 0.462158203125, mean for epoch: 0.7685353670188849, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 140: 0.6396484375, mean for epoch: 0.76761474609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 141: 0.5068359375, mean for epoch: 0.7657652509973404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 142: 0.84912109375, mean for epoch: 0.7663522639744719, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 143: 0.51708984375, mean for epoch: 0.7646091701267482, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:38,675] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:38,676] [INFO] [timer.py:207:stop] 0/410, RunningAvgSamplesPerSec=85.32574533030082, CurrSamplesPerSec=84.67217648650067, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 144: 0.791015625, mean for epoch: 0.7647925482855903, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 145: 0.53759765625, mean for epoch: 0.7632256869612069, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 146: 1.1630859375, mean for epoch: 0.7659644558005136, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 147: 1.7431640625, mean for epoch: 0.7726120721726191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 148: 0.8935546875, mean for epoch: 0.7734292520059122, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 149: 0.68994140625, mean for epoch: 0.7728689308934564, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 150: 0.74609375, mean for epoch: 0.7726904296875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 151: 1.8203125, mean for epoch: 0.7796283241928808, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 152: 0.49853515625, mean for epoch: 0.7777790270353618, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 153: 0.58935546875, mean for epoch: 0.7765475005106209, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:39,286] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:39,286] [INFO] [timer.py:207:stop] 0/420, RunningAvgSamplesPerSec=85.32125951691309, CurrSamplesPerSec=82.94941520352184, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 154: 0.64501953125, mean for epoch: 0.7756934227881493, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 155: 1.3310546875, mean for epoch: 0.7792763986895161, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 156: 1.3046875, mean for epoch: 0.7826444185697116, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 157: 0.80029296875, mean for epoch: 0.7827568297173567, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 158: 0.60205078125, mean for epoch: 0.7816131205498418, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 159: 0.71533203125, mean for epoch: 0.7811962583529874, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 160: 0.52392578125, mean for epoch: 0.7795883178710937, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 161: 1.8291015625, mean for epoch: 0.7861070336762422, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 162: 0.5966796875, mean for epoch: 0.7849377290702161, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 163: 0.82666015625, mean for epoch: 0.785193694881135, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:39,890] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:39,890] [INFO] [timer.py:207:stop] 0/430, RunningAvgSamplesPerSec=85.33693632164314, CurrSamplesPerSec=85.70578523204682, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 164: 1.767578125, mean for epoch: 0.7911838438452744, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 165: 0.5, mean for epoch: 0.7894190932765152, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 166: 0.59521484375, mean for epoch: 0.7882491881588856, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 167: 1.0712890625, mean for epoch: 0.7899440377058383, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 168: 0.61865234375, mean for epoch: 0.7889244442894345, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 169: 0.7509765625, mean for epoch: 0.7886999006102071, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 170: 0.51611328125, mean for epoch: 0.7870964499080882, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 171: 0.74951171875, mean for epoch: 0.7868766561586257, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 172: 0.72314453125, mean for epoch: 0.7865061205486918, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 173: 0.564453125, mean for epoch: 0.7852225772218208, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:40,502] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:40,502] [INFO] [timer.py:207:stop] 0/440, RunningAvgSamplesPerSec=85.33209508392454, CurrSamplesPerSec=81.91456036122601, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 174: 0.720703125, mean for epoch: 0.7848517757722702, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 175: 2.115234375, mean for epoch: 0.7924539620535714, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 176: 1.6025390625, mean for epoch: 0.7970567183061079, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 177: 0.51513671875, mean for epoch: 0.7954639499470338, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 178: 0.50634765625, mean for epoch: 0.7938397011060393, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 179: 0.71923828125, mean for epoch: 0.7934229333973464, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 180: 0.58447265625, mean for epoch: 0.7922620985243055, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 181: 0.58837890625, mean for epoch: 0.7911356720476519, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 182: 0.5166015625, mean for epoch: 0.7896272428743132, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 183: 0.49072265625, mean for epoch: 0.787993884477459, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:41,114] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:41,114] [INFO] [timer.py:207:stop] 0/450, RunningAvgSamplesPerSec=85.31794827284124, CurrSamplesPerSec=80.87993459111735, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 184: 0.7119140625, mean for epoch: 0.7875804071841033, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 185: 0.7568359375, mean for epoch: 0.7874142208614865, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 186: 0.52197265625, mean for epoch: 0.7859871156754032, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 187: 1.1611328125, mean for epoch: 0.7879932423963903, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 188: 1.1728515625, mean for epoch: 0.7900403611203457, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 189: 0.74169921875, mean for epoch: 0.789784587880291, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 190: 0.76708984375, mean for epoch: 0.7896651418585526, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 191: 0.63427734375, mean for epoch: 0.788851593177356, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 192: 0.441162109375, mean for epoch: 0.7870407104492188, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 193: 0.53125, mean for epoch: 0.7857153699805699, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:41,711] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:41,711] [INFO] [timer.py:207:stop] 0/460, RunningAvgSamplesPerSec=85.35480207019708, CurrSamplesPerSec=86.91993335378035, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 194: 0.52490234375, mean for epoch: 0.7843709729381443, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 195: 2.12890625, mean for epoch: 0.7912660256410257, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 196: 0.52099609375, mean for epoch: 0.7898870974170918, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 197: 0.73291015625, mean for epoch: 0.7895978743654822, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 198: 1.4169921875, mean for epoch: 0.7927665325126263, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 199: 0.5185546875, mean for epoch: 0.7913885835427136, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 200: 0.51318359375, mean for epoch: 0.78999755859375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 201: 0.454345703125, mean for epoch: 0.7883276488650498, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 202: 0.4296875, mean for epoch: 0.7865522025835396, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 203: 0.5517578125, mean for epoch: 0.7853955799722906, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:42,346] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:42,346] [INFO] [timer.py:207:stop] 0/470, RunningAvgSamplesPerSec=85.28551989078292, CurrSamplesPerSec=84.2794966905515, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 204: 0.53076171875, mean for epoch: 0.7841473747702206, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 205: 0.5107421875, mean for epoch: 0.7828136909298781, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 206: 1.7880859375, mean for epoch: 0.7876936532918689, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 207: 0.54736328125, mean for epoch: 0.7865326370018116, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 208: 0.47705078125, mean for epoch: 0.7850447434645432, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 209: 0.60302734375, mean for epoch: 0.7841738468151914, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 210: 2.068359375, mean for epoch: 0.7902890159970238, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 211: 0.51025390625, mean for epoch: 0.788961835382109, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 212: 0.8828125, mean for epoch: 0.7894045271963444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 213: 0.460205078125, mean for epoch: 0.7878589898767606, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:42,969] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:42,970] [INFO] [timer.py:207:stop] 0/480, RunningAvgSamplesPerSec=85.25067362146093, CurrSamplesPerSec=84.26087236025843, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 214: 0.53125, mean for epoch: 0.7866598824474299, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 215: 0.626953125, mean for epoch: 0.7859170603197675, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 216: 1.1279296875, mean for epoch: 0.7875004521122685, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 217: 0.6181640625, mean for epoch: 0.7867201000864056, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 218: 0.5029296875, mean for epoch: 0.7854183092029816, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 219: 1.517578125, mean for epoch: 0.7887615047089042, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 220: 0.611328125, mean for epoch: 0.7879549893465909, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 221: 0.6279296875, mean for epoch: 0.7872308929581447, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 222: 0.5263671875, mean for epoch: 0.7860558312218469, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 223: 0.576171875, mean for epoch: 0.7851146475616592, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:43,593] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:43,594] [INFO] [timer.py:207:stop] 0/490, RunningAvgSamplesPerSec=85.2126517031774, CurrSamplesPerSec=85.4250985759442, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 224: 0.478271484375, mean for epoch: 0.7837448120117188, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 225: 1.8037109375, mean for epoch: 0.7882779947916667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 226: 0.501953125, mean for epoch: 0.7870110705890486, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 227: 0.619140625, mean for epoch: 0.7862715532075991, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 228: 0.62255859375, mean for epoch: 0.7855535139117324, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 229: 0.475830078125, mean for epoch: 0.7842010098253275, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 230: 0.57470703125, mean for epoch: 0.7832901664402174, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 231: 0.50634765625, mean for epoch: 0.7820912811147186, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 232: 0.53369140625, mean for epoch: 0.7810205919989224, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 233: 0.84521484375, mean for epoch: 0.7812961038090128, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:44,218] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:44,219] [INFO] [timer.py:207:stop] 0/500, RunningAvgSamplesPerSec=85.17712716231685, CurrSamplesPerSec=80.576945982395, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 234: 0.71826171875, mean for epoch: 0.7810267260950855, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 235: 0.60205078125, mean for epoch: 0.7802651263297873, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 236: 0.6337890625, mean for epoch: 0.7796444650423728, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 237: 0.5205078125, mean for epoch: 0.7785510614451476, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 238: 0.5947265625, mean for epoch: 0.7777786896008403, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 239: 0.56982421875, mean for epoch: 0.7769085872123431, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 240: 0.85986328125, mean for epoch: 0.7772542317708333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 241: 0.7919921875, mean for epoch: 0.7773153851141079, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 242: 0.60205078125, mean for epoch: 0.7765911512138429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 243: 0.64990234375, mean for epoch: 0.7760697980967078, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:44,841] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:44,841] [INFO] [timer.py:207:stop] 0/510, RunningAvgSamplesPerSec=85.14891279828935, CurrSamplesPerSec=86.15187429393036, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 244: 0.5537109375, mean for epoch: 0.7751584912909836, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 245: 0.50048828125, mean for epoch: 0.7740373883928572, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 246: 0.50390625, mean for epoch: 0.7729392943343496, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 247: 3.044921875, mean for epoch: 0.7821376043775303, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 248: 1.78125, mean for epoch: 0.7861662833921371, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 249: 0.58203125, mean for epoch: 0.7853464639809237, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 250: 0.5703125, mean for epoch: 0.784486328125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 251: 1.1162109375, mean for epoch: 0.7858079401145418, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 252: 0.52490234375, mean for epoch: 0.7847726004464286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 253: 0.609375, mean for epoch: 0.784079329298419, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:45,482] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:45,482] [INFO] [timer.py:207:stop] 0/520, RunningAvgSamplesPerSec=85.06553632337067, CurrSamplesPerSec=61.56162027129769, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 254: 1.5185546875, mean for epoch: 0.7869709645669292, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 255: 0.72216796875, mean for epoch: 0.7867168351715687, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 256: 2.248046875, mean for epoch: 0.7924251556396484, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 257: 0.481201171875, mean for epoch: 0.7912141673759727, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 258: 0.55810546875, mean for epoch: 0.7903106452882752, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 259: 0.978515625, mean for epoch: 0.7910373054416023, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 260: 0.6005859375, mean for epoch: 0.7903048001802885, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 261: 1.35546875, mean for epoch: 0.7924701792983716, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 262: 0.50048828125, mean for epoch: 0.7913557445729962, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 263: 0.5576171875, mean for epoch: 0.7904670048122624, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:46,134] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:46,135] [INFO] [timer.py:207:stop] 0/530, RunningAvgSamplesPerSec=84.95975113130817, CurrSamplesPerSec=84.48116532857448, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   2:   Loss at step 264: 2.3984375, mean for epoch: 0.7965578021425189, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 265: 0.55810546875, mean for epoch: 0.7956579820165094, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 266: 0.529296875, mean for epoch: 0.7946566244713346, mem_alloc: 1023816704\n",
            " Run   2, iteration:   2:   Loss at step 267: 0.7236328125, mean for epoch: 0.7943906176849251, mem_alloc: 1023816704\n",
            "Loss after iteration 2 ; MSE: 0.79443359375, MAE: 0.491455078125\n",
            "Connected by ('127.0.0.1', 56888)\n",
            "\u001b[94mReceived training result: b'2;0.79443;0.49146' \u001b[0m\n",
            "Time per iteration 16.987037420272827, memory OrderedDict([('active.all.allocated', 714204), ('active.all.current', 7), ('active.all.freed', 714197), ('active.all.peak', 197), ('active.large_pool.allocated', 1570), ('active.large_pool.current', 3), ('active.large_pool.freed', 1567), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 712634), ('active.small_pool.current', 4), ('active.small_pool.freed', 712630), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 574516610560), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 574511476736), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 535617327104), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 535613657600), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 38899283456), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 38897819136), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 574516610560), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 574512088576), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 535617327104), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 535613657600), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 38899283456), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 38898430976), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 714204), ('allocation.all.current', 6), ('allocation.all.freed', 714198), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 1570), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 1567), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 712634), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 712631), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 303360), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 303354), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 518), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 516), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 302842), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 302838), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 47080025600), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 47059993600), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 1451042816), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 1433740800), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 45628982784), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 45626252800), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   2, iteration:   3:   Loss at step 1: 0.55078125, mean for epoch: 0.55078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 2: 0.8740234375, mean for epoch: 0.71240234375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 3: 0.45166015625, mean for epoch: 0.62548828125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 4: 0.77685546875, mean for epoch: 0.663330078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 5: 0.5029296875, mean for epoch: 0.63125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 6: 0.5458984375, mean for epoch: 0.6170247395833334, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:47,072] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:47,072] [INFO] [timer.py:207:stop] 0/540, RunningAvgSamplesPerSec=84.90459552795333, CurrSamplesPerSec=84.84379677803041, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 7: 0.5537109375, mean for epoch: 0.6079799107142857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 8: 0.499755859375, mean for epoch: 0.594451904296875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 9: 0.57373046875, mean for epoch: 0.5921495225694444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 10: 0.5400390625, mean for epoch: 0.5869384765625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 11: 0.58837890625, mean for epoch: 0.5870694247159091, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 12: 0.5322265625, mean for epoch: 0.5824991861979166, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 13: 0.55859375, mean for epoch: 0.5806603064903846, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 14: 2.171875, mean for epoch: 0.6943184988839286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 15: 0.755859375, mean for epoch: 0.6984212239583333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 16: 0.461669921875, mean for epoch: 0.683624267578125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:47,696] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:47,697] [INFO] [timer.py:207:stop] 0/550, RunningAvgSamplesPerSec=84.87862712259475, CurrSamplesPerSec=86.8371538359613, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 17: 3.224609375, mean for epoch: 0.8330939797794118, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 18: 0.52734375, mean for epoch: 0.8161078559027778, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 19: 0.467529296875, mean for epoch: 0.7977616159539473, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 20: 0.6513671875, mean for epoch: 0.79044189453125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 21: 0.56103515625, mean for epoch: 0.7795177641369048, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 22: 0.64013671875, mean for epoch: 0.7731822620738636, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 23: 0.6962890625, mean for epoch: 0.7698390794836957, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 24: 1.0078125, mean for epoch: 0.779754638671875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 25: 1.2021484375, mean for epoch: 0.796650390625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 26: 0.57421875, mean for epoch: 0.7880953275240384, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:48,307] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:48,308] [INFO] [timer.py:207:stop] 0/560, RunningAvgSamplesPerSec=84.88900372068213, CurrSamplesPerSec=86.95525259561482, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 27: 0.8427734375, mean for epoch: 0.7901204427083334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 28: 1.25, mean for epoch: 0.8065447126116071, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 29: 1.251953125, mean for epoch: 0.8219036233836207, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 30: 1.1513671875, mean for epoch: 0.8328857421875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 31: 1.9765625, mean for epoch: 0.8697785408266129, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 32: 1.3759765625, mean for epoch: 0.8855972290039062, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 33: 0.75244140625, mean for epoch: 0.8815622040719697, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 34: 0.72265625, mean for epoch: 0.8768884995404411, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 35: 1.7958984375, mean for epoch: 0.9031459263392857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 36: 0.50537109375, mean for epoch: 0.8920966254340278, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:48,920] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:48,920] [INFO] [timer.py:207:stop] 0/570, RunningAvgSamplesPerSec=84.89501540847424, CurrSamplesPerSec=83.77014212330135, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 37: 0.583984375, mean for epoch: 0.8837692673141891, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 38: 0.6826171875, mean for epoch: 0.8784757915296053, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 39: 0.51806640625, mean for epoch: 0.8692345252403846, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 40: 1.7470703125, mean for epoch: 0.891180419921875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 41: 0.76611328125, mean for epoch: 0.8881300019054879, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 42: 0.5146484375, mean for epoch: 0.8792375837053571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 43: 0.85302734375, mean for epoch: 0.8786280432412791, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 44: 0.49951171875, mean for epoch: 0.8700117631392046, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 45: 1.7373046875, mean for epoch: 0.8892849392361111, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 46: 0.43505859375, mean for epoch: 0.879410453464674, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:49,532] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:49,532] [INFO] [timer.py:207:stop] 0/580, RunningAvgSamplesPerSec=84.89263463787904, CurrSamplesPerSec=87.46843731883, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 47: 1.154296875, mean for epoch: 0.885259100731383, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 48: 0.57470703125, mean for epoch: 0.8787892659505209, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 49: 0.73974609375, mean for epoch: 0.8759516501913265, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 50: 0.509765625, mean for epoch: 0.8686279296875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 51: 1.7177734375, mean for epoch: 0.8852778416053921, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 52: 0.482177734375, mean for epoch: 0.8775259164663461, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 53: 1.4384765625, mean for epoch: 0.8881098909198113, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 54: 0.556640625, mean for epoch: 0.8819715711805556, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 55: 0.54638671875, mean for epoch: 0.8758700284090909, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 56: 0.5595703125, mean for epoch: 0.8702218191964286, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:50,151] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:50,152] [INFO] [timer.py:207:stop] 0/590, RunningAvgSamplesPerSec=84.87676156093929, CurrSamplesPerSec=82.84030400227527, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 57: 0.463134765625, mean for epoch: 0.8630799410635965, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 58: 0.480712890625, mean for epoch: 0.8564874057112069, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 59: 0.6005859375, mean for epoch: 0.852150092690678, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 60: 0.59765625, mean for epoch: 0.8479085286458333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 61: 0.4931640625, mean for epoch: 0.8420930455942623, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 62: 0.58984375, mean for epoch: 0.8380245085685484, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 63: 2.943359375, mean for epoch: 0.8714425223214286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 64: 0.51025390625, mean for epoch: 0.8657989501953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 65: 1.2060546875, mean for epoch: 0.8710336538461538, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 66: 0.498779296875, mean for epoch: 0.8653934363162878, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:50,771] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:50,771] [INFO] [timer.py:207:stop] 0/600, RunningAvgSamplesPerSec=84.86881317103358, CurrSamplesPerSec=85.6592259777392, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 67: 0.5302734375, mean for epoch: 0.8603916452891791, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 68: 0.59375, mean for epoch: 0.8564704446231618, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 69: 0.436767578125, mean for epoch: 0.850387794384058, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 70: 0.5625, mean for epoch: 0.8462751116071429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 71: 0.7744140625, mean for epoch: 0.8452629841549296, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 72: 0.68408203125, mean for epoch: 0.8430243598090278, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 73: 0.54541015625, mean for epoch: 0.838947452910959, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 74: 0.48046875, mean for epoch: 0.8341031461148649, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 75: 0.95263671875, mean for epoch: 0.83568359375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 76: 0.484375, mean for epoch: 0.8310611122532895, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:51,387] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:51,387] [INFO] [timer.py:207:stop] 0/610, RunningAvgSamplesPerSec=84.86454757573068, CurrSamplesPerSec=83.10818736625188, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 77: 0.60888671875, mean for epoch: 0.8281757305194806, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 78: 0.55126953125, mean for epoch: 0.8246256510416666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 79: 0.43505859375, mean for epoch: 0.8196944224683544, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 80: 1.3203125, mean for epoch: 0.8259521484375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 81: 1.1123046875, mean for epoch: 0.8294873649691358, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 82: 0.472412109375, mean for epoch: 0.8251327886814024, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 83: 1.759765625, mean for epoch: 0.8363934252635542, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 84: 0.53076171875, mean for epoch: 0.8327549525669643, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 85: 0.461669921875, mean for epoch: 0.8283892463235294, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 86: 0.479248046875, mean for epoch: 0.824329464934593, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:51,999] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:51,999] [INFO] [timer.py:207:stop] 0/620, RunningAvgSamplesPerSec=84.86173731636038, CurrSamplesPerSec=82.14010982554815, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 87: 0.4697265625, mean for epoch: 0.8202535695043104, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 88: 0.495361328125, mean for epoch: 0.8165616122159091, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 89: 1.1748046875, mean for epoch: 0.8205868153089888, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 90: 0.57421875, mean for epoch: 0.8178493923611111, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 91: 0.55322265625, mean for epoch: 0.81494140625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 92: 0.58935546875, mean for epoch: 0.8124893851902174, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 93: 0.6103515625, mean for epoch: 0.8103158602150538, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 94: 0.8056640625, mean for epoch: 0.8102663730053191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 95: 0.433349609375, mean for epoch: 0.806298828125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 96: 0.7314453125, mean for epoch: 0.8055191040039062, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:52,607] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:52,608] [INFO] [timer.py:207:stop] 0/630, RunningAvgSamplesPerSec=84.87499751966739, CurrSamplesPerSec=80.85342956391662, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 97: 0.662109375, mean for epoch: 0.804040653189433, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 98: 0.476318359375, mean for epoch: 0.8006965481505102, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 99: 0.62060546875, mean for epoch: 0.7988774463383839, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 100: 0.505859375, mean for epoch: 0.795947265625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 101: 0.60693359375, mean for epoch: 0.7940758431311881, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 102: 0.7978515625, mean for epoch: 0.7941128599877451, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 103: 1.8466796875, mean for epoch: 0.8043319554004854, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 104: 1.201171875, mean for epoch: 0.8081477238581731, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 105: 0.52490234375, mean for epoch: 0.8054501488095238, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 106: 1.3056640625, mean for epoch: 0.8101691479952831, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:53,215] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:53,216] [INFO] [timer.py:207:stop] 0/640, RunningAvgSamplesPerSec=84.8828279156401, CurrSamplesPerSec=80.25225776825349, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 107: 1.5927734375, mean for epoch: 0.817483206775701, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 108: 0.481201171875, mean for epoch: 0.8143694842303241, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 109: 0.52880859375, mean for epoch: 0.8117496595470184, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 110: 0.53125, mean for epoch: 0.8091996626420455, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 111: 0.76220703125, mean for epoch: 0.8087763056024775, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 112: 0.482666015625, mean for epoch: 0.8058646065848214, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 113: 0.52392578125, mean for epoch: 0.8033695727323009, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 114: 0.5283203125, mean for epoch: 0.8009568599232456, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 115: 0.4794921875, mean for epoch: 0.7981615149456521, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 116: 0.71533203125, mean for epoch: 0.7974474676724138, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:53,822] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:53,822] [INFO] [timer.py:207:stop] 0/650, RunningAvgSamplesPerSec=84.8923721705765, CurrSamplesPerSec=86.30255144032922, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 117: 0.7607421875, mean for epoch: 0.7971337473290598, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 118: 1.7421875, mean for epoch: 0.8051426774364406, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 119: 0.481201171875, mean for epoch: 0.8024204799107143, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 120: 0.61962890625, mean for epoch: 0.800897216796875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 121: 0.5595703125, mean for epoch: 0.798902779571281, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 122: 0.75830078125, mean for epoch: 0.7985699763063525, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 123: 0.49853515625, mean for epoch: 0.7961306688262195, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 124: 0.51123046875, mean for epoch: 0.7938330865675404, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 125: 0.4853515625, mean for epoch: 0.791365234375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 126: 0.74072265625, mean for epoch: 0.7909633091517857, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:54,433] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:54,434] [INFO] [timer.py:207:stop] 0/660, RunningAvgSamplesPerSec=84.89651575001547, CurrSamplesPerSec=79.41080469084287, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 127: 0.62060546875, mean for epoch: 0.7896219088336615, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 128: 0.86669921875, mean for epoch: 0.7902240753173828, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 129: 0.58935546875, mean for epoch: 0.7886669543362403, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 130: 0.53369140625, mean for epoch: 0.7867056039663461, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 131: 0.494140625, mean for epoch: 0.7844722835162213, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 132: 1.705078125, mean for epoch: 0.7914465701941288, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 133: 0.509765625, mean for epoch: 0.7893286683505639, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 134: 0.77099609375, mean for epoch: 0.7891918580923507, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 135: 1.1611328125, mean for epoch: 0.7919469762731481, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 136: 0.82177734375, mean for epoch: 0.7921663172104779, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:55,041] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:55,042] [INFO] [timer.py:207:stop] 0/670, RunningAvgSamplesPerSec=84.90949927921352, CurrSamplesPerSec=86.50261097682707, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 137: 0.50830078125, mean for epoch: 0.7900943059990876, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 138: 0.5751953125, mean for epoch: 0.7885370669157609, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 139: 0.57763671875, mean for epoch: 0.7870197982239209, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 140: 0.474365234375, mean for epoch: 0.7847865513392858, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 141: 0.71826171875, mean for epoch: 0.7843147440159575, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 142: 0.77490234375, mean for epoch: 0.7842484595070423, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 143: 0.53466796875, mean for epoch: 0.7825031413898601, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 144: 1.13671875, mean for epoch: 0.7849629720052084, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 145: 0.54541015625, mean for epoch: 0.7833108836206897, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 146: 0.55029296875, mean for epoch: 0.781714870505137, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:55,659] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:55,660] [INFO] [timer.py:207:stop] 0/680, RunningAvgSamplesPerSec=84.90287076951299, CurrSamplesPerSec=83.64551549742939, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 147: 0.619140625, mean for epoch: 0.7806089232568028, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 148: 0.74755859375, mean for epoch: 0.7803856102195946, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 149: 0.4765625, mean for epoch: 0.778346528942953, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 150: 0.595703125, mean for epoch: 0.77712890625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 151: 0.67626953125, mean for epoch: 0.7764609633692053, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 152: 0.52099609375, mean for epoch: 0.7747802734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 153: 1.8330078125, mean for epoch: 0.7816967933006536, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 154: 0.5078125, mean for epoch: 0.7799183238636364, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 155: 0.62353515625, mean for epoch: 0.7789094002016129, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 156: 0.50830078125, mean for epoch: 0.7771747295673077, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:56,272] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:56,273] [INFO] [timer.py:207:stop] 0/690, RunningAvgSamplesPerSec=84.9027664407115, CurrSamplesPerSec=84.21925135837373, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 157: 0.455810546875, mean for epoch: 0.7751278239450637, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 158: 0.53466796875, mean for epoch: 0.7736059261273734, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 159: 0.72705078125, mean for epoch: 0.7733131264740566, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 160: 0.5517578125, mean for epoch: 0.7719284057617187, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 161: 0.60791015625, mean for epoch: 0.7709096588703416, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 162: 0.5673828125, mean for epoch: 0.7696533203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 163: 0.83447265625, mean for epoch: 0.7700509849501533, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 164: 0.65625, mean for epoch: 0.7693570765053354, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 165: 0.485595703125, mean for epoch: 0.7676373106060606, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 166: 1.759765625, mean for epoch: 0.7736139871987951, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:56,896] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:56,897] [INFO] [timer.py:207:stop] 0/700, RunningAvgSamplesPerSec=84.87863076533974, CurrSamplesPerSec=81.88033921069481, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 167: 0.5009765625, mean for epoch: 0.7719814277694611, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 168: 0.962890625, mean for epoch: 0.7731177920386905, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 169: 0.728515625, mean for epoch: 0.7728538738905325, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 170: 0.46142578125, mean for epoch: 0.7710219439338235, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 171: 0.473876953125, mean for epoch: 0.7692842539290936, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 172: 0.60595703125, mean for epoch: 0.7683346770530524, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 173: 0.50927734375, mean for epoch: 0.7668372358200867, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 174: 0.45068359375, mean for epoch: 0.7650202608656609, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 175: 0.5556640625, mean for epoch: 0.7638239397321429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 176: 1.1025390625, mean for epoch: 0.7657484574751421, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:57,501] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:57,502] [INFO] [timer.py:207:stop] 0/710, RunningAvgSamplesPerSec=84.8914572014407, CurrSamplesPerSec=86.23725245081913, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 177: 0.5693359375, mean for epoch: 0.7646387822210452, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 178: 0.50732421875, mean for epoch: 0.7631931947858146, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 179: 0.455322265625, mean for epoch: 0.7614732454608939, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 180: 0.7548828125, mean for epoch: 0.7614366319444444, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 181: 1.8974609375, mean for epoch: 0.7677130093232044, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 182: 0.5986328125, mean for epoch: 0.7667839972527473, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 183: 0.5263671875, mean for epoch: 0.7654702441939891, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 184: 0.51513671875, mean for epoch: 0.7641097359035326, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 185: 0.71630859375, mean for epoch: 0.7638513513513514, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 186: 1.9873046875, mean for epoch: 0.7704290574596774, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:58,117] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:58,117] [INFO] [timer.py:207:stop] 0/720, RunningAvgSamplesPerSec=84.89002873256223, CurrSamplesPerSec=85.84682140079414, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 187: 0.57373046875, mean for epoch: 0.7693771933489305, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 188: 0.46240234375, mean for epoch: 0.7677443484042553, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 189: 0.6083984375, mean for epoch: 0.7669012483465608, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 190: 0.5830078125, mean for epoch: 0.7659333881578947, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 191: 0.7373046875, mean for epoch: 0.7657834996727748, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 192: 0.537109375, mean for epoch: 0.7645924886067709, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 193: 0.50341796875, mean for epoch: 0.7632392527525906, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 194: 0.6337890625, mean for epoch: 0.7625719837306701, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 195: 0.498779296875, mean for epoch: 0.7612192007211539, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 196: 2.0078125, mean for epoch: 0.7675793706154337, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:58,730] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:58,730] [INFO] [timer.py:207:stop] 0/730, RunningAvgSamplesPerSec=84.88598890948084, CurrSamplesPerSec=86.94083311223136, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 197: 0.56494140625, mean for epoch: 0.7665507515069797, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 198: 1.640625, mean for epoch: 0.77096526791351, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 199: 0.67724609375, mean for epoch: 0.7704943172895728, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 200: 0.76806640625, mean for epoch: 0.770482177734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 201: 1.1513671875, mean for epoch: 0.7723771280317164, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 202: 0.5810546875, mean for epoch: 0.771429987237005, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 203: 0.833984375, mean for epoch: 0.7717381369304187, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 204: 0.55078125, mean for epoch: 0.7706550149356618, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 205: 1.86328125, mean for epoch: 0.7759848990091464, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 206: 0.59814453125, mean for epoch: 0.775121596253034, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:59,344] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:59,344] [INFO] [timer.py:207:stop] 0/740, RunningAvgSamplesPerSec=84.88274559462721, CurrSamplesPerSec=82.22835633626097, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 207: 0.5712890625, mean for epoch: 0.774136898022343, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 208: 1.3076171875, mean for epoch: 0.7767017071063702, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 209: 0.5078125, mean for epoch: 0.7754151558761961, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 210: 0.7119140625, mean for epoch: 0.775112769717262, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 211: 1.3779296875, mean for epoch: 0.7779697219342417, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 212: 0.49462890625, mean for epoch: 0.7766332086527122, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 213: 0.75244140625, mean for epoch: 0.7765196321156104, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 214: 0.57958984375, mean for epoch: 0.7755993994596962, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 215: 0.5615234375, mean for epoch: 0.7746036973110465, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 216: 0.73193359375, mean for epoch: 0.7744061505353009, mem_alloc: 1023816704\n",
            "[2022-10-31 19:02:59,948] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:02:59,948] [INFO] [timer.py:207:stop] 0/750, RunningAvgSamplesPerSec=84.8969645001034, CurrSamplesPerSec=87.11997341309404, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 217: 1.6796875, mean for epoch: 0.7785779539890553, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 218: 0.54638671875, mean for epoch: 0.7775128565797018, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 219: 0.472900390625, mean for epoch: 0.7761219320776256, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 220: 0.5927734375, mean for epoch: 0.7752885298295454, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 221: 0.59228515625, mean for epoch: 0.7744604602658371, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 222: 0.5380859375, mean for epoch: 0.7733957101632883, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 223: 0.61767578125, mean for epoch: 0.7726974145179372, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 224: 0.83056640625, mean for epoch: 0.7729557582310268, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 225: 0.517578125, mean for epoch: 0.7718207465277778, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 226: 0.485107421875, mean for epoch: 0.7705521034983407, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:00,570] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:00,570] [INFO] [timer.py:207:stop] 0/760, RunningAvgSamplesPerSec=84.87747579137812, CurrSamplesPerSec=84.65713720566923, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 227: 0.67138671875, mean for epoch: 0.7701152515831498, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 228: 0.5107421875, mean for epoch: 0.7689776504248903, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 229: 0.52294921875, mean for epoch: 0.7679032904612445, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 230: 0.525390625, mean for epoch: 0.7668488875679348, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 231: 0.61962890625, mean for epoch: 0.7662115716314936, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 232: 0.52197265625, mean for epoch: 0.7651588176858837, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 233: 0.5439453125, mean for epoch: 0.7642094035005365, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 234: 0.521484375, mean for epoch: 0.7631721170539529, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 235: 0.5224609375, mean for epoch: 0.7621478141622341, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 236: 0.453125, mean for epoch: 0.7608383954581568, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:01,193] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:01,194] [INFO] [timer.py:207:stop] 0/770, RunningAvgSamplesPerSec=84.85900484356891, CurrSamplesPerSec=81.58505510579613, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 237: 0.55078125, mean for epoch: 0.759952078388713, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 238: 0.44580078125, mean for epoch: 0.7586321149553571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 239: 2.376953125, mean for epoch: 0.7654033325706067, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 240: 0.60205078125, mean for epoch: 0.7647226969401042, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 241: 0.7080078125, mean for epoch: 0.7644873654693983, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 242: 0.490966796875, mean for epoch: 0.7633571151859504, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 243: 0.459716796875, mean for epoch: 0.7621075665509259, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 244: 1.8828125, mean for epoch: 0.7667006195568647, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 245: 0.56640625, mean for epoch: 0.7658830915178572, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 246: 1.1767578125, mean for epoch: 0.767553313960874, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:01,813] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:01,813] [INFO] [timer.py:207:stop] 0/780, RunningAvgSamplesPerSec=84.85226945242746, CurrSamplesPerSec=85.1265439991557, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 247: 0.51416015625, mean for epoch: 0.7665274307312753, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 248: 0.76611328125, mean for epoch: 0.7665257607736895, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 249: 0.7177734375, mean for epoch: 0.766329968310743, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 250: 0.52001953125, mean for epoch: 0.7653447265625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 251: 0.58740234375, mean for epoch: 0.7646357927664342, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 252: 0.77490234375, mean for epoch: 0.7646765330481151, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 253: 0.63525390625, mean for epoch: 0.7641649811635376, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 254: 0.62548828125, mean for epoch: 0.7636190099040354, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 255: 0.465576171875, mean for epoch: 0.7624502144607843, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 256: 0.609375, mean for epoch: 0.7618522644042969, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:02,423] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:02,423] [INFO] [timer.py:207:stop] 0/790, RunningAvgSamplesPerSec=84.86095663914259, CurrSamplesPerSec=87.02778296503787, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 257: 1.6650390625, mean for epoch: 0.765366609922179, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 258: 0.58740234375, mean for epoch: 0.7646768259447675, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 259: 0.68359375, mean for epoch: 0.7643637638754827, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 260: 0.5341796875, mean for epoch: 0.7634784405048077, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 261: 1.6923828125, mean for epoch: 0.7670374610871648, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 262: 0.6904296875, mean for epoch: 0.766745065004771, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 263: 0.486083984375, mean for epoch: 0.7656779126069392, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 264: 0.55078125, mean for epoch: 0.7648639100970644, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 265: 0.481689453125, mean for epoch: 0.7637953272405661, mem_alloc: 1023816704\n",
            " Run   2, iteration:   3:   Loss at step 266: 2.056640625, mean for epoch: 0.7686556479088346, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:03,024] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:03,024] [INFO] [timer.py:207:stop] 0/800, RunningAvgSamplesPerSec=84.8833840267638, CurrSamplesPerSec=87.88005263202005, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   3:   Loss at step 267: 0.405029296875, mean for epoch: 0.7672937514630149, mem_alloc: 1023816704\n",
            "Loss after iteration 3 ; MSE: 0.76708984375, MAE: 0.47509765625\n",
            "Connected by ('127.0.0.1', 34724)\n",
            "\u001b[94mReceived training result: b'3;0.76709;0.47510' \u001b[0m\n",
            "Time per iteration 16.892441908518474, memory OrderedDict([('active.all.allocated', 1075722), ('active.all.current', 7), ('active.all.freed', 1075715), ('active.all.peak', 197), ('active.large_pool.allocated', 2371), ('active.large_pool.current', 3), ('active.large_pool.freed', 2368), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1073351), ('active.small_pool.current', 4), ('active.small_pool.freed', 1073347), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 861827954176), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 861822820352), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 803448487424), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 803444817920), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 58379466752), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 58378002432), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 861827954176), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 861823432192), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 803448487424), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 803444817920), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 58379466752), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 58378614272), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1075722), ('allocation.all.current', 6), ('allocation.all.freed', 1075716), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 2371), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 2368), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1073351), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1073348), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 457065), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 457059), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 785), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 783), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 456280), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 456276), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 70663979008), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 70643947008), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 2191021568), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 2173719552), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 68472957440), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 68470227456), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   2, iteration:   4:   Loss at step 1: 0.775390625, mean for epoch: 0.775390625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 2: 0.6318359375, mean for epoch: 0.70361328125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 3: 0.4404296875, mean for epoch: 0.6158854166666666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 4: 0.8681640625, mean for epoch: 0.678955078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 5: 1.7109375, mean for epoch: 0.8853515625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 6: 0.55126953125, mean for epoch: 0.8296712239583334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 7: 0.78662109375, mean for epoch: 0.8235212053571429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 8: 0.5576171875, mean for epoch: 0.790283203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 9: 0.5244140625, mean for epoch: 0.7607421875, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:03,956] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:03,957] [INFO] [timer.py:207:stop] 0/810, RunningAvgSamplesPerSec=84.84224708450893, CurrSamplesPerSec=84.32422869228512, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 10: 0.525390625, mean for epoch: 0.73720703125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 11: 0.466552734375, mean for epoch: 0.7126020951704546, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 12: 0.8193359375, mean for epoch: 0.72149658203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 13: 0.54638671875, mean for epoch: 0.7080265925480769, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 14: 0.7490234375, mean for epoch: 0.7109549386160714, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 15: 0.49267578125, mean for epoch: 0.6964029947916667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 16: 0.56591796875, mean for epoch: 0.6882476806640625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 17: 0.61865234375, mean for epoch: 0.6841538373161765, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 18: 0.51025390625, mean for epoch: 0.6744927300347222, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 19: 0.38330078125, mean for epoch: 0.659166837993421, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:04,566] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:04,567] [INFO] [timer.py:207:stop] 0/820, RunningAvgSamplesPerSec=84.84300160412181, CurrSamplesPerSec=87.42067263601955, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 20: 0.59033203125, mean for epoch: 0.65572509765625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 21: 0.54931640625, mean for epoch: 0.6506580171130952, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 22: 0.52392578125, mean for epoch: 0.6448974609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 23: 0.51806640625, mean for epoch: 0.6393830672554348, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 24: 1.9208984375, mean for epoch: 0.692779541015625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 25: 0.6220703125, mean for epoch: 0.689951171875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 26: 0.409912109375, mean for epoch: 0.6791804387019231, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 27: 0.480224609375, mean for epoch: 0.6718117042824074, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 28: 0.493408203125, mean for epoch: 0.6654401506696429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 29: 0.5263671875, mean for epoch: 0.66064453125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:05,168] [INFO] [logging.py:68:log_dist] [Rank 0] step=830, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:05,168] [INFO] [timer.py:207:stop] 0/830, RunningAvgSamplesPerSec=84.85849563852067, CurrSamplesPerSec=87.00323178851906, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 30: 0.755859375, mean for epoch: 0.663818359375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 31: 0.66162109375, mean for epoch: 0.6637474798387096, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 32: 0.64013671875, mean for epoch: 0.6630096435546875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 33: 0.485107421875, mean for epoch: 0.6576186671401515, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 34: 0.52880859375, mean for epoch: 0.6538301355698529, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 35: 0.483154296875, mean for epoch: 0.6489536830357143, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 36: 0.56591796875, mean for epoch: 0.6466471354166666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 37: 1.18359375, mean for epoch: 0.661159206081081, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 38: 0.56591796875, mean for epoch: 0.6586528577302632, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 39: 0.51123046875, mean for epoch: 0.6548727964743589, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:05,782] [INFO] [logging.py:68:log_dist] [Rank 0] step=840, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:05,782] [INFO] [timer.py:207:stop] 0/840, RunningAvgSamplesPerSec=84.85543855727423, CurrSamplesPerSec=87.46150638084912, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 40: 0.693359375, mean for epoch: 0.6558349609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 41: 1.6689453125, mean for epoch: 0.6805449695121951, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 42: 1.0078125, mean for epoch: 0.6883370535714286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 43: 1.1865234375, mean for epoch: 0.6999227834302325, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 44: 1.7216796875, mean for epoch: 0.72314453125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 45: 0.45263671875, mean for epoch: 0.7171332465277778, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 46: 0.52685546875, mean for epoch: 0.712996773097826, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 47: 0.44873046875, mean for epoch: 0.7073740857712766, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 48: 1.8564453125, mean for epoch: 0.7313130696614584, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 49: 0.884765625, mean for epoch: 0.7344447544642857, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:06,392] [INFO] [logging.py:68:log_dist] [Rank 0] step=850, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:06,393] [INFO] [timer.py:207:stop] 0/850, RunningAvgSamplesPerSec=84.85980867806182, CurrSamplesPerSec=83.71463243277768, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 50: 0.87646484375, mean for epoch: 0.73728515625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 51: 1.0908203125, mean for epoch: 0.7442172181372549, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 52: 0.55908203125, mean for epoch: 0.7406569260817307, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 53: 0.7001953125, mean for epoch: 0.7398934994103774, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 54: 0.54296875, mean for epoch: 0.7362467447916666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 55: 0.5107421875, mean for epoch: 0.7321466619318182, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 56: 0.787109375, mean for epoch: 0.7331281389508929, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 57: 0.7333984375, mean for epoch: 0.7331328810307017, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 58: 0.97705078125, mean for epoch: 0.7373383620689655, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 59: 0.51416015625, mean for epoch: 0.7335556806144068, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:07,011] [INFO] [logging.py:68:log_dist] [Rank 0] step=860, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:07,012] [INFO] [timer.py:207:stop] 0/860, RunningAvgSamplesPerSec=84.854155545028, CurrSamplesPerSec=86.89328272867395, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 60: 0.51220703125, mean for epoch: 0.7298665364583333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 61: 0.39013671875, mean for epoch: 0.7242971951844263, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 62: 0.505859375, mean for epoch: 0.7207740045362904, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 63: 0.5419921875, mean for epoch: 0.7179361979166666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 64: 0.5771484375, mean for epoch: 0.7157363891601562, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 65: 0.80029296875, mean for epoch: 0.7170372596153847, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 66: 0.51025390625, mean for epoch: 0.7139041785037878, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 67: 0.72021484375, mean for epoch: 0.7139983675373134, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 68: 0.494873046875, mean for epoch: 0.7107759363511029, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 69: 0.5126953125, mean for epoch: 0.7079052026721014, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:07,635] [INFO] [logging.py:68:log_dist] [Rank 0] step=870, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:07,636] [INFO] [timer.py:207:stop] 0/870, RunningAvgSamplesPerSec=84.83974994530453, CurrSamplesPerSec=83.75742858968624, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 70: 0.487548828125, mean for epoch: 0.7047572544642857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 71: 0.53857421875, mean for epoch: 0.7024166483274648, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 72: 0.748046875, mean for epoch: 0.7030504014756944, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 73: 0.68896484375, mean for epoch: 0.702857448630137, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 74: 0.9296875, mean for epoch: 0.7059227195945946, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 75: 0.6328125, mean for epoch: 0.7049479166666667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 76: 0.55078125, mean for epoch: 0.7029194078947368, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 77: 1.61328125, mean for epoch: 0.714742288961039, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 78: 0.9091796875, mean for epoch: 0.7172350761217948, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 79: 0.446044921875, mean for epoch: 0.7138022893591772, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:08,265] [INFO] [logging.py:68:log_dist] [Rank 0] step=880, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:08,266] [INFO] [timer.py:207:stop] 0/880, RunningAvgSamplesPerSec=84.82425402590779, CurrSamplesPerSec=85.7373202181503, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 80: 1.0625, mean for epoch: 0.7181610107421875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 81: 0.54345703125, mean for epoch: 0.7160041714891975, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 82: 0.5537109375, mean for epoch: 0.7140249857088414, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 83: 0.71826171875, mean for epoch: 0.714076030685241, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 84: 1.7255859375, mean for epoch: 0.7261178152901786, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 85: 0.457275390625, mean for epoch: 0.7229549632352941, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 86: 1.720703125, mean for epoch: 0.7345566860465116, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 87: 0.58740234375, mean for epoch: 0.7328652568247126, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 88: 0.4580078125, mean for epoch: 0.7297418767755682, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 89: 0.517578125, mean for epoch: 0.7273580143960674, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:08,880] [INFO] [logging.py:68:log_dist] [Rank 0] step=890, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:08,881] [INFO] [timer.py:207:stop] 0/890, RunningAvgSamplesPerSec=84.82220923180816, CurrSamplesPerSec=85.80958771829326, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 90: 1.0947265625, mean for epoch: 0.7314398871527777, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 91: 0.51025390625, mean for epoch: 0.729009271978022, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 92: 1.7392578125, mean for epoch: 0.739990234375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 93: 0.497314453125, mean for epoch: 0.7373808173723119, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 94: 0.505859375, mean for epoch: 0.7349178233045213, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 95: 0.73291015625, mean for epoch: 0.7348966899671052, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 96: 0.58935546875, mean for epoch: 0.7333806355794271, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 97: 1.65234375, mean for epoch: 0.7428544821198454, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 98: 0.7041015625, mean for epoch: 0.7424590441645408, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 99: 0.74658203125, mean for epoch: 0.7425006904987373, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:09,504] [INFO] [logging.py:68:log_dist] [Rank 0] step=900, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:09,504] [INFO] [timer.py:207:stop] 0/900, RunningAvgSamplesPerSec=84.80521363771437, CurrSamplesPerSec=83.97442109098772, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 100: 0.52880859375, mean for epoch: 0.74036376953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 101: 0.51708984375, mean for epoch: 0.7381531366027227, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 102: 0.47119140625, mean for epoch: 0.7355358647365197, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 103: 1.8134765625, mean for epoch: 0.7460013084041263, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 104: 0.434326171875, mean for epoch: 0.7430044320913461, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 105: 0.55224609375, mean for epoch: 0.7411876860119048, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 106: 0.71484375, mean for epoch: 0.7409391583136793, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 107: 0.48388671875, mean for epoch: 0.7385367990654206, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 108: 0.53955078125, mean for epoch: 0.7366943359375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 109: 1.76953125, mean for epoch: 0.746169903956422, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:10,113] [INFO] [logging.py:68:log_dist] [Rank 0] step=910, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:10,114] [INFO] [timer.py:207:stop] 0/910, RunningAvgSamplesPerSec=84.80835366022113, CurrSamplesPerSec=87.33657333949684, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 110: 1.3583984375, mean for epoch: 0.7517356178977272, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 111: 0.497802734375, mean for epoch: 0.7494479342623874, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 112: 0.60595703125, mean for epoch: 0.7481667654854911, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 113: 0.501953125, mean for epoch: 0.7459878837112832, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 114: 0.640625, mean for epoch: 0.7450636478892544, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 115: 0.493896484375, mean for epoch: 0.7428795855978261, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 116: 0.51416015625, mean for epoch: 0.7409078663793104, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 117: 0.51953125, mean for epoch: 0.7390157585470085, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 118: 0.6328125, mean for epoch: 0.7381157309322034, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 119: 1.001953125, mean for epoch: 0.7403328518907563, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:10,717] [INFO] [logging.py:68:log_dist] [Rank 0] step=920, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:10,717] [INFO] [timer.py:207:stop] 0/920, RunningAvgSamplesPerSec=84.8206143098518, CurrSamplesPerSec=87.92610884941283, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 120: 0.6220703125, mean for epoch: 0.7393473307291667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 121: 0.6767578125, mean for epoch: 0.7388300619834711, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 122: 0.5361328125, mean for epoch: 0.7371686091188525, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 123: 1.1171875, mean for epoch: 0.740258193597561, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 124: 0.431396484375, mean for epoch: 0.7377673733618951, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 125: 0.90869140625, mean for epoch: 0.739134765625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 126: 0.56201171875, mean for epoch: 0.7377290271577381, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 127: 0.57568359375, mean for epoch: 0.736453078863189, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 128: 0.430419921875, mean for epoch: 0.7340621948242188, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 129: 0.7109375, mean for epoch: 0.733882933624031, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:11,318] [INFO] [logging.py:68:log_dist] [Rank 0] step=930, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:11,320] [INFO] [timer.py:207:stop] 0/930, RunningAvgSamplesPerSec=84.83506921839144, CurrSamplesPerSec=84.81325854238536, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 130: 0.58935546875, mean for epoch: 0.7327711838942308, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 131: 1.740234375, mean for epoch: 0.7404617426049618, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 132: 2.2421875, mean for epoch: 0.7518384528882576, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 133: 0.52685546875, mean for epoch: 0.7501468515037594, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 134: 0.7509765625, mean for epoch: 0.7501530433768657, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 135: 0.48095703125, mean for epoch: 0.7481589988425926, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 136: 2.90234375, mean for epoch: 0.7639985926011029, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 137: 0.451416015625, mean for epoch: 0.7617169679516423, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 138: 0.458251953125, mean for epoch: 0.7595179461050725, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 139: 0.460205078125, mean for epoch: 0.7573646161196043, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:11,924] [INFO] [logging.py:68:log_dist] [Rank 0] step=940, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:11,924] [INFO] [timer.py:207:stop] 0/940, RunningAvgSamplesPerSec=84.84517162916154, CurrSamplesPerSec=88.05236573722242, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 140: 1.765625, mean for epoch: 0.7645664760044643, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 141: 0.53076171875, mean for epoch: 0.7629082862367021, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 142: 0.51123046875, mean for epoch: 0.7611359072403169, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 143: 0.7607421875, mean for epoch: 0.7611331539554196, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 144: 1.10546875, mean for epoch: 0.7635243733723959, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 145: 0.45947265625, mean for epoch: 0.7614274649784483, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 146: 1.0498046875, mean for epoch: 0.7634026514340754, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 147: 0.47265625, mean for epoch: 0.7614247847576531, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 148: 1.0078125, mean for epoch: 0.7630895666173987, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 149: 0.775390625, mean for epoch: 0.763172124056208, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:12,558] [INFO] [logging.py:68:log_dist] [Rank 0] step=950, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:12,558] [INFO] [timer.py:207:stop] 0/950, RunningAvgSamplesPerSec=84.81613363960598, CurrSamplesPerSec=77.7990799821932, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 150: 0.650390625, mean for epoch: 0.7624202473958334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 151: 0.955078125, mean for epoch: 0.7636961273799668, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 152: 0.54833984375, mean for epoch: 0.7622793097245065, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 153: 1.98046875, mean for epoch: 0.7702413322099673, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 154: 0.56884765625, mean for epoch: 0.7689335810673701, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 155: 0.4404296875, mean for epoch: 0.766814201108871, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 156: 0.81982421875, mean for epoch: 0.7671540089142628, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 157: 0.5185546875, mean for epoch: 0.7655705737460191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 158: 0.7314453125, mean for epoch: 0.7653545910799051, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 159: 0.7236328125, mean for epoch: 0.765092189956761, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:13,192] [INFO] [logging.py:68:log_dist] [Rank 0] step=960, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:13,193] [INFO] [timer.py:207:stop] 0/960, RunningAvgSamplesPerSec=84.78662726641579, CurrSamplesPerSec=79.21493378459029, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 160: 0.69091796875, mean for epoch: 0.7646286010742187, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 161: 0.60302734375, mean for epoch: 0.763624866556677, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 162: 0.496826171875, mean for epoch: 0.7619779610339507, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 163: 1.6611328125, mean for epoch: 0.7674942484662577, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 164: 0.4482421875, mean for epoch: 0.7655475895579268, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 165: 0.54541015625, mean for epoch: 0.7642134232954545, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 166: 0.51025390625, mean for epoch: 0.762683546686747, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 167: 0.53466796875, mean for epoch: 0.7613181839446108, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 168: 0.5419921875, mean for epoch: 0.7600126720610119, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 169: 1.7177734375, mean for epoch: 0.7656798955251479, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:13,819] [INFO] [logging.py:68:log_dist] [Rank 0] step=970, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:13,819] [INFO] [timer.py:207:stop] 0/970, RunningAvgSamplesPerSec=84.7742832862491, CurrSamplesPerSec=80.79486833741066, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 170: 0.70849609375, mean for epoch: 0.7653435202205883, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 171: 0.7763671875, mean for epoch: 0.7654079861111112, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 172: 0.42822265625, mean for epoch: 0.7634476062863372, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 173: 1.6787109375, mean for epoch: 0.7687381457731214, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 174: 2.20703125, mean for epoch: 0.7770041980962644, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 175: 0.77099609375, mean for epoch: 0.7769698660714286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 176: 0.54345703125, mean for epoch: 0.7756430886008523, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 177: 0.51806640625, mean for epoch: 0.7741878531073446, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 178: 0.52392578125, mean for epoch: 0.7727818864115169, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 179: 0.464599609375, mean for epoch: 0.7710601977129888, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:14,440] [INFO] [logging.py:68:log_dist] [Rank 0] step=980, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:14,440] [INFO] [timer.py:207:stop] 0/980, RunningAvgSamplesPerSec=84.76212481399423, CurrSamplesPerSec=80.74447400539798, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 180: 0.47412109375, mean for epoch: 0.7694105360243055, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 181: 0.611328125, mean for epoch: 0.7685371525379834, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 182: 0.57958984375, mean for epoch: 0.7674989805116759, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 183: 0.451904296875, mean for epoch: 0.7657744193989071, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 184: 1.9560546875, mean for epoch: 0.7722433338994565, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 185: 0.468017578125, mean for epoch: 0.7705988703547297, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 186: 0.591796875, mean for epoch: 0.7696375693044355, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 187: 0.51171875, mean for epoch: 0.7682583242814172, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 188: 1.779296875, mean for epoch: 0.773636188912899, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 189: 0.44091796875, mean for epoch: 0.7718757750496031, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:15,047] [INFO] [logging.py:68:log_dist] [Rank 0] step=990, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:15,047] [INFO] [timer.py:207:stop] 0/990, RunningAvgSamplesPerSec=84.77477534278933, CurrSamplesPerSec=85.9696401998844, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 190: 0.56201171875, mean for epoch: 0.7707712273848685, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 191: 0.5322265625, mean for epoch: 0.7695223024378273, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 192: 0.6337890625, mean for epoch: 0.7688153584798177, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 193: 1.1025390625, mean for epoch: 0.7705444968426166, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 194: 1.34375, mean for epoch: 0.7734991643846649, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 195: 0.5859375, mean for epoch: 0.7725373096955128, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 196: 0.4248046875, mean for epoch: 0.7707631636639031, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 197: 0.4833984375, mean for epoch: 0.7693044594701777, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 198: 0.7861328125, mean for epoch: 0.7693894511521465, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 199: 0.55712890625, mean for epoch: 0.7683228152481156, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:15,651] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:15,652] [INFO] [timer.py:207:stop] 0/1000, RunningAvgSamplesPerSec=84.7864701748914, CurrSamplesPerSec=88.26620200846823, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 200: 0.517578125, mean for epoch: 0.767069091796875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 201: 0.49609375, mean for epoch: 0.7657209557680348, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 202: 0.457275390625, mean for epoch: 0.7641939975247525, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 203: 0.7841796875, mean for epoch: 0.7642924491995073, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 204: 0.63525390625, mean for epoch: 0.7636599073223039, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 205: 0.68798828125, mean for epoch: 0.7632907774390244, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 206: 1.240234375, mean for epoch: 0.7656060376213593, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 207: 0.744140625, mean for epoch: 0.7655023399758454, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 208: 0.58642578125, mean for epoch: 0.7646413949819711, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 209: 0.65869140625, mean for epoch: 0.7641344572368421, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:16,245] [INFO] [logging.py:68:log_dist] [Rank 0] step=1010, skipped=18, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:16,246] [INFO] [timer.py:207:stop] 0/1010, RunningAvgSamplesPerSec=84.81058640384047, CurrSamplesPerSec=87.96926122921525, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 210: 0.525390625, mean for epoch: 0.7629975818452381, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 211: 1.6689453125, mean for epoch: 0.767291172985782, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 212: 1.701171875, mean for epoch: 0.7716962706367925, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 213: 0.5126953125, mean for epoch: 0.7704803036971831, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 214: 0.6640625, mean for epoch: 0.7699830242406542, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 215: 0.55126953125, mean for epoch: 0.7689657521802326, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 216: 0.57470703125, mean for epoch: 0.76806640625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 217: 0.65771484375, mean for epoch: 0.767557873703917, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 218: 0.60595703125, mean for epoch: 0.7668165854357798, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:16,789] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
            " Run   2, iteration:   4:   Loss at step 219: 0.623046875, mean for epoch: 0.766160102739726, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:16,835] [INFO] [stage_1_and_2.py:1767:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
            "[2022-10-31 19:03:16,836] [INFO] [logging.py:68:log_dist] [Rank 0] step=1020, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:16,836] [INFO] [timer.py:207:stop] 0/1020, RunningAvgSamplesPerSec=84.84336552631046, CurrSamplesPerSec=113.03817254724405, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 220: 0.444091796875, mean for epoch: 0.7646961558948864, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 221: 0.475830078125, mean for epoch: 0.7633890695701357, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 222: 1.32421875, mean for epoch: 0.7659153293918919, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 223: 0.61669921875, mean for epoch: 0.7652461988508968, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 224: 0.5703125, mean for epoch: 0.7643759591238839, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 225: 0.463623046875, mean for epoch: 0.7630392795138888, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 226: 1.07421875, mean for epoch: 0.7644161798257744, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 227: 0.42333984375, mean for epoch: 0.7629136409003304, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 228: 0.489501953125, mean for epoch: 0.7617144668311403, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 229: 0.552734375, mean for epoch: 0.760801890010917, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:17,446] [INFO] [logging.py:68:log_dist] [Rank 0] step=1030, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:17,447] [INFO] [timer.py:207:stop] 0/1030, RunningAvgSamplesPerSec=84.8461501745573, CurrSamplesPerSec=82.97402946808678, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 230: 0.463134765625, mean for epoch: 0.7595076851222826, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 231: 0.62939453125, mean for epoch: 0.7589444247159091, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 232: 1.0244140625, mean for epoch: 0.7600886903960129, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 233: 0.44580078125, mean for epoch: 0.7587398152494635, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 234: 1.1396484375, mean for epoch: 0.7603676298744658, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 235: 0.475341796875, mean for epoch: 0.7591547539893617, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 236: 0.84375, mean for epoch: 0.7595132084216102, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 237: 0.79345703125, mean for epoch: 0.7596564313027426, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 238: 0.7421875, mean for epoch: 0.7595830324317226, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 239: 0.5234375, mean for epoch: 0.7585949758106695, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:18,053] [INFO] [logging.py:68:log_dist] [Rank 0] step=1040, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:18,054] [INFO] [timer.py:207:stop] 0/1040, RunningAvgSamplesPerSec=84.85382032688054, CurrSamplesPerSec=85.26151882163055, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 240: 0.576171875, mean for epoch: 0.7578348795572917, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 241: 0.86474609375, mean for epoch: 0.7582784945539419, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 242: 0.736328125, mean for epoch: 0.7581877905475206, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 243: 0.489013671875, mean for epoch: 0.757080078125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 244: 1.3046875, mean for epoch: 0.7593243708376025, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 245: 1.0595703125, mean for epoch: 0.7605498644770409, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 246: 0.52197265625, mean for epoch: 0.7595800384273373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 247: 0.73486328125, mean for epoch: 0.7594799705845142, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 248: 0.57275390625, mean for epoch: 0.758727042905746, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 249: 0.95947265625, mean for epoch: 0.759533250188253, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:18,662] [INFO] [logging.py:68:log_dist] [Rank 0] step=1050, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:18,662] [INFO] [timer.py:207:stop] 0/1050, RunningAvgSamplesPerSec=84.86035624382909, CurrSamplesPerSec=86.9130890659903, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 250: 0.479736328125, mean for epoch: 0.7584140625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 251: 0.49072265625, mean for epoch: 0.757347562873506, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 252: 0.4853515625, mean for epoch: 0.7562682136656746, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 253: 1.015625, mean for epoch: 0.7572933393033597, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 254: 0.65380859375, mean for epoch: 0.7568859190452756, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 255: 1.09375, mean for epoch: 0.7582069546568627, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 256: 0.50439453125, mean for epoch: 0.7572154998779297, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 257: 0.51953125, mean for epoch: 0.7562906584387159, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 258: 0.47216796875, mean for epoch: 0.7551894077034884, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 259: 0.5390625, mean for epoch: 0.7543549408783784, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:19,263] [INFO] [logging.py:68:log_dist] [Rank 0] step=1060, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:19,264] [INFO] [timer.py:207:stop] 0/1060, RunningAvgSamplesPerSec=84.8733417932019, CurrSamplesPerSec=82.93399770633131, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   4:   Loss at step 260: 0.529296875, mean for epoch: 0.7534893329326923, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 261: 0.56396484375, mean for epoch: 0.7527631854645593, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 262: 0.55615234375, mean for epoch: 0.7520127624045801, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 263: 0.5341796875, mean for epoch: 0.7511844997623575, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 264: 0.76904296875, mean for epoch: 0.7512521454782197, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 265: 0.736328125, mean for epoch: 0.7511958284198114, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 266: 0.5537109375, mean for epoch: 0.7504534040178571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   4:   Loss at step 267: 0.54345703125, mean for epoch: 0.7496781367041199, mem_alloc: 1023816704\n",
            "Loss after iteration 4 ; MSE: 0.74951171875, MAE: 0.46630859375\n",
            "Connected by ('127.0.0.1', 41076)\n",
            "\u001b[94mReceived training result: b'4;0.74951;0.46631' \u001b[0m\n",
            "Time per iteration 16.834487676620483, memory OrderedDict([('active.all.allocated', 1436244), ('active.all.current', 7), ('active.all.freed', 1436237), ('active.all.peak', 197), ('active.large_pool.allocated', 3168), ('active.large_pool.current', 3), ('active.large_pool.freed', 3165), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1433076), ('active.small_pool.current', 4), ('active.small_pool.freed', 1433072), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 1149126733312), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 1149121599488), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 1071274104832), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 1071270435328), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 77852628480), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 77851164160), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 1149126733312), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 1149122211328), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 1071274104832), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 1071270435328), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 77852628480), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 77851776000), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1436244), ('allocation.all.current', 6), ('allocation.all.freed', 1436238), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 3168), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 3165), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1433076), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1433073), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 610340), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 610334), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 1050), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 1048), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 609290), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 609286), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 94235367936), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 94215335936), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 2925457408), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 2908155392), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 91309910528), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 91307180544), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            " Run   2, iteration:   5:   Loss at step 1: 0.49853515625, mean for epoch: 0.49853515625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 2: 0.473388671875, mean for epoch: 0.4859619140625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:20,177] [INFO] [logging.py:68:log_dist] [Rank 0] step=1070, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:20,178] [INFO] [timer.py:207:stop] 0/1070, RunningAvgSamplesPerSec=84.86148136295166, CurrSamplesPerSec=82.01130164440882, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 3: 0.81591796875, mean for epoch: 0.595947265625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 4: 0.74072265625, mean for epoch: 0.63214111328125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 5: 0.44970703125, mean for epoch: 0.595654296875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 6: 0.452880859375, mean for epoch: 0.5718587239583334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 7: 2.5078125, mean for epoch: 0.8484235491071429, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 8: 0.78369140625, mean for epoch: 0.84033203125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 9: 0.434326171875, mean for epoch: 0.7952202690972222, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 10: 1.4658203125, mean for epoch: 0.8622802734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 11: 0.65185546875, mean for epoch: 0.8431507457386364, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 12: 0.40478515625, mean for epoch: 0.8066202799479166, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:20,793] [INFO] [logging.py:68:log_dist] [Rank 0] step=1080, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:20,793] [INFO] [timer.py:207:stop] 0/1080, RunningAvgSamplesPerSec=84.85401749152744, CurrSamplesPerSec=85.55718289633114, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 13: 0.712890625, mean for epoch: 0.7994103064903846, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 14: 0.45947265625, mean for epoch: 0.7751290457589286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 15: 0.8388671875, mean for epoch: 0.7793782552083334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 16: 0.4033203125, mean for epoch: 0.7558746337890625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 17: 0.4130859375, mean for epoch: 0.7357105928308824, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 18: 0.80078125, mean for epoch: 0.7393256293402778, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 19: 0.919921875, mean for epoch: 0.7488306949013158, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 20: 1.2763671875, mean for epoch: 0.77520751953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 21: 0.56689453125, mean for epoch: 0.7652878534226191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 22: 0.8251953125, mean for epoch: 0.7680109197443182, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:21,403] [INFO] [logging.py:68:log_dist] [Rank 0] step=1090, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:21,403] [INFO] [timer.py:207:stop] 0/1090, RunningAvgSamplesPerSec=84.85820025516801, CurrSamplesPerSec=86.73766755865846, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 23: 0.5126953125, mean for epoch: 0.7569102411684783, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 24: 0.5224609375, mean for epoch: 0.7471415201822916, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 25: 0.66455078125, mean for epoch: 0.743837890625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 26: 0.4853515625, mean for epoch: 0.7338961087740384, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 27: 0.476318359375, mean for epoch: 0.7243561921296297, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 28: 0.47021484375, mean for epoch: 0.7152797154017857, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 29: 0.53515625, mean for epoch: 0.7090685614224138, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 30: 0.7412109375, mean for epoch: 0.7101399739583333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 31: 0.52783203125, mean for epoch: 0.7042590725806451, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 32: 0.48046875, mean for epoch: 0.697265625, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:22,022] [INFO] [logging.py:68:log_dist] [Rank 0] step=1100, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:22,022] [INFO] [timer.py:207:stop] 0/1100, RunningAvgSamplesPerSec=84.85065138611289, CurrSamplesPerSec=86.29296333329219, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 33: 0.76123046875, mean for epoch: 0.6992039535984849, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 34: 0.486328125, mean for epoch: 0.6929428998161765, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 35: 0.732421875, mean for epoch: 0.6940708705357143, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 36: 0.479248046875, mean for epoch: 0.6881035698784722, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 37: 0.439697265625, mean for epoch: 0.6813898859797297, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 38: 0.54541015625, mean for epoch: 0.6778114720394737, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 39: 0.44189453125, mean for epoch: 0.6717623197115384, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 40: 0.496337890625, mean for epoch: 0.667376708984375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 41: 0.51708984375, mean for epoch: 0.6637111756859756, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 42: 0.4833984375, mean for epoch: 0.6594180152529762, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:22,649] [INFO] [logging.py:68:log_dist] [Rank 0] step=1110, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:22,650] [INFO] [timer.py:207:stop] 0/1110, RunningAvgSamplesPerSec=84.83285446912846, CurrSamplesPerSec=77.97582441280689, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 43: 0.54052734375, mean for epoch: 0.6566531159156976, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 44: 0.51416015625, mean for epoch: 0.6534146395596591, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 45: 0.51416015625, mean for epoch: 0.6503200954861111, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 46: 0.6650390625, mean for epoch: 0.6506400730298914, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 47: 1.5341796875, mean for epoch: 0.669438788231383, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 48: 1.86328125, mean for epoch: 0.6943105061848959, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 49: 1.7607421875, mean for epoch: 0.7160744180484694, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 50: 0.6728515625, mean for epoch: 0.7152099609375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 51: 1.658203125, mean for epoch: 0.7337000229779411, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 52: 0.60693359375, mean for epoch: 0.73126220703125, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:23,260] [INFO] [logging.py:68:log_dist] [Rank 0] step=1120, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:23,261] [INFO] [timer.py:207:stop] 0/1120, RunningAvgSamplesPerSec=84.83949716290957, CurrSamplesPerSec=86.740896381715, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 53: 0.472412109375, mean for epoch: 0.7263782429245284, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 54: 0.54296875, mean for epoch: 0.7229817708333334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 55: 0.52880859375, mean for epoch: 0.7194513494318182, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 56: 0.5283203125, mean for epoch: 0.7160382952008929, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 57: 0.431396484375, mean for epoch: 0.7110445792214912, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 58: 1.044921875, mean for epoch: 0.7168010843211207, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 59: 0.5419921875, mean for epoch: 0.7138382216631356, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 60: 0.52880859375, mean for epoch: 0.71075439453125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 61: 0.71240234375, mean for epoch: 0.7107814100922131, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 62: 0.603515625, mean for epoch: 0.7090513167842742, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:23,875] [INFO] [logging.py:68:log_dist] [Rank 0] step=1130, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:23,875] [INFO] [timer.py:207:stop] 0/1130, RunningAvgSamplesPerSec=84.83734490294773, CurrSamplesPerSec=86.2535679326144, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 63: 0.5361328125, mean for epoch: 0.7063065786210317, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 64: 0.88232421875, mean for epoch: 0.7090568542480469, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 65: 0.984375, mean for epoch: 0.7132925180288462, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 66: 0.5224609375, mean for epoch: 0.7104011304450758, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 67: 0.5087890625, mean for epoch: 0.707391995102612, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 68: 0.480224609375, mean for epoch: 0.7040512982536765, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 69: 0.5224609375, mean for epoch: 0.7014195538949275, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 70: 0.80126953125, mean for epoch: 0.7028459821428571, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 71: 0.53955078125, mean for epoch: 0.7005460497359155, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 72: 0.578125, mean for epoch: 0.6988457573784722, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:24,490] [INFO] [logging.py:68:log_dist] [Rank 0] step=1140, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:24,491] [INFO] [timer.py:207:stop] 0/1140, RunningAvgSamplesPerSec=84.83565186242625, CurrSamplesPerSec=85.76151276105884, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 73: 0.439208984375, mean for epoch: 0.695289089255137, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 74: 1.36328125, mean for epoch: 0.7043160103462838, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 75: 1.111328125, mean for epoch: 0.7097428385416666, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 76: 0.48095703125, mean for epoch: 0.7067324989720395, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 77: 0.564453125, mean for epoch: 0.7048847148944806, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 78: 0.73779296875, mean for epoch: 0.7053066155849359, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 79: 0.6982421875, mean for epoch: 0.7052171924446202, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 80: 1.640625, mean for epoch: 0.7169097900390625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 81: 0.71435546875, mean for epoch: 0.7168782552083334, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 82: 0.7568359375, mean for epoch: 0.7173655440167683, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:25,105] [INFO] [logging.py:68:log_dist] [Rank 0] step=1150, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:25,105] [INFO] [timer.py:207:stop] 0/1150, RunningAvgSamplesPerSec=84.83836164021476, CurrSamplesPerSec=81.79219968798752, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 83: 0.83349609375, mean for epoch: 0.7187647072665663, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 84: 0.42431640625, mean for epoch: 0.7152593703497023, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 85: 0.6201171875, mean for epoch: 0.7141400505514706, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 86: 1.6328125, mean for epoch: 0.7248222883357558, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 87: 1.6103515625, mean for epoch: 0.7350007857399425, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 88: 0.77490234375, mean for epoch: 0.7354542125355114, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 89: 0.485107421875, mean for epoch: 0.732641327247191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 90: 0.62939453125, mean for epoch: 0.731494140625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 91: 0.49462890625, mean for epoch: 0.7288912259615384, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 92: 0.4599609375, mean for epoch: 0.725968070652174, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:25,702] [INFO] [logging.py:68:log_dist] [Rank 0] step=1160, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:25,703] [INFO] [timer.py:207:stop] 0/1160, RunningAvgSamplesPerSec=84.85996816983335, CurrSamplesPerSec=87.74143882183127, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 93: 0.472900390625, mean for epoch: 0.7232469128024194, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 94: 0.50146484375, mean for epoch: 0.7208875290890957, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 95: 0.95751953125, mean for epoch: 0.7233783922697369, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 96: 0.489501953125, mean for epoch: 0.7209421793619791, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 97: 0.48583984375, mean for epoch: 0.718518443943299, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 98: 0.47265625, mean for epoch: 0.7160096460459183, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 99: 0.64013671875, mean for epoch: 0.7152432528409091, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 100: 1.365234375, mean for epoch: 0.7217431640625, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 101: 1.26171875, mean for epoch: 0.7270894569925742, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 102: 2.107421875, mean for epoch: 0.7406221277573529, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:26,310] [INFO] [logging.py:68:log_dist] [Rank 0] step=1170, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:26,311] [INFO] [timer.py:207:stop] 0/1170, RunningAvgSamplesPerSec=84.86830566072345, CurrSamplesPerSec=84.0966580317114, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 103: 0.4853515625, mean for epoch: 0.7381437727548543, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 104: 0.634765625, mean for epoch: 0.7371497521033654, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 105: 0.476806640625, mean for epoch: 0.7346702938988096, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 106: 0.396484375, mean for epoch: 0.7314798607016509, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 107: 0.615234375, mean for epoch: 0.7303934542932243, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 108: 0.55126953125, mean for epoch: 0.7287348994502315, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 109: 0.5087890625, mean for epoch: 0.7267170477350917, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 110: 0.5263671875, mean for epoch: 0.7248956853693181, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 111: 0.456787109375, mean for epoch: 0.7224802927927928, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 112: 0.52490234375, mean for epoch: 0.7207162039620536, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:26,921] [INFO] [logging.py:68:log_dist] [Rank 0] step=1180, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:26,922] [INFO] [timer.py:207:stop] 0/1180, RunningAvgSamplesPerSec=84.87138432174817, CurrSamplesPerSec=88.49414723481108, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 113: 0.54248046875, mean for epoch: 0.7191388965707964, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 114: 0.5458984375, mean for epoch: 0.7176192434210527, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 115: 1.017578125, mean for epoch: 0.7202275815217392, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 116: 1.6455078125, mean for epoch: 0.728204135237069, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 117: 0.52734375, mean for epoch: 0.7264873798076923, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 118: 0.53955078125, mean for epoch: 0.724903171345339, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 119: 0.4375, mean for epoch: 0.7224880186449579, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 120: 0.50244140625, mean for epoch: 0.720654296875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 121: 1.0078125, mean for epoch: 0.7230275051652892, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 122: 0.57666015625, mean for epoch: 0.7218277727971312, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:27,521] [INFO] [logging.py:68:log_dist] [Rank 0] step=1190, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:27,521] [INFO] [timer.py:207:stop] 0/1190, RunningAvgSamplesPerSec=84.88662521821006, CurrSamplesPerSec=88.52963649334914, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 123: 0.70703125, mean for epoch: 0.7217074758638211, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 124: 0.64111328125, mean for epoch: 0.7210575226814516, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 125: 0.5166015625, mean for epoch: 0.719421875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 126: 0.4736328125, mean for epoch: 0.7174711681547619, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 127: 1.3232421875, mean for epoch: 0.7222410187007874, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 128: 0.482666015625, mean for epoch: 0.7203693389892578, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 129: 0.435546875, mean for epoch: 0.7181614129118217, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 130: 0.51318359375, mean for epoch: 0.7165846604567307, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 131: 0.53271484375, mean for epoch: 0.7151810740696565, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 132: 0.63134765625, mean for epoch: 0.7145459724195076, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:28,132] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:28,133] [INFO] [timer.py:207:stop] 0/1200, RunningAvgSamplesPerSec=84.8896755048059, CurrSamplesPerSec=86.07761610606029, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 133: 0.377685546875, mean for epoch: 0.7120131872650376, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 134: 0.7724609375, mean for epoch: 0.7124642898787313, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 135: 0.5390625, mean for epoch: 0.711179832175926, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 136: 0.533203125, mean for epoch: 0.7098711799172794, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 137: 0.51513671875, mean for epoch: 0.7084497604927007, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 138: 0.58349609375, mean for epoch: 0.7075442991394928, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 139: 0.489501953125, mean for epoch: 0.7059756491681655, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 140: 0.444091796875, mean for epoch: 0.7041050502232142, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 141: 1.724609375, mean for epoch: 0.7113426695478723, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 142: 2.2109375, mean for epoch: 0.7219031965228874, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:28,742] [INFO] [logging.py:68:log_dist] [Rank 0] step=1210, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:28,742] [INFO] [timer.py:207:stop] 0/1210, RunningAvgSamplesPerSec=84.89282627561916, CurrSamplesPerSec=82.01194307680876, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 143: 0.49853515625, mean for epoch: 0.7203411822552448, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 144: 0.5400390625, mean for epoch: 0.7190890842013888, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 145: 0.59912109375, mean for epoch: 0.71826171875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 146: 0.59228515625, mean for epoch: 0.7173988655821918, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 147: 0.436279296875, mean for epoch: 0.7154864875637755, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 148: 0.66259765625, mean for epoch: 0.7151291305954391, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 149: 1.7470703125, mean for epoch: 0.7220549103397651, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 150: 0.59130859375, mean for epoch: 0.7211832682291667, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 151: 0.435302734375, mean for epoch: 0.719290019660596, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 152: 0.431884765625, mean for epoch: 0.7173991956208882, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:29,346] [INFO] [logging.py:68:log_dist] [Rank 0] step=1220, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:29,346] [INFO] [timer.py:207:stop] 0/1220, RunningAvgSamplesPerSec=84.90247499248241, CurrSamplesPerSec=87.2940392940393, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 153: 0.5498046875, mean for epoch: 0.7163038066789216, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 154: 1.396484375, mean for epoch: 0.7207205636160714, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 155: 0.6513671875, mean for epoch: 0.7202731224798387, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 156: 0.69189453125, mean for epoch: 0.7200912084334936, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 157: 0.6689453125, mean for epoch: 0.7197654383957006, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 158: 1.533203125, mean for epoch: 0.7249137781843354, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 159: 0.47900390625, mean for epoch: 0.723367175216195, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 160: 0.46533203125, mean for epoch: 0.7217544555664063, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 161: 0.8623046875, mean for epoch: 0.7226274383734472, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 162: 1.8388671875, mean for epoch: 0.7295178071952161, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:29,995] [INFO] [logging.py:68:log_dist] [Rank 0] step=1230, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:29,996] [INFO] [timer.py:207:stop] 0/1230, RunningAvgSamplesPerSec=84.86200410413622, CurrSamplesPerSec=86.16603323951763, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 163: 0.75830078125, mean for epoch: 0.7296943898581288, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 164: 0.54052734375, mean for epoch: 0.7285409322599086, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 165: 0.44677734375, mean for epoch: 0.7268332741477272, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 166: 1.734375, mean for epoch: 0.7329028026167169, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 167: 0.57275390625, mean for epoch: 0.7319438271893712, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 168: 0.6689453125, mean for epoch: 0.7315688360305059, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 169: 0.763671875, mean for epoch: 0.7317587948409763, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 170: 2.37890625, mean for epoch: 0.7414478975183824, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 171: 0.5419921875, mean for epoch: 0.7402814898574561, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 172: 0.74560546875, mean for epoch: 0.7403124432231105, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:30,652] [INFO] [logging.py:68:log_dist] [Rank 0] step=1240, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:30,653] [INFO] [timer.py:207:stop] 0/1240, RunningAvgSamplesPerSec=84.8145144829713, CurrSamplesPerSec=80.96799351376394, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 173: 0.595703125, mean for epoch: 0.7394765512102601, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 174: 0.51025390625, mean for epoch: 0.7381591796875, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 175: 0.54541015625, mean for epoch: 0.7370577566964286, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 176: 0.484619140625, mean for epoch: 0.7356234463778409, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 177: 0.5673828125, mean for epoch: 0.7346729343220338, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 178: 0.489013671875, mean for epoch: 0.7332928261060393, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 179: 0.8017578125, mean for epoch: 0.7336753120635475, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 180: 0.50634765625, mean for epoch: 0.7324123806423611, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 181: 1.873046875, mean for epoch: 0.7387142286774862, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 182: 0.49658203125, mean for epoch: 0.7373838319883241, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:31,316] [INFO] [logging.py:68:log_dist] [Rank 0] step=1250, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:31,317] [INFO] [timer.py:207:stop] 0/1250, RunningAvgSamplesPerSec=84.75922004199427, CurrSamplesPerSec=76.15041612804833, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 183: 0.6884765625, mean for epoch: 0.7371165791495902, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 184: 0.451904296875, mean for epoch: 0.7355665123980978, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 185: 0.470947265625, mean for epoch: 0.7341361380912163, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 186: 0.425048828125, mean for epoch: 0.732474378360215, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 187: 0.484619140625, mean for epoch: 0.7311489492814172, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 188: 0.576171875, mean for epoch: 0.7303246031416223, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 189: 0.50927734375, mean for epoch: 0.7291550409226191, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 190: 0.5498046875, mean for epoch: 0.7282110916940789, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 191: 0.52490234375, mean for epoch: 0.7271466479875655, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 192: 1.2880859375, mean for epoch: 0.7300682067871094, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:31,950] [INFO] [logging.py:68:log_dist] [Rank 0] step=1260, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:31,951] [INFO] [timer.py:207:stop] 0/1260, RunningAvgSamplesPerSec=84.7406415433707, CurrSamplesPerSec=85.50939026478672, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 193: 0.98486328125, mean for epoch: 0.7313883885200777, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 194: 0.50048828125, mean for epoch: 0.7301981817815721, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 195: 0.52685546875, mean for epoch: 0.7291553986378205, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 196: 0.53125, mean for epoch: 0.7281456772161989, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 197: 0.54833984375, mean for epoch: 0.7272329572493654, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 198: 0.5498046875, mean for epoch: 0.7263368548768939, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 199: 0.54150390625, mean for epoch: 0.7254080460898241, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 200: 0.466552734375, mean for epoch: 0.72411376953125, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 201: 1.6435546875, mean for epoch: 0.7286881024564676, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 202: 0.481201171875, mean for epoch: 0.727462919631807, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:32,574] [INFO] [logging.py:68:log_dist] [Rank 0] step=1270, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:32,574] [INFO] [timer.py:207:stop] 0/1270, RunningAvgSamplesPerSec=84.73194915860137, CurrSamplesPerSec=81.08758525759005, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 203: 0.68359375, mean for epoch: 0.7272468153479064, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 204: 1.701171875, mean for epoch: 0.7320209577971813, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 205: 0.83544921875, mean for epoch: 0.7325254858993903, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 206: 0.56103515625, mean for epoch: 0.7316930085709952, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 207: 0.5224609375, mean for epoch: 0.7306822256189613, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 208: 0.494140625, mean for epoch: 0.7295450063852164, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 209: 0.443115234375, mean for epoch: 0.728174529007177, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 210: 0.48291015625, mean for epoch: 0.727006603422619, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 211: 0.51953125, mean for epoch: 0.7260233079087678, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 212: 0.4892578125, mean for epoch: 0.7249064895341981, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:33,197] [INFO] [logging.py:68:log_dist] [Rank 0] step=1280, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:33,197] [INFO] [timer.py:207:stop] 0/1280, RunningAvgSamplesPerSec=84.7240129514027, CurrSamplesPerSec=84.0599159060938, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 213: 0.498291015625, mean for epoch: 0.7238425671214789, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 214: 0.407470703125, mean for epoch: 0.7223641939252337, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 215: 0.5625, mean for epoch: 0.7216206395348838, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 216: 0.517578125, mean for epoch: 0.7206759982638888, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 217: 0.53955078125, mean for epoch: 0.7198413198444701, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 218: 0.46044921875, mean for epoch: 0.7186514478211009, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 219: 0.56689453125, mean for epoch: 0.7179584938641552, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 220: 0.99853515625, mean for epoch: 0.7192338423295455, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 221: 0.68115234375, mean for epoch: 0.7190615278563348, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 222: 0.44189453125, mean for epoch: 0.7178130278716216, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:33,809] [INFO] [logging.py:68:log_dist] [Rank 0] step=1290, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:33,810] [INFO] [timer.py:207:stop] 0/1290, RunningAvgSamplesPerSec=84.72775685330126, CurrSamplesPerSec=83.45246101257864, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 223: 0.471435546875, mean for epoch: 0.7167081961182735, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 224: 0.495849609375, mean for epoch: 0.7157222202845982, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 225: 2.001953125, mean for epoch: 0.7214388020833333, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 226: 0.4765625, mean for epoch: 0.7203552786227876, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 227: 0.54833984375, mean for epoch: 0.719597501376652, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 228: 1.80859375, mean for epoch: 0.7243738007127193, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 229: 0.55859375, mean for epoch: 0.723649870360262, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 230: 0.72802734375, mean for epoch: 0.7236689028532609, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 231: 0.494384765625, mean for epoch: 0.7226763308306277, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 232: 0.68798828125, mean for epoch: 0.7225268133755388, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:34,433] [INFO] [logging.py:68:log_dist] [Rank 0] step=1300, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:34,433] [INFO] [timer.py:207:stop] 0/1300, RunningAvgSamplesPerSec=84.72168145900785, CurrSamplesPerSec=81.25189360919006, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 233: 1.0, mean for epoch: 0.7237176854211373, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 234: 2.05078125, mean for epoch: 0.7293888972355769, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 235: 0.638671875, mean for epoch: 0.7290028673537234, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 236: 0.469970703125, mean for epoch: 0.7279052734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 237: 0.56787109375, mean for epoch: 0.7272300237341772, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 238: 0.537109375, mean for epoch: 0.7264311974789915, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 239: 1.337890625, mean for epoch: 0.728989605125523, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 240: 1.037109375, mean for epoch: 0.7302734375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 241: 0.53271484375, mean for epoch: 0.7294536922977178, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 242: 0.552734375, mean for epoch: 0.7287234471849173, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:35,059] [INFO] [logging.py:68:log_dist] [Rank 0] step=1310, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:35,060] [INFO] [timer.py:207:stop] 0/1310, RunningAvgSamplesPerSec=84.7107079140996, CurrSamplesPerSec=85.79730066971865, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 243: 0.46484375, mean for epoch: 0.727637522505144, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 244: 1.6279296875, mean for epoch: 0.7313272444928278, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 245: 2.208984375, mean for epoch: 0.7373584980867347, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 246: 0.52587890625, mean for epoch: 0.736498824949187, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 247: 0.49951171875, mean for epoch: 0.7355393629807693, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 248: 0.5380859375, mean for epoch: 0.7347431798135081, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 249: 0.70947265625, mean for epoch: 0.7346416917670683, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 250: 1.095703125, mean for epoch: 0.7360859375, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 251: 0.435302734375, mean for epoch: 0.7348875980453188, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 252: 1.0126953125, mean for epoch: 0.7359900096106151, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:35,673] [INFO] [logging.py:68:log_dist] [Rank 0] step=1320, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:35,674] [INFO] [timer.py:207:stop] 0/1320, RunningAvgSamplesPerSec=84.71173273687957, CurrSamplesPerSec=86.93831019430154, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 253: 1.6982421875, mean for epoch: 0.739793377902668, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 254: 0.8310546875, mean for epoch: 0.7401526743971457, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 255: 0.5546875, mean for epoch: 0.7394253599877451, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 256: 0.52880859375, mean for epoch: 0.7386026382446289, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 257: 0.461669921875, mean for epoch: 0.737525079036965, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 258: 1.1337890625, mean for epoch: 0.7390609859496124, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 259: 0.75341796875, mean for epoch: 0.739116418315637, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 260: 0.50048828125, mean for epoch: 0.7381986177884615, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 261: 0.5419921875, mean for epoch: 0.73744686901341, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 262: 0.5908203125, mean for epoch: 0.736887225667939, mem_alloc: 1023816704\n",
            "[2022-10-31 19:03:36,280] [INFO] [logging.py:68:log_dist] [Rank 0] step=1330, skipped=20, lr=[5e-05], mom=[(0.9, 0.999)]\n",
            "[2022-10-31 19:03:36,280] [INFO] [timer.py:207:stop] 0/1330, RunningAvgSamplesPerSec=84.71937157307015, CurrSamplesPerSec=87.04259257722032, MemAllocated=0.0GB, MaxMemAllocated=0.95GB\n",
            " Run   2, iteration:   5:   Loss at step 263: 0.460205078125, mean for epoch: 0.735835202293251, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 264: 1.0595703125, mean for epoch: 0.7370614716500947, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 265: 0.4560546875, mean for epoch: 0.7360010686910378, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 266: 1.0478515625, mean for epoch: 0.7371734389685151, mem_alloc: 1023816704\n",
            " Run   2, iteration:   5:   Loss at step 267: 0.6171875, mean for epoch: 0.7367240534293071, mem_alloc: 1023816704\n",
            "Loss after iteration 5 ; MSE: 0.73681640625, MAE: 0.4599609375\n",
            "Connected by ('127.0.0.1', 42756)\n",
            "\u001b[94mReceived training result: b'5;0.73682;0.45996' \u001b[0m\n",
            "Time per iteration 16.835287857055665, memory OrderedDict([('active.all.allocated', 1797762), ('active.all.current', 7), ('active.all.freed', 1797755), ('active.all.peak', 197), ('active.large_pool.allocated', 3969), ('active.large_pool.current', 3), ('active.large_pool.freed', 3966), ('active.large_pool.peak', 4), ('active.small_pool.allocated', 1793793), ('active.small_pool.current', 4), ('active.small_pool.freed', 1793789), ('active.small_pool.peak', 193), ('active_bytes.all.allocated', 1436438076928), ('active_bytes.all.current', 5133824), ('active_bytes.all.freed', 1436432943104), ('active_bytes.all.peak', 1023816704), ('active_bytes.large_pool.allocated', 1339105265152), ('active_bytes.large_pool.current', 3669504), ('active_bytes.large_pool.freed', 1339101595648), ('active_bytes.large_pool.peak', 1004011008), ('active_bytes.small_pool.allocated', 97332811776), ('active_bytes.small_pool.current', 1464320), ('active_bytes.small_pool.freed', 97331347456), ('active_bytes.small_pool.peak', 19805696), ('allocated_bytes.all.allocated', 1436438076928), ('allocated_bytes.all.current', 4521984), ('allocated_bytes.all.freed', 1436433554944), ('allocated_bytes.all.peak', 1023816704), ('allocated_bytes.large_pool.allocated', 1339105265152), ('allocated_bytes.large_pool.current', 3669504), ('allocated_bytes.large_pool.freed', 1339101595648), ('allocated_bytes.large_pool.peak', 1004011008), ('allocated_bytes.small_pool.allocated', 97332811776), ('allocated_bytes.small_pool.current', 852480), ('allocated_bytes.small_pool.freed', 97331959296), ('allocated_bytes.small_pool.peak', 19805696), ('allocation.all.allocated', 1797762), ('allocation.all.current', 6), ('allocation.all.freed', 1797756), ('allocation.all.peak', 197), ('allocation.large_pool.allocated', 3969), ('allocation.large_pool.current', 3), ('allocation.large_pool.freed', 3966), ('allocation.large_pool.peak', 4), ('allocation.small_pool.allocated', 1793793), ('allocation.small_pool.current', 3), ('allocation.small_pool.freed', 1793790), ('allocation.small_pool.peak', 193), ('inactive_split.all.allocated', 764045), ('inactive_split.all.current', 6), ('inactive_split.all.freed', 764039), ('inactive_split.all.peak', 23), ('inactive_split.large_pool.allocated', 1317), ('inactive_split.large_pool.current', 2), ('inactive_split.large_pool.freed', 1315), ('inactive_split.large_pool.peak', 2), ('inactive_split.small_pool.allocated', 762728), ('inactive_split.small_pool.current', 4), ('inactive_split.small_pool.freed', 762724), ('inactive_split.small_pool.peak', 21), ('inactive_split_bytes.all.allocated', 117819321344), ('inactive_split_bytes.all.current', 20032000), ('inactive_split_bytes.all.freed', 117799289344), ('inactive_split_bytes.all.peak', 26149888), ('inactive_split_bytes.large_pool.allocated', 3665436160), ('inactive_split_bytes.large_pool.current', 17302016), ('inactive_split_bytes.large_pool.freed', 3648134144), ('inactive_split_bytes.large_pool.peak', 17302016), ('inactive_split_bytes.small_pool.allocated', 114153885184), ('inactive_split_bytes.small_pool.current', 2729984), ('inactive_split_bytes.small_pool.freed', 114151155200), ('inactive_split_bytes.small_pool.peak', 8847872), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 1042284544), ('reserved_bytes.all.current', 1042284544), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 1042284544), ('reserved_bytes.large_pool.allocated', 1021313024), ('reserved_bytes.large_pool.current', 1021313024), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 1021313024), ('reserved_bytes.small_pool.allocated', 20971520), ('reserved_bytes.small_pool.current', 20971520), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 20971520), ('segment.all.allocated', 12), ('segment.all.current', 12), ('segment.all.freed', 0), ('segment.all.peak', 12), ('segment.large_pool.allocated', 2), ('segment.large_pool.current', 2), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 2), ('segment.small_pool.allocated', 10), ('segment.small_pool.current', 10), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 10)])\n",
            "1023816704\n",
            "test 2857\n",
            "Validation set Loss at step 1: 0.423828125, mean for epoch: 0.423828125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 2: 0.437744140625, mean for epoch: 0.4307861328125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 3: 0.38134765625, mean for epoch: 0.414306640625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 4: 0.5283203125, mean for epoch: 0.44281005859375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 5: 0.5263671875, mean for epoch: 0.459521484375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 6: 0.67529296875, mean for epoch: 0.4954833984375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 7: 0.423828125, mean for epoch: 0.48524693080357145, mem_alloc: 1023816704\n",
            "Validation set Loss at step 8: 0.54052734375, mean for epoch: 0.492156982421875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 9: 0.447021484375, mean for epoch: 0.4871419270833333, mem_alloc: 1023816704\n",
            "Validation set Loss at step 10: 0.525390625, mean for epoch: 0.490966796875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 11: 0.6474609375, mean for epoch: 0.5051935369318182, mem_alloc: 1023816704\n",
            "Validation set Loss at step 12: 0.475341796875, mean for epoch: 0.5027058919270834, mem_alloc: 1023816704\n",
            "Validation set Loss at step 13: 0.443359375, mean for epoch: 0.49814077524038464, mem_alloc: 1023816704\n",
            "Validation set Loss at step 14: 0.50146484375, mean for epoch: 0.49837820870535715, mem_alloc: 1023816704\n",
            "Validation set Loss at step 15: 0.2724609375, mean for epoch: 0.4833170572916667, mem_alloc: 1023816704\n",
            "Validation set Loss at step 16: 0.37939453125, mean for epoch: 0.4768218994140625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 17: 0.442626953125, mean for epoch: 0.4748104319852941, mem_alloc: 1023816704\n",
            "Validation set Loss at step 18: 0.37255859375, mean for epoch: 0.4691297743055556, mem_alloc: 1023816704\n",
            "Validation set Loss at step 19: 0.282470703125, mean for epoch: 0.4593056126644737, mem_alloc: 1023816704\n",
            "Validation set Loss at step 20: 0.2744140625, mean for epoch: 0.45006103515625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 21: 0.399658203125, mean for epoch: 0.44766090029761907, mem_alloc: 1023816704\n",
            "Validation set Loss at step 22: 0.294189453125, mean for epoch: 0.44068492542613635, mem_alloc: 1023816704\n",
            "Validation set Loss at step 23: 0.461181640625, mean for epoch: 0.44157608695652173, mem_alloc: 1023816704\n",
            "Validation set Loss at step 24: 0.3974609375, mean for epoch: 0.4397379557291667, mem_alloc: 1023816704\n",
            "Validation set Loss at step 25: 0.32958984375, mean for epoch: 0.43533203125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 26: 0.348876953125, mean for epoch: 0.4320068359375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 27: 0.498046875, mean for epoch: 0.4344527633101852, mem_alloc: 1023816704\n",
            "Validation set Loss at step 28: 0.78857421875, mean for epoch: 0.44709995814732145, mem_alloc: 1023816704\n",
            "Validation set Loss at step 29: 0.61669921875, mean for epoch: 0.45294820851293105, mem_alloc: 1023816704\n",
            "Validation set Loss at step 30: 0.57470703125, mean for epoch: 0.4570068359375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 31: 0.65869140625, mean for epoch: 0.4635127898185484, mem_alloc: 1023816704\n",
            "Validation set Loss at step 32: 0.29150390625, mean for epoch: 0.45813751220703125, mem_alloc: 1023816704\n",
            "Validation set Loss at step 33: 0.322021484375, mean for epoch: 0.4540127840909091, mem_alloc: 1023816704\n",
            "Validation set Loss at step 34: 0.3798828125, mean for epoch: 0.45183249080882354, mem_alloc: 1023816704\n",
            "Validation set Loss at step 35: 0.3603515625, mean for epoch: 0.44921875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 36: 0.35693359375, mean for epoch: 0.4466552734375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 37: 0.30126953125, mean for epoch: 0.44272592905405406, mem_alloc: 1023816704\n",
            "Validation set Loss at step 38: 0.352783203125, mean for epoch: 0.44035901521381576, mem_alloc: 1023816704\n",
            "Validation set Loss at step 39: 0.316162109375, mean for epoch: 0.4371744791666667, mem_alloc: 1023816704\n",
            "Validation set Loss at step 40: 0.333251953125, mean for epoch: 0.434576416015625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 41: 0.29931640625, mean for epoch: 0.4312773913871951, mem_alloc: 1023816704\n",
            "Validation set Loss at step 42: 0.375, mean for epoch: 0.42993745349702384, mem_alloc: 1023816704\n",
            "Validation set Loss at step 43: 0.68017578125, mean for epoch: 0.4357569494912791, mem_alloc: 1023816704\n",
            "Validation set Loss at step 44: 0.70751953125, mean for epoch: 0.4419333718039773, mem_alloc: 1023816704\n",
            "Validation set Loss at step 45: 0.77392578125, mean for epoch: 0.44931098090277777, mem_alloc: 1023816704\n",
            "Validation set Loss at step 46: 0.50830078125, mean for epoch: 0.45059336786684784, mem_alloc: 1023816704\n",
            "Validation set Loss at step 47: 0.375732421875, mean for epoch: 0.4490005817819149, mem_alloc: 1023816704\n",
            "Validation set Loss at step 48: 1.083984375, mean for epoch: 0.4622294108072917, mem_alloc: 1023816704\n",
            "Validation set Loss at step 49: 22.453125, mean for epoch: 0.9110231983418368, mem_alloc: 1023816704\n",
            "Validation set Loss at step 50: 39.875, mean for epoch: 1.690302734375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 51: 21.671875, mean for epoch: 2.082098268995098, mem_alloc: 1023816704\n",
            "Validation set Loss at step 52: 55.46875, mean for epoch: 3.1087646484375, mem_alloc: 1023816704\n",
            "Validation set Loss at step 53: 6.2578125, mean for epoch: 3.1681806456367925, mem_alloc: 1023816704\n",
            "Validation set Loss at step 54: 1.19140625, mean for epoch: 3.131573712384259, mem_alloc: 1023816704\n",
            "Validation set Loss at step 55: 0.499755859375, mean for epoch: 3.083722478693182, mem_alloc: 1023816704\n",
            "Validation set Loss at step 56: 0.305419921875, mean for epoch: 3.0341099330357144, mem_alloc: 1023816704\n",
            "Validation set Loss at step 57: 0.275634765625, mean for epoch: 2.98571563185307, mem_alloc: 1023816704\n",
            "Validation set Loss at step 58: 0.330810546875, mean for epoch: 2.93994140625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 59: 0.306396484375, mean for epoch: 2.895305051641949, mem_alloc: 1023816704\n",
            "Validation set Loss at step 60: 0.332275390625, mean for epoch: 2.852587890625, mem_alloc: 1023816704\n",
            "Validation set Loss at step 61: 0.390625, mean for epoch: 2.812227843237705, mem_alloc: 1023816704\n",
            "Validation set Loss at step 62: 0.57373046875, mean for epoch: 2.776123046875, mem_alloc: 1023816704\n",
            "Validation set Loss at step 63: 0.472900390625, mean for epoch: 2.739563957093254, mem_alloc: 1023816704\n",
            "Validation set Loss at step 64: 0.418701171875, mean for epoch: 2.7033004760742188, mem_alloc: 1023816704\n",
            "Validation set Loss at step 65: 0.62451171875, mean for epoch: 2.671319110576923, mem_alloc: 1023816704\n",
            "Validation set Loss at step 66: 0.89794921875, mean for epoch: 2.6444498697916665, mem_alloc: 1023816704\n",
            "Validation set Loss at step 67: 0.5576171875, mean for epoch: 2.613303113339552, mem_alloc: 1023816704\n",
            "Validation set Loss at step 68: 0.40185546875, mean for epoch: 2.5807818244485294, mem_alloc: 1023816704\n",
            "Validation set Loss at step 69: 0.389404296875, mean for epoch: 2.5490227298460146, mem_alloc: 1023816704\n",
            "Validation set Loss at step 70: 0.5703125, mean for epoch: 2.5207554408482142, mem_alloc: 1023816704\n",
            "Validation set Loss at step 71: 0.50439453125, mean for epoch: 2.4923559914172535, mem_alloc: 1023816704\n",
            "Validation set Loss at step 72: 0.77685546875, mean for epoch: 2.4685295952690973, mem_alloc: 1023816704\n",
            "Validation set Loss at step 73: 0.51025390625, mean for epoch: 2.4417039008989727, mem_alloc: 1023816704\n",
            "Validation set Loss at step 74: 0.35302734375, mean for epoch: 2.413478542018581, mem_alloc: 1023816704\n",
            "Validation set Loss at step 75: 0.58544921875, mean for epoch: 2.389104817708333, mem_alloc: 1023816704\n",
            "Validation set Loss at step 76: 0.4541015625, mean for epoch: 2.3636442485608553, mem_alloc: 1023816704\n",
            "Validation set Loss at step 77: 0.51611328125, mean for epoch: 2.3396503398944803, mem_alloc: 1023816704\n",
            "Validation set Loss at step 78: 0.39208984375, mean for epoch: 2.3146816155849357, mem_alloc: 1023816704\n",
            "Validation set Loss at step 79: 0.32568359375, mean for epoch: 2.2895044254351267, mem_alloc: 1023816704\n",
            "Validation set Loss at step 80: 0.41015625, mean for epoch: 2.2660125732421874, mem_alloc: 1023816704\n",
            "Validation set Loss at step 81: 0.378173828125, mean for epoch: 2.242705922067901, mem_alloc: 1023816704\n",
            "Validation set Loss at step 82: 0.388916015625, mean for epoch: 2.2200987280868905, mem_alloc: 1023816704\n",
            "Validation set Loss at step 83: 0.3583984375, mean for epoch: 2.1976686041039155, mem_alloc: 1023816704\n",
            "Validation set Loss at step 84: 0.439453125, mean for epoch: 2.1767374674479165, mem_alloc: 1023816704\n",
            "Validation set Loss at step 85: 0.406005859375, mean for epoch: 2.155905330882353, mem_alloc: 1023816704\n",
            "Validation set Loss at step 86: 0.490478515625, mean for epoch: 2.1365399027979652, mem_alloc: 1023816704\n",
            "Validation set Loss at step 87: 0.6181640625, mean for epoch: 2.1190873069324714, mem_alloc: 1023816704\n",
            "Validation set Loss at step 88: 0.6201171875, mean for epoch: 2.102053555575284, mem_alloc: 1023816704\n",
            "Validation set Loss at step 89: 0.548828125, mean for epoch: 2.084601584445225, mem_alloc: 1023816704\n",
            "Loss for validation set  ; MSE: 2.083984375, MAE: 0.5302734375\n",
            "prediction[0.06396, 0.1388, 0.3384, 0.221, 0.3628, 0.154, -0.04926, -0.208, -0.4727, -0.4915, -0.3196, -0.2566, 0.03061, 0.5303, 0.6333, 1.042, 0.872, 0.8896, 0.8306, 0.588, 0.3481, 0.02072, 0.0642, -0.1205]Connected by ('127.0.0.1', 42758)\n",
            "\n",
            "\u001b[94mReceived result: b'2.08398;0.53027' \u001b[0m\n",
            "truth[0.0924, 0.127, 0.1855, 0.2688, 0.318, 0.09155, -0.03864, -0.1779, -0.02875, -0.0996, -0.1186, -0.0922, -0.1392, 1.113, 0.719, 1.474, 1.246, 1.088, 1.033, 0.848, 0.2876, 0.2177, 0.1254, 0.113]\n",
            "Iteration  1| MSE 2.0801 | MAE 0.5230\n",
            "Iteration  2| MSE 2.0840 | MAE 0.5303\n",
            "Mean        | MSE 2.0820 | MAE 0.5266\n",
            "Iteration  1| MSE 2.0801 | MAE 0.5230\n",
            "Iteration  2| MSE 2.0840 | MAE 0.5303\n",
            "Mean        | MSE 2.0820 | MAE 0.5266\n",
            "[[[0.9375, 0.57715], [0.93457, 0.57471]], [[0.79053, 0.48999], [0.79443, 0.49146]], [[0.76367, 0.47437], [0.76709, 0.4751]], [[0.74951, 0.46631], [0.74951, 0.46631]], [[0.7373, 0.45972], [0.73682, 0.45996]]]\n",
            "[2022-10-31 19:03:38,990] [INFO] [launch.py:318:main] Process 1205 exits successfully.\n"
          ]
        }
      ]
    }
  ]
}